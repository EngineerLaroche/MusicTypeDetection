{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload chaque module spécifié par %aimport\n",
    "%autoreload 1\n",
    "\n",
    "%aimport src.kerasCallbacks\n",
    "%aimport src.results\n",
    "\n",
    "from IPython.display import display\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from src import constants\n",
    "from src.kerasCallbacks import BestWeightsRestorer\n",
    "import src.results as resultsUtil\n",
    "import src.runUtil as runUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_feature_set():\n",
    "\n",
    "    file_path = path.join(constants.RAW_TAGGED_FEATURE_SET_PATH, \"msd-marsyas_dev_new/msd-marsyas_dev_new.csv\")\n",
    "    \n",
    "    ftrs = np.array(pd.read_csv(file_path, header=None).values[:,2:-1])\n",
    "    lbls = np.array(pd.read_csv(file_path, header=None).values[:,-1])\n",
    "    \n",
    "    return ftrs, lbls\n",
    "\n",
    "def scale_features(ftrs):\n",
    "    \n",
    "    standardscaler = StandardScaler()\n",
    "    ftrs_scld = standardscaler.fit_transform(ftrs)\n",
    "    \n",
    "    return ftrs_scld\n",
    "\n",
    "def one_hot_labels(lbls):\n",
    "    \n",
    "    lbls_1d = lbls.reshape(len(lbls), 1)\n",
    "        \n",
    "    oh_encoder = OneHotEncoder(sparse=False)\n",
    "    lbls_oh = oh_encoder.fit_transform(lbls_1d)\n",
    "    \n",
    "    return lbls_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features and the labels\n",
    "raw_ftrs, raw_lbls = load_feature_set()\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoded_lbls = lbl_encoder.fit_transform(raw_lbls)\n",
    "\n",
    "ftrs = scale_features(raw_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    layer = Dense(90, activation='relu')(inputs)\n",
    "    layer = Dense(85, activation='relu')(layer)\n",
    "    \n",
    "    layer = Dropout(0.10)(layer)\n",
    "    \n",
    "    layer = Dense(80, activation='relu')(layer)\n",
    "    layer = Dense(75, activation='relu')(layer)\n",
    "    layer = Dense(70, activation='relu')(layer)\n",
    "    \n",
    "    layer = BatchNormalization()(layer)\n",
    "    \n",
    "    layer = Dense(65, activation='relu')(layer)\n",
    "    layer = Dense(60, activation='relu')(layer)\n",
    "    \n",
    "    layer = BatchNormalization()(layer)\n",
    "    \n",
    "    layer = Dense(55, activation='relu')(layer)\n",
    "    layer = Dense(50, activation='relu')(layer)\n",
    "    \n",
    "    layer = Dropout(0.10)(layer)\n",
    "    \n",
    "    layer = Dense(45, activation='relu')(layer)\n",
    "    layer = Dense(40, activation='relu')(layer)\n",
    "    \n",
    "    layer = Dropout(0.10)(layer)\n",
    "    \n",
    "    layer = Dense(30, activation='relu')(layer)\n",
    "    \n",
    "    outputs = Dense(25, activation='softmax')(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.001), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            CategoricalAccuracy(name='accuracy')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Train on 237150 samples, validate on 35922 samples\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/110\n",
      "237150/237150 [==============================] - 2s 11us/sample - loss: 2.8867 - accuracy: 0.1478 - val_loss: 2.8725 - val_accuracy: 0.1659\n",
      "Epoch 2/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.5356 - accuracy: 0.2318 - val_loss: 2.6070 - val_accuracy: 0.2151\n",
      "Epoch 3/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.4399 - accuracy: 0.2604 - val_loss: 2.4758 - val_accuracy: 0.2428\n",
      "Epoch 4/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3800 - accuracy: 0.2789 - val_loss: 2.4532 - val_accuracy: 0.2447\n",
      "Epoch 5/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3366 - accuracy: 0.2940 - val_loss: 2.4374 - val_accuracy: 0.2522\n",
      "Epoch 6/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2991 - accuracy: 0.3065 - val_loss: 2.4256 - val_accuracy: 0.2565\n",
      "Epoch 7/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2711 - accuracy: 0.3148 - val_loss: 2.3966 - val_accuracy: 0.2674\n",
      "Epoch 8/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2456 - accuracy: 0.3220 - val_loss: 2.3836 - val_accuracy: 0.2704\n",
      "Epoch 9/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2262 - accuracy: 0.3281 - val_loss: 2.3801 - val_accuracy: 0.2689\n",
      "Epoch 10/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2112 - accuracy: 0.3330 - val_loss: 2.3605 - val_accuracy: 0.2738\n",
      "Epoch 11/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1950 - accuracy: 0.3383 - val_loss: 2.3666 - val_accuracy: 0.2746\n",
      "Epoch 12/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1827 - accuracy: 0.3413 - val_loss: 2.3604 - val_accuracy: 0.2760\n",
      "Epoch 13/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1709 - accuracy: 0.3447 - val_loss: 2.3680 - val_accuracy: 0.2726\n",
      "Epoch 14/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.1596 - accuracy: 0.3475 - val_loss: 2.3580 - val_accuracy: 0.2759\n",
      "Epoch 15/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1504 - accuracy: 0.3517 - val_loss: 2.3454 - val_accuracy: 0.2772\n",
      "Epoch 16/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1400 - accuracy: 0.3544 - val_loss: 2.3471 - val_accuracy: 0.2812\n",
      "Epoch 17/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1309 - accuracy: 0.3571 - val_loss: 2.3474 - val_accuracy: 0.2779\n",
      "Epoch 18/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1243 - accuracy: 0.3581 - val_loss: 2.3422 - val_accuracy: 0.2846\n",
      "Epoch 19/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1160 - accuracy: 0.3603 - val_loss: 2.3465 - val_accuracy: 0.2787\n",
      "Epoch 20/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1100 - accuracy: 0.3635 - val_loss: 2.3395 - val_accuracy: 0.2827\n",
      "Epoch 21/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.1032 - accuracy: 0.3649 - val_loss: 2.3573 - val_accuracy: 0.2775\n",
      "Epoch 22/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0949 - accuracy: 0.3683 - val_loss: 2.3331 - val_accuracy: 0.2836\n",
      "Epoch 23/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0910 - accuracy: 0.3694 - val_loss: 2.3476 - val_accuracy: 0.2819\n",
      "Epoch 24/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0859 - accuracy: 0.3698 - val_loss: 2.3496 - val_accuracy: 0.2796\n",
      "Epoch 25/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0795 - accuracy: 0.3722 - val_loss: 2.3470 - val_accuracy: 0.2793\n",
      "Epoch 26/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0738 - accuracy: 0.3740 - val_loss: 2.3590 - val_accuracy: 0.2788\n",
      "Epoch 27/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0703 - accuracy: 0.3763 - val_loss: 2.3417 - val_accuracy: 0.2836\n",
      "Epoch 28/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0631 - accuracy: 0.3774 - val_loss: 2.3443 - val_accuracy: 0.2807\n",
      "Epoch 29/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0593 - accuracy: 0.3787 - val_loss: 2.3331 - val_accuracy: 0.2863\n",
      "Epoch 30/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0557 - accuracy: 0.3793 - val_loss: 2.3373 - val_accuracy: 0.2817\n",
      "Epoch 31/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0534 - accuracy: 0.3809 - val_loss: 2.3448 - val_accuracy: 0.2832\n",
      "Epoch 32/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0508 - accuracy: 0.3810 - val_loss: 2.3462 - val_accuracy: 0.2829\n",
      "Epoch 33/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0455 - accuracy: 0.3828 - val_loss: 2.3584 - val_accuracy: 0.2758\n",
      "Epoch 34/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0406 - accuracy: 0.3837 - val_loss: 2.3455 - val_accuracy: 0.2868\n",
      "Epoch 35/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0382 - accuracy: 0.3854 - val_loss: 2.3403 - val_accuracy: 0.2843\n",
      "Epoch 36/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0341 - accuracy: 0.3861 - val_loss: 2.3385 - val_accuracy: 0.2835\n",
      "Epoch 37/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0319 - accuracy: 0.3866 - val_loss: 2.3436 - val_accuracy: 0.2844\n",
      "Epoch 38/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0280 - accuracy: 0.3872 - val_loss: 2.3306 - val_accuracy: 0.2889\n",
      "Epoch 39/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0253 - accuracy: 0.3881 - val_loss: 2.3368 - val_accuracy: 0.2875\n",
      "Epoch 40/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0233 - accuracy: 0.3893 - val_loss: 2.3328 - val_accuracy: 0.2864\n",
      "Epoch 41/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0194 - accuracy: 0.3900 - val_loss: 2.3555 - val_accuracy: 0.2834\n",
      "Epoch 42/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0174 - accuracy: 0.3909 - val_loss: 2.3568 - val_accuracy: 0.2837\n",
      "Epoch 43/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0148 - accuracy: 0.3909 - val_loss: 2.3420 - val_accuracy: 0.2852\n",
      "Epoch 44/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0096 - accuracy: 0.3935 - val_loss: 2.3370 - val_accuracy: 0.2850\n",
      "Epoch 45/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0119 - accuracy: 0.3931 - val_loss: 2.3338 - val_accuracy: 0.2897\n",
      "Epoch 46/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0075 - accuracy: 0.3931 - val_loss: 2.3373 - val_accuracy: 0.2873\n",
      "Epoch 47/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0041 - accuracy: 0.3947 - val_loss: 2.3405 - val_accuracy: 0.2868\n",
      "Epoch 48/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0013 - accuracy: 0.3948 - val_loss: 2.3440 - val_accuracy: 0.2862\n",
      "Epoch 49/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0011 - accuracy: 0.3958 - val_loss: 2.3417 - val_accuracy: 0.2871\n",
      "Epoch 50/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9997 - accuracy: 0.3957 - val_loss: 2.3439 - val_accuracy: 0.2845\n",
      "Epoch 51/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9938 - accuracy: 0.3983 - val_loss: 2.3469 - val_accuracy: 0.2854\n",
      "Epoch 52/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9941 - accuracy: 0.3982 - val_loss: 2.3472 - val_accuracy: 0.2836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9904 - accuracy: 0.3981 - val_loss: 2.3355 - val_accuracy: 0.2900\n",
      "Epoch 54/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9884 - accuracy: 0.3993 - val_loss: 2.3443 - val_accuracy: 0.2867\n",
      "Epoch 55/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9872 - accuracy: 0.4001 - val_loss: 2.3427 - val_accuracy: 0.2844\n",
      "Epoch 56/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9837 - accuracy: 0.4015 - val_loss: 2.3343 - val_accuracy: 0.2906\n",
      "Epoch 57/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9851 - accuracy: 0.3998 - val_loss: 2.3418 - val_accuracy: 0.2890\n",
      "Epoch 58/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9825 - accuracy: 0.4011 - val_loss: 2.3464 - val_accuracy: 0.2874\n",
      "Epoch 59/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9797 - accuracy: 0.4018 - val_loss: 2.3512 - val_accuracy: 0.2829\n",
      "Epoch 60/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9759 - accuracy: 0.4033 - val_loss: 2.3577 - val_accuracy: 0.2834\n",
      "Epoch 61/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9779 - accuracy: 0.4031 - val_loss: 2.3730 - val_accuracy: 0.2820\n",
      "Epoch 62/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9737 - accuracy: 0.4042 - val_loss: 2.3408 - val_accuracy: 0.2849\n",
      "Epoch 63/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9726 - accuracy: 0.4037 - val_loss: 2.3622 - val_accuracy: 0.2860\n",
      "Epoch 64/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9721 - accuracy: 0.4047 - val_loss: 2.3394 - val_accuracy: 0.2891\n",
      "Epoch 65/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9694 - accuracy: 0.4048 - val_loss: 2.3481 - val_accuracy: 0.2845\n",
      "Epoch 66/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9676 - accuracy: 0.4058 - val_loss: 2.3548 - val_accuracy: 0.2850\n",
      "Epoch 67/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9654 - accuracy: 0.4061 - val_loss: 2.3385 - val_accuracy: 0.2890\n",
      "Epoch 68/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9635 - accuracy: 0.4070 - val_loss: 2.3662 - val_accuracy: 0.2829\n",
      "Epoch 69/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9602 - accuracy: 0.4076 - val_loss: 2.3559 - val_accuracy: 0.2854\n",
      "Epoch 70/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9627 - accuracy: 0.4080 - val_loss: 2.3472 - val_accuracy: 0.2863\n",
      "Epoch 71/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9607 - accuracy: 0.4084 - val_loss: 2.3563 - val_accuracy: 0.2863\n",
      "Epoch 72/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9565 - accuracy: 0.4087 - val_loss: 2.3441 - val_accuracy: 0.2898\n",
      "Epoch 73/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9563 - accuracy: 0.4089 - val_loss: 2.3559 - val_accuracy: 0.2849\n",
      "Epoch 74/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9555 - accuracy: 0.4091 - val_loss: 2.3567 - val_accuracy: 0.2859\n",
      "Epoch 75/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9568 - accuracy: 0.4092 - val_loss: 2.3554 - val_accuracy: 0.2855\n",
      "Epoch 76/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9533 - accuracy: 0.4106 - val_loss: 2.3508 - val_accuracy: 0.2869\n",
      "Epoch 77/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9520 - accuracy: 0.4105 - val_loss: 2.3534 - val_accuracy: 0.2850\n",
      "Epoch 78/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9511 - accuracy: 0.4108 - val_loss: 2.3583 - val_accuracy: 0.2846\n",
      "Epoch 79/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9501 - accuracy: 0.4105 - val_loss: 2.3700 - val_accuracy: 0.2803\n",
      "Epoch 80/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9460 - accuracy: 0.4123 - val_loss: 2.3578 - val_accuracy: 0.2849\n",
      "Epoch 81/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9457 - accuracy: 0.4125 - val_loss: 2.3580 - val_accuracy: 0.2858\n",
      "Epoch 82/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9479 - accuracy: 0.4120 - val_loss: 2.3438 - val_accuracy: 0.2869\n",
      "Epoch 83/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9434 - accuracy: 0.4123 - val_loss: 2.3507 - val_accuracy: 0.2857\n",
      "Epoch 84/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9426 - accuracy: 0.4140 - val_loss: 2.3643 - val_accuracy: 0.2835\n",
      "Epoch 85/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9407 - accuracy: 0.4142 - val_loss: 2.3702 - val_accuracy: 0.2853\n",
      "Epoch 86/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9388 - accuracy: 0.4146 - val_loss: 2.3785 - val_accuracy: 0.2811\n",
      "Epoch 87/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9400 - accuracy: 0.4141 - val_loss: 2.3728 - val_accuracy: 0.2819\n",
      "Epoch 88/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9386 - accuracy: 0.4145 - val_loss: 2.3468 - val_accuracy: 0.2871\n",
      "Epoch 89/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9375 - accuracy: 0.4148 - val_loss: 2.3602 - val_accuracy: 0.2877\n",
      "Epoch 90/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9372 - accuracy: 0.4145 - val_loss: 2.3582 - val_accuracy: 0.2885\n",
      "Epoch 91/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9366 - accuracy: 0.4155 - val_loss: 2.3530 - val_accuracy: 0.2885\n",
      "Epoch 92/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9354 - accuracy: 0.4151 - val_loss: 2.3652 - val_accuracy: 0.2859\n",
      "Epoch 93/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9324 - accuracy: 0.4168 - val_loss: 2.3535 - val_accuracy: 0.2864\n",
      "Epoch 94/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9308 - accuracy: 0.4162 - val_loss: 2.3774 - val_accuracy: 0.2843\n",
      "Epoch 95/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9326 - accuracy: 0.4165 - val_loss: 2.3483 - val_accuracy: 0.2890\n",
      "Epoch 96/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9317 - accuracy: 0.4166 - val_loss: 2.3622 - val_accuracy: 0.2847\n",
      "Epoch 97/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9300 - accuracy: 0.4173 - val_loss: 2.3517 - val_accuracy: 0.2881\n",
      "Epoch 98/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9290 - accuracy: 0.4167 - val_loss: 2.3638 - val_accuracy: 0.2839\n",
      "Epoch 99/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9293 - accuracy: 0.4171 - val_loss: 2.3629 - val_accuracy: 0.2819\n",
      "Epoch 100/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9281 - accuracy: 0.4171 - val_loss: 2.3721 - val_accuracy: 0.2869\n",
      "Epoch 101/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9237 - accuracy: 0.4188 - val_loss: 2.3530 - val_accuracy: 0.2885\n",
      "Epoch 102/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9278 - accuracy: 0.4167 - val_loss: 2.3485 - val_accuracy: 0.2904\n",
      "Epoch 103/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9244 - accuracy: 0.4183 - val_loss: 2.3722 - val_accuracy: 0.2867\n",
      "Epoch 104/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9221 - accuracy: 0.4193 - val_loss: 2.3717 - val_accuracy: 0.2838\n",
      "Epoch 105/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9240 - accuracy: 0.4186 - val_loss: 2.3523 - val_accuracy: 0.2859\n",
      "Epoch 106/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9242 - accuracy: 0.4184 - val_loss: 2.3662 - val_accuracy: 0.2848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9218 - accuracy: 0.4188 - val_loss: 2.3634 - val_accuracy: 0.2839\n",
      "Epoch 108/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9179 - accuracy: 0.4211 - val_loss: 2.3546 - val_accuracy: 0.2884\n",
      "Epoch 109/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9187 - accuracy: 0.4197 - val_loss: 2.3528 - val_accuracy: 0.2864\n",
      "Epoch 110/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9170 - accuracy: 0.4210 - val_loss: 2.3587 - val_accuracy: 0.2884\n",
      "Restoring the best weights from epoch 110\n",
      "Training fold 2\n",
      "Train on 237150 samples, validate on 35914 samples\n",
      "Epoch 1/110\n",
      "237150/237150 [==============================] - 2s 10us/sample - loss: 2.8796 - accuracy: 0.1448 - val_loss: 2.8589 - val_accuracy: 0.1728\n",
      "Epoch 2/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.5266 - accuracy: 0.2360 - val_loss: 2.5786 - val_accuracy: 0.2168\n",
      "Epoch 3/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.4305 - accuracy: 0.2667 - val_loss: 2.4922 - val_accuracy: 0.2330\n",
      "Epoch 4/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3705 - accuracy: 0.2869 - val_loss: 2.4586 - val_accuracy: 0.2496\n",
      "Epoch 5/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3247 - accuracy: 0.2999 - val_loss: 2.4384 - val_accuracy: 0.2543\n",
      "Epoch 6/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2885 - accuracy: 0.3104 - val_loss: 2.4503 - val_accuracy: 0.2519\n",
      "Epoch 7/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.2596 - accuracy: 0.3196 - val_loss: 2.4057 - val_accuracy: 0.2655\n",
      "Epoch 8/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2394 - accuracy: 0.3248 - val_loss: 2.3942 - val_accuracy: 0.2655\n",
      "Epoch 9/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2198 - accuracy: 0.3305 - val_loss: 2.4008 - val_accuracy: 0.2676\n",
      "Epoch 10/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2025 - accuracy: 0.3348 - val_loss: 2.3838 - val_accuracy: 0.2704\n",
      "Epoch 11/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1874 - accuracy: 0.3398 - val_loss: 2.3718 - val_accuracy: 0.2746\n",
      "Epoch 12/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1791 - accuracy: 0.3418 - val_loss: 2.3692 - val_accuracy: 0.2768\n",
      "Epoch 13/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1654 - accuracy: 0.3456 - val_loss: 2.3799 - val_accuracy: 0.2750\n",
      "Epoch 14/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1545 - accuracy: 0.3493 - val_loss: 2.3818 - val_accuracy: 0.2736\n",
      "Epoch 15/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1443 - accuracy: 0.3513 - val_loss: 2.3623 - val_accuracy: 0.2795\n",
      "Epoch 16/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1395 - accuracy: 0.3529 - val_loss: 2.3469 - val_accuracy: 0.2794\n",
      "Epoch 17/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1288 - accuracy: 0.3555 - val_loss: 2.3703 - val_accuracy: 0.2773\n",
      "Epoch 18/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1205 - accuracy: 0.3575 - val_loss: 2.3526 - val_accuracy: 0.2782\n",
      "Epoch 19/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1138 - accuracy: 0.3604 - val_loss: 2.3574 - val_accuracy: 0.2779\n",
      "Epoch 20/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1048 - accuracy: 0.3632 - val_loss: 2.3613 - val_accuracy: 0.2817\n",
      "Epoch 21/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0996 - accuracy: 0.3640 - val_loss: 2.3947 - val_accuracy: 0.2725\n",
      "Epoch 22/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0943 - accuracy: 0.3657 - val_loss: 2.3515 - val_accuracy: 0.2828\n",
      "Epoch 23/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0863 - accuracy: 0.3693 - val_loss: 2.3561 - val_accuracy: 0.2803\n",
      "Epoch 24/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0831 - accuracy: 0.3688 - val_loss: 2.3472 - val_accuracy: 0.2822\n",
      "Epoch 25/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0782 - accuracy: 0.3707 - val_loss: 2.3564 - val_accuracy: 0.2810\n",
      "Epoch 26/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0724 - accuracy: 0.3727 - val_loss: 2.3391 - val_accuracy: 0.2865\n",
      "Epoch 27/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0676 - accuracy: 0.3751 - val_loss: 2.3466 - val_accuracy: 0.2822\n",
      "Epoch 28/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0631 - accuracy: 0.3764 - val_loss: 2.3556 - val_accuracy: 0.2836\n",
      "Epoch 29/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0570 - accuracy: 0.3763 - val_loss: 2.3584 - val_accuracy: 0.2804\n",
      "Epoch 30/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0545 - accuracy: 0.3772 - val_loss: 2.3565 - val_accuracy: 0.2793\n",
      "Epoch 31/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0494 - accuracy: 0.3794 - val_loss: 2.3397 - val_accuracy: 0.2847\n",
      "Epoch 32/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0451 - accuracy: 0.3822 - val_loss: 2.3400 - val_accuracy: 0.2860\n",
      "Epoch 33/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0403 - accuracy: 0.3829 - val_loss: 2.3413 - val_accuracy: 0.2872\n",
      "Epoch 34/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0399 - accuracy: 0.3828 - val_loss: 2.3614 - val_accuracy: 0.2806\n",
      "Epoch 35/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0335 - accuracy: 0.3851 - val_loss: 2.3630 - val_accuracy: 0.2805\n",
      "Epoch 36/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0308 - accuracy: 0.3845 - val_loss: 2.3517 - val_accuracy: 0.2850\n",
      "Epoch 37/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0286 - accuracy: 0.3860 - val_loss: 2.3577 - val_accuracy: 0.2864\n",
      "Epoch 38/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0266 - accuracy: 0.3864 - val_loss: 2.3640 - val_accuracy: 0.2831\n",
      "Epoch 39/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0221 - accuracy: 0.3876 - val_loss: 2.3439 - val_accuracy: 0.2863\n",
      "Epoch 40/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0197 - accuracy: 0.3884 - val_loss: 2.3606 - val_accuracy: 0.2840\n",
      "Epoch 41/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0206 - accuracy: 0.3893 - val_loss: 2.3614 - val_accuracy: 0.2827\n",
      "Epoch 42/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0123 - accuracy: 0.3911 - val_loss: 2.3686 - val_accuracy: 0.2825\n",
      "Epoch 43/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0091 - accuracy: 0.3920 - val_loss: 2.3417 - val_accuracy: 0.2869\n",
      "Epoch 44/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0079 - accuracy: 0.3921 - val_loss: 2.3634 - val_accuracy: 0.2804\n",
      "Epoch 45/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0069 - accuracy: 0.3921 - val_loss: 2.3482 - val_accuracy: 0.2857\n",
      "Epoch 46/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0032 - accuracy: 0.3934 - val_loss: 2.3444 - val_accuracy: 0.2877\n",
      "Epoch 47/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0022 - accuracy: 0.3947 - val_loss: 2.3699 - val_accuracy: 0.2822\n",
      "Epoch 48/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9997 - accuracy: 0.3947 - val_loss: 2.3462 - val_accuracy: 0.2886\n",
      "Epoch 49/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9950 - accuracy: 0.3960 - val_loss: 2.3416 - val_accuracy: 0.2881\n",
      "Epoch 50/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9928 - accuracy: 0.3965 - val_loss: 2.3496 - val_accuracy: 0.2889\n",
      "Epoch 51/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9908 - accuracy: 0.3972 - val_loss: 2.3485 - val_accuracy: 0.2886\n",
      "Epoch 52/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9918 - accuracy: 0.3968 - val_loss: 2.3445 - val_accuracy: 0.2890\n",
      "Epoch 53/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9906 - accuracy: 0.3978 - val_loss: 2.3506 - val_accuracy: 0.2877\n",
      "Epoch 54/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9862 - accuracy: 0.3993 - val_loss: 2.3633 - val_accuracy: 0.2865\n",
      "Epoch 55/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9831 - accuracy: 0.3998 - val_loss: 2.3387 - val_accuracy: 0.2899\n",
      "Epoch 56/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9810 - accuracy: 0.4000 - val_loss: 2.3597 - val_accuracy: 0.2886\n",
      "Epoch 57/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9819 - accuracy: 0.4004 - val_loss: 2.3579 - val_accuracy: 0.2869\n",
      "Epoch 58/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9785 - accuracy: 0.4010 - val_loss: 2.3587 - val_accuracy: 0.2875\n",
      "Epoch 59/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9766 - accuracy: 0.4023 - val_loss: 2.3592 - val_accuracy: 0.2850\n",
      "Epoch 60/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9732 - accuracy: 0.4022 - val_loss: 2.3428 - val_accuracy: 0.2901\n",
      "Epoch 61/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9724 - accuracy: 0.4028 - val_loss: 2.3664 - val_accuracy: 0.2853\n",
      "Epoch 62/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9717 - accuracy: 0.4032 - val_loss: 2.3499 - val_accuracy: 0.2866\n",
      "Epoch 63/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9708 - accuracy: 0.4034 - val_loss: 2.3582 - val_accuracy: 0.2891\n",
      "Epoch 64/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9693 - accuracy: 0.4038 - val_loss: 2.3579 - val_accuracy: 0.2844\n",
      "Epoch 65/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9699 - accuracy: 0.4038 - val_loss: 2.3568 - val_accuracy: 0.2884\n",
      "Epoch 66/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9670 - accuracy: 0.4043 - val_loss: 2.3550 - val_accuracy: 0.2853\n",
      "Epoch 67/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9639 - accuracy: 0.4051 - val_loss: 2.3490 - val_accuracy: 0.2864\n",
      "Epoch 68/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9648 - accuracy: 0.4046 - val_loss: 2.3702 - val_accuracy: 0.2858\n",
      "Epoch 69/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9603 - accuracy: 0.4067 - val_loss: 2.3613 - val_accuracy: 0.2864\n",
      "Epoch 70/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9595 - accuracy: 0.4063 - val_loss: 2.3672 - val_accuracy: 0.2878\n",
      "Epoch 71/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9588 - accuracy: 0.4068 - val_loss: 2.3744 - val_accuracy: 0.2826\n",
      "Epoch 72/110\n",
      "237150/237150 [==============================] - 2s 6us/sample - loss: 1.9571 - accuracy: 0.4074 - val_loss: 2.3575 - val_accuracy: 0.2855\n",
      "Epoch 73/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9574 - accuracy: 0.4083 - val_loss: 2.3578 - val_accuracy: 0.2860\n",
      "Epoch 74/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9526 - accuracy: 0.4082 - val_loss: 2.3577 - val_accuracy: 0.2901\n",
      "Epoch 75/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9543 - accuracy: 0.4079 - val_loss: 2.3635 - val_accuracy: 0.2856\n",
      "Epoch 76/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9498 - accuracy: 0.4083 - val_loss: 2.3475 - val_accuracy: 0.2900\n",
      "Epoch 77/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9512 - accuracy: 0.4087 - val_loss: 2.3502 - val_accuracy: 0.2909\n",
      "Epoch 78/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9487 - accuracy: 0.4094 - val_loss: 2.3441 - val_accuracy: 0.2885\n",
      "Epoch 79/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9468 - accuracy: 0.4107 - val_loss: 2.3777 - val_accuracy: 0.2867\n",
      "Epoch 80/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9454 - accuracy: 0.4111 - val_loss: 2.3552 - val_accuracy: 0.2904\n",
      "Epoch 81/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9438 - accuracy: 0.4109 - val_loss: 2.3628 - val_accuracy: 0.2864\n",
      "Epoch 82/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9466 - accuracy: 0.4102 - val_loss: 2.3569 - val_accuracy: 0.2871\n",
      "Epoch 83/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9442 - accuracy: 0.4125 - val_loss: 2.3559 - val_accuracy: 0.2874\n",
      "Epoch 84/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9428 - accuracy: 0.4115 - val_loss: 2.3517 - val_accuracy: 0.2885\n",
      "Epoch 85/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9425 - accuracy: 0.4118 - val_loss: 2.3532 - val_accuracy: 0.2874\n",
      "Epoch 86/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9407 - accuracy: 0.4123 - val_loss: 2.3649 - val_accuracy: 0.2858\n",
      "Epoch 87/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9396 - accuracy: 0.4110 - val_loss: 2.3654 - val_accuracy: 0.2863\n",
      "Epoch 88/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9382 - accuracy: 0.4127 - val_loss: 2.3503 - val_accuracy: 0.2894\n",
      "Epoch 89/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9365 - accuracy: 0.4131 - val_loss: 2.3562 - val_accuracy: 0.2878\n",
      "Epoch 90/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9373 - accuracy: 0.4132 - val_loss: 2.3498 - val_accuracy: 0.2913\n",
      "Epoch 91/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9371 - accuracy: 0.4132 - val_loss: 2.3682 - val_accuracy: 0.2865\n",
      "Epoch 92/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9336 - accuracy: 0.4138 - val_loss: 2.3554 - val_accuracy: 0.2886\n",
      "Epoch 93/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9344 - accuracy: 0.4151 - val_loss: 2.3685 - val_accuracy: 0.2864\n",
      "Epoch 94/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9300 - accuracy: 0.4153 - val_loss: 2.3705 - val_accuracy: 0.2888\n",
      "Epoch 95/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9303 - accuracy: 0.4157 - val_loss: 2.3608 - val_accuracy: 0.2900\n",
      "Epoch 96/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9305 - accuracy: 0.4154 - val_loss: 2.3636 - val_accuracy: 0.2898\n",
      "Epoch 97/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9293 - accuracy: 0.4146 - val_loss: 2.3516 - val_accuracy: 0.2885\n",
      "Epoch 98/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9287 - accuracy: 0.4155 - val_loss: 2.3665 - val_accuracy: 0.2881\n",
      "Epoch 99/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9257 - accuracy: 0.4160 - val_loss: 2.3610 - val_accuracy: 0.2864\n",
      "Epoch 100/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9271 - accuracy: 0.4164 - val_loss: 2.3826 - val_accuracy: 0.2848\n",
      "Epoch 101/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9274 - accuracy: 0.4162 - val_loss: 2.3654 - val_accuracy: 0.2877\n",
      "Epoch 102/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9264 - accuracy: 0.4168 - val_loss: 2.3645 - val_accuracy: 0.2888\n",
      "Epoch 103/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9244 - accuracy: 0.4168 - val_loss: 2.3631 - val_accuracy: 0.2869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9213 - accuracy: 0.4176 - val_loss: 2.3678 - val_accuracy: 0.2840\n",
      "Epoch 105/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9234 - accuracy: 0.4177 - val_loss: 2.3544 - val_accuracy: 0.2879\n",
      "Epoch 106/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9221 - accuracy: 0.4168 - val_loss: 2.3713 - val_accuracy: 0.2867\n",
      "Epoch 107/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9187 - accuracy: 0.4190 - val_loss: 2.3674 - val_accuracy: 0.2883\n",
      "Epoch 108/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9192 - accuracy: 0.4191 - val_loss: 2.3716 - val_accuracy: 0.2889\n",
      "Epoch 109/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9197 - accuracy: 0.4175 - val_loss: 2.3557 - val_accuracy: 0.2887\n",
      "Epoch 110/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9151 - accuracy: 0.4194 - val_loss: 2.3797 - val_accuracy: 0.2866\n",
      "Restoring the best weights from epoch 110\n",
      "Training fold 3\n",
      "Train on 237150 samples, validate on 35911 samples\n",
      "Epoch 1/110\n",
      "237150/237150 [==============================] - 2s 10us/sample - loss: 2.8834 - accuracy: 0.1428 - val_loss: 2.8134 - val_accuracy: 0.1858\n",
      "Epoch 2/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.5499 - accuracy: 0.2253 - val_loss: 2.6015 - val_accuracy: 0.2120\n",
      "Epoch 3/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.4576 - accuracy: 0.2551 - val_loss: 2.5084 - val_accuracy: 0.2307\n",
      "Epoch 4/110\n",
      "237150/237150 [==============================] - 2s 6us/sample - loss: 2.3922 - accuracy: 0.2776 - val_loss: 2.4645 - val_accuracy: 0.2499\n",
      "Epoch 5/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3424 - accuracy: 0.2943 - val_loss: 2.4228 - val_accuracy: 0.2606\n",
      "Epoch 6/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.3043 - accuracy: 0.3052 - val_loss: 2.4139 - val_accuracy: 0.2579\n",
      "Epoch 7/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2736 - accuracy: 0.3151 - val_loss: 2.4043 - val_accuracy: 0.2636\n",
      "Epoch 8/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2477 - accuracy: 0.3225 - val_loss: 2.4150 - val_accuracy: 0.2705\n",
      "Epoch 9/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2270 - accuracy: 0.3290 - val_loss: 2.3868 - val_accuracy: 0.2703\n",
      "Epoch 10/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.2099 - accuracy: 0.3339 - val_loss: 2.3773 - val_accuracy: 0.2727\n",
      "Epoch 11/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1933 - accuracy: 0.3387 - val_loss: 2.3722 - val_accuracy: 0.2749\n",
      "Epoch 12/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1799 - accuracy: 0.3435 - val_loss: 2.3867 - val_accuracy: 0.2743\n",
      "Epoch 13/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1669 - accuracy: 0.3464 - val_loss: 2.3553 - val_accuracy: 0.2801\n",
      "Epoch 14/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1576 - accuracy: 0.3493 - val_loss: 2.3616 - val_accuracy: 0.2811\n",
      "Epoch 15/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1458 - accuracy: 0.3537 - val_loss: 2.3808 - val_accuracy: 0.2768\n",
      "Epoch 16/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1374 - accuracy: 0.3554 - val_loss: 2.3486 - val_accuracy: 0.2829\n",
      "Epoch 17/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1303 - accuracy: 0.3572 - val_loss: 2.3490 - val_accuracy: 0.2864\n",
      "Epoch 18/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1211 - accuracy: 0.3607 - val_loss: 2.3471 - val_accuracy: 0.2853\n",
      "Epoch 19/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1130 - accuracy: 0.3617 - val_loss: 2.3451 - val_accuracy: 0.2895\n",
      "Epoch 20/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1067 - accuracy: 0.3647 - val_loss: 2.3526 - val_accuracy: 0.2858\n",
      "Epoch 21/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.1013 - accuracy: 0.3663 - val_loss: 2.3495 - val_accuracy: 0.2879\n",
      "Epoch 22/110\n",
      "237150/237150 [==============================] - 2s 7us/sample - loss: 2.0955 - accuracy: 0.3684 - val_loss: 2.3495 - val_accuracy: 0.2880\n",
      "Epoch 23/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0853 - accuracy: 0.3714 - val_loss: 2.3572 - val_accuracy: 0.2875\n",
      "Epoch 24/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0830 - accuracy: 0.3715 - val_loss: 2.3534 - val_accuracy: 0.2842\n",
      "Epoch 25/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0778 - accuracy: 0.3733 - val_loss: 2.3508 - val_accuracy: 0.2846\n",
      "Epoch 26/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0733 - accuracy: 0.3756 - val_loss: 2.3331 - val_accuracy: 0.2901\n",
      "Epoch 27/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0679 - accuracy: 0.3764 - val_loss: 2.3386 - val_accuracy: 0.2892\n",
      "Epoch 28/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0616 - accuracy: 0.3778 - val_loss: 2.3587 - val_accuracy: 0.2825\n",
      "Epoch 29/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0595 - accuracy: 0.3795 - val_loss: 2.3393 - val_accuracy: 0.2884\n",
      "Epoch 30/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0525 - accuracy: 0.3804 - val_loss: 2.3355 - val_accuracy: 0.2917\n",
      "Epoch 31/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0492 - accuracy: 0.3821 - val_loss: 2.3280 - val_accuracy: 0.2929\n",
      "Epoch 32/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0471 - accuracy: 0.3831 - val_loss: 2.3330 - val_accuracy: 0.2915\n",
      "Epoch 33/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0428 - accuracy: 0.3828 - val_loss: 2.3443 - val_accuracy: 0.2906\n",
      "Epoch 34/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0384 - accuracy: 0.3850 - val_loss: 2.3402 - val_accuracy: 0.2917\n",
      "Epoch 35/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0336 - accuracy: 0.3855 - val_loss: 2.3500 - val_accuracy: 0.2907\n",
      "Epoch 36/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 2.0315 - accuracy: 0.3862 - val_loss: 2.3359 - val_accuracy: 0.2915\n",
      "Epoch 37/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0296 - accuracy: 0.3873 - val_loss: 2.3422 - val_accuracy: 0.2881\n",
      "Epoch 38/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0258 - accuracy: 0.3887 - val_loss: 2.3415 - val_accuracy: 0.2891\n",
      "Epoch 39/110\n",
      "237150/237150 [==============================] - 2s 7us/sample - loss: 2.0205 - accuracy: 0.3900 - val_loss: 2.3422 - val_accuracy: 0.2896\n",
      "Epoch 40/110\n",
      "237150/237150 [==============================] - 2s 6us/sample - loss: 2.0184 - accuracy: 0.3904 - val_loss: 2.3527 - val_accuracy: 0.2884\n",
      "Epoch 41/110\n",
      "237150/237150 [==============================] - 2s 6us/sample - loss: 2.0147 - accuracy: 0.3918 - val_loss: 2.3483 - val_accuracy: 0.2904\n",
      "Epoch 42/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0126 - accuracy: 0.3924 - val_loss: 2.3708 - val_accuracy: 0.2858\n",
      "Epoch 43/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0106 - accuracy: 0.3923 - val_loss: 2.3460 - val_accuracy: 0.2895\n",
      "Epoch 44/110\n",
      "237150/237150 [==============================] - 2s 6us/sample - loss: 2.0092 - accuracy: 0.3928 - val_loss: 2.3362 - val_accuracy: 0.2900\n",
      "Epoch 45/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0035 - accuracy: 0.3950 - val_loss: 2.3431 - val_accuracy: 0.2908\n",
      "Epoch 46/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0029 - accuracy: 0.3946 - val_loss: 2.3344 - val_accuracy: 0.2920\n",
      "Epoch 47/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237150/237150 [==============================] - 1s 6us/sample - loss: 2.0004 - accuracy: 0.3954 - val_loss: 2.3362 - val_accuracy: 0.2904\n",
      "Epoch 48/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9964 - accuracy: 0.3958 - val_loss: 2.3510 - val_accuracy: 0.2895\n",
      "Epoch 49/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9954 - accuracy: 0.3965 - val_loss: 2.3576 - val_accuracy: 0.2868\n",
      "Epoch 50/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9947 - accuracy: 0.3967 - val_loss: 2.3359 - val_accuracy: 0.2910\n",
      "Epoch 51/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9922 - accuracy: 0.3976 - val_loss: 2.3426 - val_accuracy: 0.2926\n",
      "Epoch 52/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9871 - accuracy: 0.3992 - val_loss: 2.3574 - val_accuracy: 0.2865\n",
      "Epoch 53/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9850 - accuracy: 0.3991 - val_loss: 2.3338 - val_accuracy: 0.2941\n",
      "Epoch 54/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9861 - accuracy: 0.3989 - val_loss: 2.3588 - val_accuracy: 0.2869\n",
      "Epoch 55/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9821 - accuracy: 0.4009 - val_loss: 2.3578 - val_accuracy: 0.2877\n",
      "Epoch 56/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9800 - accuracy: 0.3996 - val_loss: 2.3544 - val_accuracy: 0.2921\n",
      "Epoch 57/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9802 - accuracy: 0.4008 - val_loss: 2.3448 - val_accuracy: 0.2913\n",
      "Epoch 58/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9776 - accuracy: 0.4027 - val_loss: 2.3490 - val_accuracy: 0.2901\n",
      "Epoch 59/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9743 - accuracy: 0.4028 - val_loss: 2.3665 - val_accuracy: 0.2856\n",
      "Epoch 60/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9731 - accuracy: 0.4035 - val_loss: 2.3434 - val_accuracy: 0.2890\n",
      "Epoch 61/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9705 - accuracy: 0.4030 - val_loss: 2.3444 - val_accuracy: 0.2929\n",
      "Epoch 62/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9685 - accuracy: 0.4037 - val_loss: 2.3524 - val_accuracy: 0.2910\n",
      "Epoch 63/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9677 - accuracy: 0.4046 - val_loss: 2.3383 - val_accuracy: 0.2914\n",
      "Epoch 64/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9655 - accuracy: 0.4052 - val_loss: 2.3429 - val_accuracy: 0.2926\n",
      "Epoch 65/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9644 - accuracy: 0.4059 - val_loss: 2.3471 - val_accuracy: 0.2919\n",
      "Epoch 66/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9648 - accuracy: 0.4063 - val_loss: 2.3458 - val_accuracy: 0.2909\n",
      "Epoch 67/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9624 - accuracy: 0.4056 - val_loss: 2.3414 - val_accuracy: 0.2902\n",
      "Epoch 68/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9590 - accuracy: 0.4071 - val_loss: 2.3394 - val_accuracy: 0.2925\n",
      "Epoch 69/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9577 - accuracy: 0.4078 - val_loss: 2.3480 - val_accuracy: 0.2883\n",
      "Epoch 70/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9562 - accuracy: 0.4087 - val_loss: 2.3537 - val_accuracy: 0.2872\n",
      "Epoch 71/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9547 - accuracy: 0.4072 - val_loss: 2.3622 - val_accuracy: 0.2890\n",
      "Epoch 72/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9526 - accuracy: 0.4092 - val_loss: 2.3679 - val_accuracy: 0.2899\n",
      "Epoch 73/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9516 - accuracy: 0.4091 - val_loss: 2.3514 - val_accuracy: 0.2929\n",
      "Epoch 74/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9508 - accuracy: 0.4098 - val_loss: 2.3555 - val_accuracy: 0.2867\n",
      "Epoch 75/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9508 - accuracy: 0.4092 - val_loss: 2.3505 - val_accuracy: 0.2906\n",
      "Epoch 76/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9484 - accuracy: 0.4092 - val_loss: 2.3560 - val_accuracy: 0.2903\n",
      "Epoch 77/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9475 - accuracy: 0.4108 - val_loss: 2.3570 - val_accuracy: 0.2892\n",
      "Epoch 78/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9450 - accuracy: 0.4106 - val_loss: 2.3524 - val_accuracy: 0.2890\n",
      "Epoch 79/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9414 - accuracy: 0.4124 - val_loss: 2.3514 - val_accuracy: 0.2938\n",
      "Epoch 80/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9459 - accuracy: 0.4113 - val_loss: 2.3513 - val_accuracy: 0.2921\n",
      "Epoch 81/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9435 - accuracy: 0.4124 - val_loss: 2.3573 - val_accuracy: 0.2877\n",
      "Epoch 82/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9404 - accuracy: 0.4124 - val_loss: 2.3438 - val_accuracy: 0.2951\n",
      "Epoch 83/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9396 - accuracy: 0.4127 - val_loss: 2.3504 - val_accuracy: 0.2927\n",
      "Epoch 84/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9377 - accuracy: 0.4139 - val_loss: 2.3685 - val_accuracy: 0.2867\n",
      "Epoch 85/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9381 - accuracy: 0.4135 - val_loss: 2.3474 - val_accuracy: 0.2928\n",
      "Epoch 86/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9375 - accuracy: 0.4138 - val_loss: 2.3809 - val_accuracy: 0.2862\n",
      "Epoch 87/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9367 - accuracy: 0.4135 - val_loss: 2.3444 - val_accuracy: 0.2940\n",
      "Epoch 88/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9333 - accuracy: 0.4146 - val_loss: 2.3606 - val_accuracy: 0.2897\n",
      "Epoch 89/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9342 - accuracy: 0.4146 - val_loss: 2.3467 - val_accuracy: 0.2935\n",
      "Epoch 90/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9324 - accuracy: 0.4146 - val_loss: 2.3487 - val_accuracy: 0.2920\n",
      "Epoch 91/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9322 - accuracy: 0.4157 - val_loss: 2.3631 - val_accuracy: 0.2872\n",
      "Epoch 92/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9287 - accuracy: 0.4160 - val_loss: 2.3569 - val_accuracy: 0.2929\n",
      "Epoch 93/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9271 - accuracy: 0.4157 - val_loss: 2.3465 - val_accuracy: 0.2905\n",
      "Epoch 94/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9280 - accuracy: 0.4160 - val_loss: 2.3447 - val_accuracy: 0.2938\n",
      "Epoch 95/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9264 - accuracy: 0.4175 - val_loss: 2.3563 - val_accuracy: 0.2904\n",
      "Epoch 96/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9252 - accuracy: 0.4175 - val_loss: 2.3712 - val_accuracy: 0.2891\n",
      "Epoch 97/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9260 - accuracy: 0.4171 - val_loss: 2.3690 - val_accuracy: 0.2867\n",
      "Epoch 98/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9227 - accuracy: 0.4173 - val_loss: 2.3614 - val_accuracy: 0.2894\n",
      "Epoch 99/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9228 - accuracy: 0.4171 - val_loss: 2.3550 - val_accuracy: 0.2926\n",
      "Epoch 100/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9233 - accuracy: 0.4169 - val_loss: 2.3574 - val_accuracy: 0.2899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9205 - accuracy: 0.4185 - val_loss: 2.3545 - val_accuracy: 0.2914\n",
      "Epoch 102/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9178 - accuracy: 0.4199 - val_loss: 2.3649 - val_accuracy: 0.2886\n",
      "Epoch 103/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9203 - accuracy: 0.4186 - val_loss: 2.3614 - val_accuracy: 0.2901\n",
      "Epoch 104/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9170 - accuracy: 0.4196 - val_loss: 2.3685 - val_accuracy: 0.2893\n",
      "Epoch 105/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9151 - accuracy: 0.4194 - val_loss: 2.3564 - val_accuracy: 0.2917\n",
      "Epoch 106/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9157 - accuracy: 0.4190 - val_loss: 2.3655 - val_accuracy: 0.2889\n",
      "Epoch 107/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9147 - accuracy: 0.4204 - val_loss: 2.3620 - val_accuracy: 0.2911\n",
      "Epoch 108/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9145 - accuracy: 0.4197 - val_loss: 2.3624 - val_accuracy: 0.2917\n",
      "Epoch 109/110\n",
      "237150/237150 [==============================] - 1s 5us/sample - loss: 1.9120 - accuracy: 0.4203 - val_loss: 2.3678 - val_accuracy: 0.2906\n",
      "Epoch 110/110\n",
      "237150/237150 [==============================] - 1s 6us/sample - loss: 1.9139 - accuracy: 0.4206 - val_loss: 2.3546 - val_accuracy: 0.2932\n",
      "Restoring the best weights from epoch 110\n",
      "Training fold 4\n",
      "Train on 237175 samples, validate on 35905 samples\n",
      "Epoch 1/110\n",
      "237175/237175 [==============================] - 2s 10us/sample - loss: 2.8567 - accuracy: 0.1473 - val_loss: 2.8255 - val_accuracy: 0.1588\n",
      "Epoch 2/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.5184 - accuracy: 0.2389 - val_loss: 2.5564 - val_accuracy: 0.2215\n",
      "Epoch 3/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.4249 - accuracy: 0.2672 - val_loss: 2.4913 - val_accuracy: 0.2344\n",
      "Epoch 4/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.3646 - accuracy: 0.2856 - val_loss: 2.4302 - val_accuracy: 0.2518\n",
      "Epoch 5/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.3147 - accuracy: 0.3003 - val_loss: 2.4121 - val_accuracy: 0.2609\n",
      "Epoch 6/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2805 - accuracy: 0.3117 - val_loss: 2.4070 - val_accuracy: 0.2636\n",
      "Epoch 7/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2518 - accuracy: 0.3202 - val_loss: 2.3885 - val_accuracy: 0.2659\n",
      "Epoch 8/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2335 - accuracy: 0.3266 - val_loss: 2.3765 - val_accuracy: 0.2700\n",
      "Epoch 9/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2146 - accuracy: 0.3310 - val_loss: 2.3764 - val_accuracy: 0.2719\n",
      "Epoch 10/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1997 - accuracy: 0.3355 - val_loss: 2.3717 - val_accuracy: 0.2753\n",
      "Epoch 11/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1849 - accuracy: 0.3404 - val_loss: 2.3872 - val_accuracy: 0.2725\n",
      "Epoch 12/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1737 - accuracy: 0.3446 - val_loss: 2.3597 - val_accuracy: 0.2800\n",
      "Epoch 13/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1601 - accuracy: 0.3489 - val_loss: 2.3741 - val_accuracy: 0.2763\n",
      "Epoch 14/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1512 - accuracy: 0.3504 - val_loss: 2.3486 - val_accuracy: 0.2841\n",
      "Epoch 15/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1408 - accuracy: 0.3532 - val_loss: 2.3453 - val_accuracy: 0.2837\n",
      "Epoch 16/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1299 - accuracy: 0.3572 - val_loss: 2.3629 - val_accuracy: 0.2801\n",
      "Epoch 17/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1232 - accuracy: 0.3590 - val_loss: 2.3585 - val_accuracy: 0.2826\n",
      "Epoch 18/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1146 - accuracy: 0.3620 - val_loss: 2.3456 - val_accuracy: 0.2861\n",
      "Epoch 19/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1081 - accuracy: 0.3629 - val_loss: 2.3513 - val_accuracy: 0.2844\n",
      "Epoch 20/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1011 - accuracy: 0.3650 - val_loss: 2.3621 - val_accuracy: 0.2790\n",
      "Epoch 21/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0961 - accuracy: 0.3667 - val_loss: 2.3510 - val_accuracy: 0.2807\n",
      "Epoch 22/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0878 - accuracy: 0.3693 - val_loss: 2.3431 - val_accuracy: 0.2843\n",
      "Epoch 23/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0844 - accuracy: 0.3702 - val_loss: 2.3622 - val_accuracy: 0.2833\n",
      "Epoch 24/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0788 - accuracy: 0.3714 - val_loss: 2.3619 - val_accuracy: 0.2831\n",
      "Epoch 25/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0737 - accuracy: 0.3740 - val_loss: 2.3587 - val_accuracy: 0.2844\n",
      "Epoch 26/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0678 - accuracy: 0.3757 - val_loss: 2.3520 - val_accuracy: 0.2811\n",
      "Epoch 27/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0632 - accuracy: 0.3758 - val_loss: 2.3523 - val_accuracy: 0.2851\n",
      "Epoch 28/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0590 - accuracy: 0.3776 - val_loss: 2.3390 - val_accuracy: 0.2857\n",
      "Epoch 29/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0546 - accuracy: 0.3795 - val_loss: 2.3497 - val_accuracy: 0.2873\n",
      "Epoch 30/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0509 - accuracy: 0.3806 - val_loss: 2.3614 - val_accuracy: 0.2839\n",
      "Epoch 31/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0452 - accuracy: 0.3813 - val_loss: 2.3558 - val_accuracy: 0.2832\n",
      "Epoch 32/110\n",
      "237175/237175 [==============================] - 2s 6us/sample - loss: 2.0435 - accuracy: 0.3815 - val_loss: 2.3453 - val_accuracy: 0.2859\n",
      "Epoch 33/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0394 - accuracy: 0.3831 - val_loss: 2.3503 - val_accuracy: 0.2854\n",
      "Epoch 34/110\n",
      "237175/237175 [==============================] - 2s 7us/sample - loss: 2.0347 - accuracy: 0.3848 - val_loss: 2.3406 - val_accuracy: 0.2858\n",
      "Epoch 35/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0334 - accuracy: 0.3849 - val_loss: 2.3444 - val_accuracy: 0.2902\n",
      "Epoch 36/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0271 - accuracy: 0.3878 - val_loss: 2.3456 - val_accuracy: 0.2893\n",
      "Epoch 37/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0267 - accuracy: 0.3856 - val_loss: 2.3498 - val_accuracy: 0.2880\n",
      "Epoch 38/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0225 - accuracy: 0.3888 - val_loss: 2.3493 - val_accuracy: 0.2899\n",
      "Epoch 39/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0199 - accuracy: 0.3891 - val_loss: 2.3645 - val_accuracy: 0.2838\n",
      "Epoch 40/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0167 - accuracy: 0.3898 - val_loss: 2.3485 - val_accuracy: 0.2878\n",
      "Epoch 41/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0146 - accuracy: 0.3906 - val_loss: 2.3569 - val_accuracy: 0.2882\n",
      "Epoch 42/110\n",
      "237175/237175 [==============================] - 2s 7us/sample - loss: 2.0106 - accuracy: 0.3917 - val_loss: 2.3505 - val_accuracy: 0.2885\n",
      "Epoch 43/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0098 - accuracy: 0.3924 - val_loss: 2.3471 - val_accuracy: 0.2865\n",
      "Epoch 44/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0078 - accuracy: 0.3928 - val_loss: 2.3540 - val_accuracy: 0.2863\n",
      "Epoch 45/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0021 - accuracy: 0.3951 - val_loss: 2.3536 - val_accuracy: 0.2847\n",
      "Epoch 46/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 2.0012 - accuracy: 0.3954 - val_loss: 2.3496 - val_accuracy: 0.2871\n",
      "Epoch 47/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0017 - accuracy: 0.3942 - val_loss: 2.3565 - val_accuracy: 0.2848\n",
      "Epoch 48/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9954 - accuracy: 0.3965 - val_loss: 2.3581 - val_accuracy: 0.2863\n",
      "Epoch 49/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9944 - accuracy: 0.3967 - val_loss: 2.3506 - val_accuracy: 0.2875\n",
      "Epoch 50/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9938 - accuracy: 0.3973 - val_loss: 2.3501 - val_accuracy: 0.2866\n",
      "Epoch 51/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9899 - accuracy: 0.3971 - val_loss: 2.3579 - val_accuracy: 0.2868\n",
      "Epoch 52/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9886 - accuracy: 0.3975 - val_loss: 2.3736 - val_accuracy: 0.2819\n",
      "Epoch 53/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9877 - accuracy: 0.3986 - val_loss: 2.3500 - val_accuracy: 0.2874\n",
      "Epoch 54/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9848 - accuracy: 0.3999 - val_loss: 2.3416 - val_accuracy: 0.2871\n",
      "Epoch 55/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9814 - accuracy: 0.3999 - val_loss: 2.3659 - val_accuracy: 0.2827\n",
      "Epoch 56/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9805 - accuracy: 0.4005 - val_loss: 2.3581 - val_accuracy: 0.2846\n",
      "Epoch 57/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9809 - accuracy: 0.4006 - val_loss: 2.3518 - val_accuracy: 0.2869\n",
      "Epoch 58/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9762 - accuracy: 0.4020 - val_loss: 2.3586 - val_accuracy: 0.2839\n",
      "Epoch 59/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9752 - accuracy: 0.4012 - val_loss: 2.3559 - val_accuracy: 0.2845\n",
      "Epoch 60/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9734 - accuracy: 0.4036 - val_loss: 2.3540 - val_accuracy: 0.2852\n",
      "Epoch 61/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9709 - accuracy: 0.4031 - val_loss: 2.3653 - val_accuracy: 0.2867\n",
      "Epoch 62/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9727 - accuracy: 0.4020 - val_loss: 2.3512 - val_accuracy: 0.2833\n",
      "Epoch 63/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9682 - accuracy: 0.4054 - val_loss: 2.3481 - val_accuracy: 0.2893\n",
      "Epoch 64/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9640 - accuracy: 0.4058 - val_loss: 2.3548 - val_accuracy: 0.2872\n",
      "Epoch 65/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9628 - accuracy: 0.4054 - val_loss: 2.3494 - val_accuracy: 0.2883\n",
      "Epoch 66/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9650 - accuracy: 0.4048 - val_loss: 2.3593 - val_accuracy: 0.2878\n",
      "Epoch 67/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9626 - accuracy: 0.4053 - val_loss: 2.3559 - val_accuracy: 0.2870\n",
      "Epoch 68/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9588 - accuracy: 0.4075 - val_loss: 2.3641 - val_accuracy: 0.2853\n",
      "Epoch 69/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9564 - accuracy: 0.4064 - val_loss: 2.3447 - val_accuracy: 0.2897\n",
      "Epoch 70/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9585 - accuracy: 0.4068 - val_loss: 2.3501 - val_accuracy: 0.2873\n",
      "Epoch 71/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9570 - accuracy: 0.4078 - val_loss: 2.3477 - val_accuracy: 0.2852\n",
      "Epoch 72/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9555 - accuracy: 0.4070 - val_loss: 2.3639 - val_accuracy: 0.2841\n",
      "Epoch 73/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9558 - accuracy: 0.4084 - val_loss: 2.3628 - val_accuracy: 0.2861\n",
      "Epoch 74/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9537 - accuracy: 0.4086 - val_loss: 2.3594 - val_accuracy: 0.2854\n",
      "Epoch 75/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9507 - accuracy: 0.4096 - val_loss: 2.3665 - val_accuracy: 0.2839\n",
      "Epoch 76/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9476 - accuracy: 0.4102 - val_loss: 2.3677 - val_accuracy: 0.2846\n",
      "Epoch 77/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9468 - accuracy: 0.4108 - val_loss: 2.3567 - val_accuracy: 0.2875\n",
      "Epoch 78/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9471 - accuracy: 0.4094 - val_loss: 2.3506 - val_accuracy: 0.2862\n",
      "Epoch 79/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9445 - accuracy: 0.4107 - val_loss: 2.3557 - val_accuracy: 0.2836\n",
      "Epoch 80/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9447 - accuracy: 0.4109 - val_loss: 2.3530 - val_accuracy: 0.2847\n",
      "Epoch 81/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9420 - accuracy: 0.4119 - val_loss: 2.3548 - val_accuracy: 0.2872\n",
      "Epoch 82/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9422 - accuracy: 0.4118 - val_loss: 2.3697 - val_accuracy: 0.2841\n",
      "Epoch 83/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9438 - accuracy: 0.4113 - val_loss: 2.3665 - val_accuracy: 0.2841\n",
      "Epoch 84/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9391 - accuracy: 0.4124 - val_loss: 2.3591 - val_accuracy: 0.2858\n",
      "Epoch 85/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9392 - accuracy: 0.4122 - val_loss: 2.3549 - val_accuracy: 0.2891\n",
      "Epoch 86/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9366 - accuracy: 0.4131 - val_loss: 2.3549 - val_accuracy: 0.2875\n",
      "Epoch 87/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9352 - accuracy: 0.4132 - val_loss: 2.3624 - val_accuracy: 0.2852\n",
      "Epoch 88/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9370 - accuracy: 0.4134 - val_loss: 2.3567 - val_accuracy: 0.2857\n",
      "Epoch 89/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9324 - accuracy: 0.4144 - val_loss: 2.3596 - val_accuracy: 0.2856\n",
      "Epoch 90/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9331 - accuracy: 0.4138 - val_loss: 2.3544 - val_accuracy: 0.2849\n",
      "Epoch 91/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9318 - accuracy: 0.4140 - val_loss: 2.3496 - val_accuracy: 0.2873\n",
      "Epoch 92/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9305 - accuracy: 0.4146 - val_loss: 2.3619 - val_accuracy: 0.2859\n",
      "Epoch 93/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9296 - accuracy: 0.4151 - val_loss: 2.3639 - val_accuracy: 0.2833\n",
      "Epoch 94/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9294 - accuracy: 0.4144 - val_loss: 2.3663 - val_accuracy: 0.2842\n",
      "Epoch 95/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9301 - accuracy: 0.4159 - val_loss: 2.3640 - val_accuracy: 0.2858\n",
      "Epoch 96/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9259 - accuracy: 0.4166 - val_loss: 2.3805 - val_accuracy: 0.2836\n",
      "Epoch 97/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9264 - accuracy: 0.4167 - val_loss: 2.3483 - val_accuracy: 0.2891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9259 - accuracy: 0.4158 - val_loss: 2.3537 - val_accuracy: 0.2861\n",
      "Epoch 99/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9229 - accuracy: 0.4171 - val_loss: 2.3678 - val_accuracy: 0.2844\n",
      "Epoch 100/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9235 - accuracy: 0.4173 - val_loss: 2.3672 - val_accuracy: 0.2872\n",
      "Epoch 101/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9206 - accuracy: 0.4172 - val_loss: 2.3617 - val_accuracy: 0.2859\n",
      "Epoch 102/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9186 - accuracy: 0.4184 - val_loss: 2.3681 - val_accuracy: 0.2870\n",
      "Epoch 103/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9202 - accuracy: 0.4176 - val_loss: 2.3653 - val_accuracy: 0.2846\n",
      "Epoch 104/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9173 - accuracy: 0.4186 - val_loss: 2.3619 - val_accuracy: 0.2863\n",
      "Epoch 105/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9191 - accuracy: 0.4185 - val_loss: 2.3723 - val_accuracy: 0.2830\n",
      "Epoch 106/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9165 - accuracy: 0.4188 - val_loss: 2.3715 - val_accuracy: 0.2847\n",
      "Epoch 107/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9176 - accuracy: 0.4186 - val_loss: 2.3669 - val_accuracy: 0.2846\n",
      "Epoch 108/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9155 - accuracy: 0.4189 - val_loss: 2.3787 - val_accuracy: 0.2839\n",
      "Epoch 109/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9170 - accuracy: 0.4188 - val_loss: 2.3565 - val_accuracy: 0.2836\n",
      "Epoch 110/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9134 - accuracy: 0.4203 - val_loss: 2.3685 - val_accuracy: 0.2847\n",
      "Restoring the best weights from epoch 110\n",
      "Training fold 5\n",
      "Train on 237175 samples, validate on 35903 samples\n",
      "Epoch 1/110\n",
      "237175/237175 [==============================] - 3s 11us/sample - loss: 2.8621 - accuracy: 0.1410 - val_loss: 2.8053 - val_accuracy: 0.1791\n",
      "Epoch 2/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.5251 - accuracy: 0.2331 - val_loss: 2.5365 - val_accuracy: 0.2296\n",
      "Epoch 3/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.4315 - accuracy: 0.2651 - val_loss: 2.4755 - val_accuracy: 0.2442\n",
      "Epoch 4/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.3705 - accuracy: 0.2846 - val_loss: 2.4339 - val_accuracy: 0.2543\n",
      "Epoch 5/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.3271 - accuracy: 0.2969 - val_loss: 2.4087 - val_accuracy: 0.2622\n",
      "Epoch 6/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2960 - accuracy: 0.3062 - val_loss: 2.3953 - val_accuracy: 0.2631\n",
      "Epoch 7/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2684 - accuracy: 0.3144 - val_loss: 2.3798 - val_accuracy: 0.2684\n",
      "Epoch 8/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2467 - accuracy: 0.3222 - val_loss: 2.3663 - val_accuracy: 0.2734\n",
      "Epoch 9/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2276 - accuracy: 0.3259 - val_loss: 2.3777 - val_accuracy: 0.2710\n",
      "Epoch 10/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.2113 - accuracy: 0.3325 - val_loss: 2.3690 - val_accuracy: 0.2741\n",
      "Epoch 11/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1967 - accuracy: 0.3363 - val_loss: 2.3739 - val_accuracy: 0.2724\n",
      "Epoch 12/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1840 - accuracy: 0.3403 - val_loss: 2.3817 - val_accuracy: 0.2688\n",
      "Epoch 13/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1719 - accuracy: 0.3442 - val_loss: 2.3547 - val_accuracy: 0.2806\n",
      "Epoch 14/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1604 - accuracy: 0.3466 - val_loss: 2.3564 - val_accuracy: 0.2787\n",
      "Epoch 15/110\n",
      "237175/237175 [==============================] - 2s 6us/sample - loss: 2.1514 - accuracy: 0.3507 - val_loss: 2.3539 - val_accuracy: 0.2840\n",
      "Epoch 16/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1426 - accuracy: 0.3530 - val_loss: 2.3611 - val_accuracy: 0.2756\n",
      "Epoch 17/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1341 - accuracy: 0.3552 - val_loss: 2.3270 - val_accuracy: 0.2873\n",
      "Epoch 18/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1258 - accuracy: 0.3572 - val_loss: 2.3327 - val_accuracy: 0.2861\n",
      "Epoch 19/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1188 - accuracy: 0.3594 - val_loss: 2.3590 - val_accuracy: 0.2807\n",
      "Epoch 20/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1133 - accuracy: 0.3623 - val_loss: 2.3634 - val_accuracy: 0.2788\n",
      "Epoch 21/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.1058 - accuracy: 0.3638 - val_loss: 2.3457 - val_accuracy: 0.2837\n",
      "Epoch 22/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0991 - accuracy: 0.3655 - val_loss: 2.3542 - val_accuracy: 0.2851\n",
      "Epoch 23/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0958 - accuracy: 0.3672 - val_loss: 2.3355 - val_accuracy: 0.2880\n",
      "Epoch 24/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0889 - accuracy: 0.3688 - val_loss: 2.3299 - val_accuracy: 0.2867\n",
      "Epoch 25/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0852 - accuracy: 0.3688 - val_loss: 2.3235 - val_accuracy: 0.2901\n",
      "Epoch 26/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0784 - accuracy: 0.3719 - val_loss: 2.3317 - val_accuracy: 0.2877\n",
      "Epoch 27/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0735 - accuracy: 0.3734 - val_loss: 2.3352 - val_accuracy: 0.2833\n",
      "Epoch 28/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0662 - accuracy: 0.3748 - val_loss: 2.3191 - val_accuracy: 0.2879\n",
      "Epoch 29/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0638 - accuracy: 0.3759 - val_loss: 2.3451 - val_accuracy: 0.2812\n",
      "Epoch 30/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0597 - accuracy: 0.3772 - val_loss: 2.3382 - val_accuracy: 0.2855\n",
      "Epoch 31/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0566 - accuracy: 0.3782 - val_loss: 2.3408 - val_accuracy: 0.2855\n",
      "Epoch 32/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 2.0522 - accuracy: 0.3804 - val_loss: 2.3459 - val_accuracy: 0.2884\n",
      "Epoch 33/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0501 - accuracy: 0.3797 - val_loss: 2.3369 - val_accuracy: 0.2861\n",
      "Epoch 34/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0448 - accuracy: 0.3812 - val_loss: 2.3420 - val_accuracy: 0.2858\n",
      "Epoch 35/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0424 - accuracy: 0.3816 - val_loss: 2.3313 - val_accuracy: 0.2902\n",
      "Epoch 36/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0374 - accuracy: 0.3833 - val_loss: 2.3445 - val_accuracy: 0.2865\n",
      "Epoch 37/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0347 - accuracy: 0.3834 - val_loss: 2.3479 - val_accuracy: 0.2872\n",
      "Epoch 38/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0317 - accuracy: 0.3842 - val_loss: 2.3440 - val_accuracy: 0.2852\n",
      "Epoch 39/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0294 - accuracy: 0.3853 - val_loss: 2.3343 - val_accuracy: 0.2871\n",
      "Epoch 40/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0289 - accuracy: 0.3867 - val_loss: 2.3434 - val_accuracy: 0.2853\n",
      "Epoch 41/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0248 - accuracy: 0.3874 - val_loss: 2.3342 - val_accuracy: 0.2863\n",
      "Epoch 42/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0203 - accuracy: 0.3887 - val_loss: 2.3230 - val_accuracy: 0.2887\n",
      "Epoch 43/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0177 - accuracy: 0.3891 - val_loss: 2.3384 - val_accuracy: 0.2909\n",
      "Epoch 44/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0153 - accuracy: 0.3908 - val_loss: 2.3532 - val_accuracy: 0.2853\n",
      "Epoch 45/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0125 - accuracy: 0.3906 - val_loss: 2.3377 - val_accuracy: 0.2884\n",
      "Epoch 46/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0091 - accuracy: 0.3921 - val_loss: 2.3403 - val_accuracy: 0.2892\n",
      "Epoch 47/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0058 - accuracy: 0.3923 - val_loss: 2.3444 - val_accuracy: 0.2903\n",
      "Epoch 48/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0039 - accuracy: 0.3933 - val_loss: 2.3285 - val_accuracy: 0.2887\n",
      "Epoch 49/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0008 - accuracy: 0.3945 - val_loss: 2.3340 - val_accuracy: 0.2906\n",
      "Epoch 50/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 2.0013 - accuracy: 0.3947 - val_loss: 2.3368 - val_accuracy: 0.2911\n",
      "Epoch 51/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9947 - accuracy: 0.3965 - val_loss: 2.3479 - val_accuracy: 0.2886\n",
      "Epoch 52/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9951 - accuracy: 0.3959 - val_loss: 2.3481 - val_accuracy: 0.2864\n",
      "Epoch 53/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9925 - accuracy: 0.3970 - val_loss: 2.3282 - val_accuracy: 0.2911\n",
      "Epoch 54/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9926 - accuracy: 0.3968 - val_loss: 2.3381 - val_accuracy: 0.2894\n",
      "Epoch 55/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9878 - accuracy: 0.3980 - val_loss: 2.3378 - val_accuracy: 0.2895\n",
      "Epoch 56/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9879 - accuracy: 0.3982 - val_loss: 2.3346 - val_accuracy: 0.2921\n",
      "Epoch 57/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9844 - accuracy: 0.3996 - val_loss: 2.3515 - val_accuracy: 0.2898\n",
      "Epoch 58/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9845 - accuracy: 0.3999 - val_loss: 2.3405 - val_accuracy: 0.2895\n",
      "Epoch 59/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9818 - accuracy: 0.3999 - val_loss: 2.3452 - val_accuracy: 0.2892\n",
      "Epoch 60/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9798 - accuracy: 0.4010 - val_loss: 2.3412 - val_accuracy: 0.2892\n",
      "Epoch 61/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9765 - accuracy: 0.4009 - val_loss: 2.3464 - val_accuracy: 0.2897\n",
      "Epoch 62/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9759 - accuracy: 0.4017 - val_loss: 2.3303 - val_accuracy: 0.2911\n",
      "Epoch 63/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9740 - accuracy: 0.4026 - val_loss: 2.3393 - val_accuracy: 0.2898\n",
      "Epoch 64/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9747 - accuracy: 0.4030 - val_loss: 2.3449 - val_accuracy: 0.2843\n",
      "Epoch 65/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9709 - accuracy: 0.4034 - val_loss: 2.3457 - val_accuracy: 0.2908\n",
      "Epoch 66/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9719 - accuracy: 0.4026 - val_loss: 2.3361 - val_accuracy: 0.2906\n",
      "Epoch 67/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9656 - accuracy: 0.4046 - val_loss: 2.3425 - val_accuracy: 0.2903\n",
      "Epoch 68/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9699 - accuracy: 0.4041 - val_loss: 2.3431 - val_accuracy: 0.2885\n",
      "Epoch 69/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9652 - accuracy: 0.4045 - val_loss: 2.3332 - val_accuracy: 0.2908\n",
      "Epoch 70/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9634 - accuracy: 0.4052 - val_loss: 2.3566 - val_accuracy: 0.2908\n",
      "Epoch 71/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9627 - accuracy: 0.4063 - val_loss: 2.3332 - val_accuracy: 0.2891\n",
      "Epoch 72/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9603 - accuracy: 0.4061 - val_loss: 2.3297 - val_accuracy: 0.2945\n",
      "Epoch 73/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9599 - accuracy: 0.4067 - val_loss: 2.3262 - val_accuracy: 0.2923\n",
      "Epoch 74/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9601 - accuracy: 0.4069 - val_loss: 2.3477 - val_accuracy: 0.2883\n",
      "Epoch 75/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9573 - accuracy: 0.4074 - val_loss: 2.3416 - val_accuracy: 0.2922\n",
      "Epoch 76/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9564 - accuracy: 0.4076 - val_loss: 2.3510 - val_accuracy: 0.2871\n",
      "Epoch 77/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9541 - accuracy: 0.4079 - val_loss: 2.3392 - val_accuracy: 0.2894\n",
      "Epoch 78/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9520 - accuracy: 0.4095 - val_loss: 2.3335 - val_accuracy: 0.2924\n",
      "Epoch 79/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9497 - accuracy: 0.4103 - val_loss: 2.3450 - val_accuracy: 0.2903\n",
      "Epoch 80/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9501 - accuracy: 0.4094 - val_loss: 2.3400 - val_accuracy: 0.2907\n",
      "Epoch 81/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9503 - accuracy: 0.4096 - val_loss: 2.3294 - val_accuracy: 0.2976\n",
      "Epoch 82/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9480 - accuracy: 0.4101 - val_loss: 2.3387 - val_accuracy: 0.2925\n",
      "Epoch 83/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9481 - accuracy: 0.4111 - val_loss: 2.3375 - val_accuracy: 0.2918\n",
      "Epoch 84/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9445 - accuracy: 0.4119 - val_loss: 2.3318 - val_accuracy: 0.2913\n",
      "Epoch 85/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9453 - accuracy: 0.4109 - val_loss: 2.3489 - val_accuracy: 0.2905\n",
      "Epoch 86/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9430 - accuracy: 0.4111 - val_loss: 2.3309 - val_accuracy: 0.2926\n",
      "Epoch 87/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9417 - accuracy: 0.4131 - val_loss: 2.3317 - val_accuracy: 0.2911\n",
      "Epoch 88/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9398 - accuracy: 0.4130 - val_loss: 2.3488 - val_accuracy: 0.2899\n",
      "Epoch 89/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9400 - accuracy: 0.4129 - val_loss: 2.3462 - val_accuracy: 0.2882\n",
      "Epoch 90/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9382 - accuracy: 0.4124 - val_loss: 2.3427 - val_accuracy: 0.2922\n",
      "Epoch 91/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9374 - accuracy: 0.4132 - val_loss: 2.3451 - val_accuracy: 0.2919\n",
      "Epoch 92/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9374 - accuracy: 0.4135 - val_loss: 2.3513 - val_accuracy: 0.2891\n",
      "Epoch 93/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9379 - accuracy: 0.4133 - val_loss: 2.3381 - val_accuracy: 0.2925\n",
      "Epoch 94/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9335 - accuracy: 0.4144 - val_loss: 2.3572 - val_accuracy: 0.2882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9351 - accuracy: 0.4150 - val_loss: 2.3489 - val_accuracy: 0.2917\n",
      "Epoch 96/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9332 - accuracy: 0.4150 - val_loss: 2.3368 - val_accuracy: 0.2924\n",
      "Epoch 97/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9315 - accuracy: 0.4149 - val_loss: 2.3450 - val_accuracy: 0.2904\n",
      "Epoch 98/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9317 - accuracy: 0.4159 - val_loss: 2.3521 - val_accuracy: 0.2893\n",
      "Epoch 99/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9298 - accuracy: 0.4162 - val_loss: 2.3464 - val_accuracy: 0.2888\n",
      "Epoch 100/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9297 - accuracy: 0.4159 - val_loss: 2.3715 - val_accuracy: 0.2883\n",
      "Epoch 101/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9278 - accuracy: 0.4161 - val_loss: 2.3386 - val_accuracy: 0.2893\n",
      "Epoch 102/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9255 - accuracy: 0.4172 - val_loss: 2.3524 - val_accuracy: 0.2856\n",
      "Epoch 103/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9282 - accuracy: 0.4163 - val_loss: 2.3507 - val_accuracy: 0.2880\n",
      "Epoch 104/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9260 - accuracy: 0.4164 - val_loss: 2.3504 - val_accuracy: 0.2886\n",
      "Epoch 105/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9229 - accuracy: 0.4188 - val_loss: 2.3539 - val_accuracy: 0.2894\n",
      "Epoch 106/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9216 - accuracy: 0.4185 - val_loss: 2.3358 - val_accuracy: 0.2913\n",
      "Epoch 107/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9223 - accuracy: 0.4183 - val_loss: 2.3561 - val_accuracy: 0.2908\n",
      "Epoch 108/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9227 - accuracy: 0.4182 - val_loss: 2.3544 - val_accuracy: 0.2886\n",
      "Epoch 109/110\n",
      "237175/237175 [==============================] - 1s 6us/sample - loss: 1.9201 - accuracy: 0.4180 - val_loss: 2.3551 - val_accuracy: 0.2911\n",
      "Epoch 110/110\n",
      "237175/237175 [==============================] - 1s 5us/sample - loss: 1.9215 - accuracy: 0.4187 - val_loss: 2.3471 - val_accuracy: 0.2864\n",
      "Restoring the best weights from epoch 110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_micro</th>\n",
       "      <td>0.289065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_macro</th>\n",
       "      <td>0.280182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_accuracy</th>\n",
       "      <td>0.289065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_batch_val_accuracy</th>\n",
       "      <td>0.289064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_accuracy</th>\n",
       "      <td>0.384283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_loss</th>\n",
       "      <td>2.331053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loss</th>\n",
       "      <td>2.037084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>1553.272688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "avg_val_f1_micro           0.289065\n",
       "avg_val_f1_macro           0.280182\n",
       "avg_val_accuracy           0.289065\n",
       "avg_batch_val_accuracy     0.289064\n",
       "avg_accuracy               0.384283\n",
       "avg_val_loss               2.331053\n",
       "avg_loss                   2.037084\n",
       "train_time              1553.272688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_fold(x_train, y_train, x_val, y_val, run_name, fold=None):\n",
    "\n",
    "    input_shape = x_train[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_val = to_categorical(y_val)\n",
    "    \n",
    "    # Resample the train data to overcome imbalance\n",
    "    x_train_resampl, y_train_resampl = SMOTE().fit_resample(x_train, y_train)\n",
    "    \n",
    "    if fold is not None:\n",
    "        run_name += '_fold' + str(fold)\n",
    "        print('Training fold ' + str(fold))\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    weight_restorer = BestWeightsRestorer(monitor='val_loss', mode='min', verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=x_train_resampl,\n",
    "        y=y_train_resampl,\n",
    "        validation_data=[x_val, y_val],\n",
    "        epochs=110,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board, weight_restorer],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    prob_predictions = model.predict(x_val)\n",
    "    predictions = prob_predictions.argmax(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "experiment_number += 1\n",
    "run_name = 'base_mlp_marsyas_cv_balanced_' + str(experiment_number)\n",
    "\n",
    "results = resultsUtil.cross_validate(\n",
    "    x=ftrs,\n",
    "    y=lbl_encoded_lbls,\n",
    "    n_splits=5,\n",
    "    train_func=train_fold,\n",
    "    run_name=run_name\n",
    ")\n",
    "\n",
    "runUtil.save_run_results(run_name, results)\n",
    "\n",
    "resultsdf = pd.DataFrame([results]).transpose()\n",
    "\n",
    "display(resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs_resampl, lbls_resampl = SMOTE().fit_resample(ftrs, lbl_encoded_lbls)\n",
    "lbls_resampl_oh = one_hot_labels(lbls_resampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "179555/179555 [==============================] - 3s 14us/sample - loss: 2.9494 - accuracy: 0.1338\n",
      "Epoch 2/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.6211 - accuracy: 0.2082\n",
      "Epoch 3/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.5307 - accuracy: 0.2327\n",
      "Epoch 4/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.4850 - accuracy: 0.2468\n",
      "Epoch 5/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.4536 - accuracy: 0.2559\n",
      "Epoch 6/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.4280 - accuracy: 0.2642\n",
      "Epoch 7/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.4047 - accuracy: 0.2713\n",
      "Epoch 8/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3850 - accuracy: 0.2749\n",
      "Epoch 9/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3698 - accuracy: 0.2777\n",
      "Epoch 10/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3548 - accuracy: 0.2830\n",
      "Epoch 11/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3424 - accuracy: 0.2857\n",
      "Epoch 12/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3321 - accuracy: 0.2891\n",
      "Epoch 13/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3226 - accuracy: 0.2910\n",
      "Epoch 14/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3153 - accuracy: 0.2934\n",
      "Epoch 15/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.3071 - accuracy: 0.2938\n",
      "Epoch 16/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2995 - accuracy: 0.2961\n",
      "Epoch 17/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2965 - accuracy: 0.2972\n",
      "Epoch 18/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2922 - accuracy: 0.2984\n",
      "Epoch 19/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2850 - accuracy: 0.3007\n",
      "Epoch 20/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2802 - accuracy: 0.3017\n",
      "Epoch 21/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2762 - accuracy: 0.3024\n",
      "Epoch 22/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2718 - accuracy: 0.3041\n",
      "Epoch 23/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2664 - accuracy: 0.3060\n",
      "Epoch 24/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2641 - accuracy: 0.3070\n",
      "Epoch 25/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2600 - accuracy: 0.3079\n",
      "Epoch 26/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2566 - accuracy: 0.3084\n",
      "Epoch 27/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2520 - accuracy: 0.3095\n",
      "Epoch 28/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2485 - accuracy: 0.3100\n",
      "Epoch 29/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2464 - accuracy: 0.3100\n",
      "Epoch 30/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2464 - accuracy: 0.3107\n",
      "Epoch 31/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2422 - accuracy: 0.3124\n",
      "Epoch 32/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2356 - accuracy: 0.3139\n",
      "Epoch 33/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2341 - accuracy: 0.3134\n",
      "Epoch 34/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2322 - accuracy: 0.3145\n",
      "Epoch 35/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2301 - accuracy: 0.3155\n",
      "Epoch 36/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2273 - accuracy: 0.3162\n",
      "Epoch 37/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2235 - accuracy: 0.3176\n",
      "Epoch 38/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2219 - accuracy: 0.3177\n",
      "Epoch 39/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2231 - accuracy: 0.3175\n",
      "Epoch 40/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2191 - accuracy: 0.3176\n",
      "Epoch 41/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2162 - accuracy: 0.3190\n",
      "Epoch 42/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2152 - accuracy: 0.3189\n",
      "Epoch 43/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2121 - accuracy: 0.3218\n",
      "Epoch 44/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2092 - accuracy: 0.3213\n",
      "Epoch 45/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2102 - accuracy: 0.3206\n",
      "Epoch 46/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2066 - accuracy: 0.3213\n",
      "Epoch 47/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2067 - accuracy: 0.3211\n",
      "Epoch 48/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2024 - accuracy: 0.3230\n",
      "Epoch 49/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.2019 - accuracy: 0.3228\n",
      "Epoch 50/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1998 - accuracy: 0.3243\n",
      "Epoch 51/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1978 - accuracy: 0.3235\n",
      "Epoch 52/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1953 - accuracy: 0.3243\n",
      "Epoch 53/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1938 - accuracy: 0.3257\n",
      "Epoch 54/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1950 - accuracy: 0.3251\n",
      "Epoch 55/110\n",
      "179555/179555 [==============================] - 1s 8us/sample - loss: 2.1924 - accuracy: 0.3258\n",
      "Epoch 56/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1912 - accuracy: 0.3253\n",
      "Epoch 57/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1913 - accuracy: 0.3254\n",
      "Epoch 58/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1868 - accuracy: 0.3273\n",
      "Epoch 59/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1878 - accuracy: 0.3272\n",
      "Epoch 60/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1863 - accuracy: 0.3277\n",
      "Epoch 61/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1841 - accuracy: 0.3271\n",
      "Epoch 62/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1825 - accuracy: 0.3284\n",
      "Epoch 63/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1801 - accuracy: 0.3281\n",
      "Epoch 64/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1811 - accuracy: 0.3306\n",
      "Epoch 65/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1773 - accuracy: 0.3295\n",
      "Epoch 66/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1765 - accuracy: 0.3306\n",
      "Epoch 67/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1752 - accuracy: 0.3299\n",
      "Epoch 68/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1739 - accuracy: 0.3301\n",
      "Epoch 69/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1741 - accuracy: 0.3304\n",
      "Epoch 70/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1729 - accuracy: 0.3311\n",
      "Epoch 71/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1709 - accuracy: 0.3316\n",
      "Epoch 72/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1710 - accuracy: 0.3311\n",
      "Epoch 73/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1680 - accuracy: 0.3324\n",
      "Epoch 74/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1687 - accuracy: 0.3326\n",
      "Epoch 75/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1675 - accuracy: 0.3328\n",
      "Epoch 76/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1661 - accuracy: 0.3321\n",
      "Epoch 77/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1644 - accuracy: 0.3318\n",
      "Epoch 78/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1651 - accuracy: 0.3327\n",
      "Epoch 79/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1638 - accuracy: 0.3332\n",
      "Epoch 80/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1597 - accuracy: 0.3344\n",
      "Epoch 81/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1618 - accuracy: 0.3341\n",
      "Epoch 82/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1590 - accuracy: 0.3355\n",
      "Epoch 83/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1607 - accuracy: 0.3336\n",
      "Epoch 84/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1569 - accuracy: 0.3348\n",
      "Epoch 85/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1558 - accuracy: 0.3346\n",
      "Epoch 86/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1561 - accuracy: 0.3347\n",
      "Epoch 87/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1552 - accuracy: 0.3357\n",
      "Epoch 88/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1538 - accuracy: 0.3351\n",
      "Epoch 89/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1519 - accuracy: 0.3373\n",
      "Epoch 90/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1517 - accuracy: 0.3361\n",
      "Epoch 91/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1513 - accuracy: 0.3375\n",
      "Epoch 92/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1508 - accuracy: 0.3368\n",
      "Epoch 93/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1507 - accuracy: 0.3367\n",
      "Epoch 94/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1506 - accuracy: 0.3371\n",
      "Epoch 95/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1473 - accuracy: 0.3381\n",
      "Epoch 96/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1472 - accuracy: 0.3378\n",
      "Epoch 97/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1456 - accuracy: 0.3371\n",
      "Epoch 98/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1461 - accuracy: 0.3378\n",
      "Epoch 99/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1439 - accuracy: 0.3390\n",
      "Epoch 100/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1425 - accuracy: 0.3390\n",
      "Epoch 101/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1442 - accuracy: 0.3388\n",
      "Epoch 102/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1418 - accuracy: 0.3382\n",
      "Epoch 103/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1414 - accuracy: 0.3383\n",
      "Epoch 104/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1419 - accuracy: 0.3395\n",
      "Epoch 105/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1384 - accuracy: 0.3400\n",
      "Epoch 106/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1401 - accuracy: 0.3387\n",
      "Epoch 107/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1393 - accuracy: 0.3396\n",
      "Epoch 108/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1398 - accuracy: 0.3411\n",
      "Epoch 109/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1367 - accuracy: 0.3401\n",
      "Epoch 110/110\n",
      "179555/179555 [==============================] - 1s 7us/sample - loss: 2.1345 - accuracy: 0.3410\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(x, y, run_name):\n",
    "    \n",
    "    save_path = constants.MODELS_PATH + run_name + '.h5' \n",
    "    \n",
    "    input_shape = x[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    \n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        epochs=110,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.save(save_path)\n",
    "\n",
    "\n",
    "train_final_model(ftrs_resampl, lbls_resampl_oh, 'base_mlp_marsyas_final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
