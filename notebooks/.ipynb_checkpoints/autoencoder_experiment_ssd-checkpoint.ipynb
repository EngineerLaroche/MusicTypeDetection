{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 4 : Développement d’un système intelligent\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Laroche - LARA12078907<br>Marc-Antoine Charland - CHAM16059609<br>Jonathan Croteau-Dicaire - CROJ10109402    |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Été 2019                                            |\n",
    "| Groupe                | 02                                                      |\n",
    "| Numéro du laboratoire | TP-04                                                   |\n",
    "| Professeur            | Prof. Alessandro L. Koarich                             |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                                     |\n",
    "| Date                  | 5 août 2019 (23h55)                                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from src import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_set():\n",
    "\n",
    "    file_path = path.join(constants.RAW_TAGGED_FEATURE_SET_PATH, \"msd-ssd_dev/msd-ssd_dev.csv\")\n",
    "    \n",
    "    ftrs = np.array(pd.read_csv(file_path, header=None).values[:,2:-1])\n",
    "    lbls = np.array(pd.read_csv(file_path, header=None).values[:,-1])\n",
    "    \n",
    "    return ftrs, lbls\n",
    "\n",
    "def scale_features(ftrs):\n",
    "    \n",
    "    standardscaler = StandardScaler()\n",
    "    ftrs_scld = standardscaler.fit_transform(ftrs)\n",
    "    \n",
    "    return ftrs_scld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179555, 168)\n"
     ]
    }
   ],
   "source": [
    "# Load the features and the labels\n",
    "raw_ftrs, raw_lbls = load_feature_set()\n",
    "\n",
    "ftrs = scale_features(raw_ftrs)\n",
    "\n",
    "print(ftrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.777, 5.941, 5.433, 2.869, 2.587, 1.154, 0.26, -0.003, -0.014, -0.014, -0.02, 0.033, 0.158, 0.232, 0.279, 0.673, 1.834, 6.345, 1.47, 1.038, 2.909, 3.058, 2.42, 1.397, 2.43, 4.601, 10.857, 2.101, 1.625, 0.273, -0.338, -0.602, -0.699, -0.671, -0.635, -0.443, 0.015, 0.202, 0.393, 0.045, 0.709, 20.506, 0.246, -0.093, 1.54, 1.581, 0.365, 0.129, -1.764, -0.956, 0.167, -1.196, -1.32, -0.783, 0.136, 0.253, -0.137, -0.093, 0.285, 0.312, 1.105, 0.974, 1.21, -0.283, -1.504, -1.194, -1.102, -0.636, -0.658, -1.065, -0.892, -0.607, -0.335, -0.431, -0.228, -0.612, -0.557, -0.463, 0.069, 0.164, -0.166, -0.142, 0.236, 0.042, 0.687, 0.543, 0.772, -0.267, -0.497, -0.542, -0.412, -0.285, -0.231, -0.321, -0.301, -0.183, 6.138, 5.808, 4.747, 2.946, 2.859, 1.231, 0.313, 0.068, 0.082, 0.072, 0.044, 0.038, 0.077, 0.136, 0.16, 0.643, 1.909, 6.058, 1.505, 1.096, 2.966, 3.21, 2.523, 1.775, 4.854, 6.194, 3.386, 2.724, 1.905, 0.684, 0.582, 0.42, 0.737, 0.496, 0.644, 0.461, 0.412, 0.221, 0.31, 0.439, 0.583, 0.505, 0.876, 1.083, 1.617, 1.595, 2.988, -0.065, 2.529, 3.606, 4.716, 1.816, 1.542, 0.698, 0.28, -0.137, -0.368, -0.425, -0.172, -0.066, 0.856, 0.968, 1.428, 0.424, 0.83, 5.854, 0.617, 0.265, 1.759, 1.476, 0.565, 0.579]\n"
     ]
    }
   ],
   "source": [
    "print([round(a, 3) for a in max(ftrs, key=lambda x: x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    regularization = 0.000001\n",
    "\n",
    "    inputs = Input(shape=(168,), name=\"inputs\")\n",
    "\n",
    "    encoded = Dense(\n",
    "        160, activation='relu', activity_regularizer=l1(regularization)\n",
    "    )(inputs)\n",
    "    \n",
    "    #encoded = BatchNormalization()(encoded)\n",
    "    \n",
    "    #encoded = Dropout(0.05)(encoded)\n",
    "    \n",
    "    encoded = Dense(\n",
    "        150, activation='relu', activity_regularizer=l1(regularization)\n",
    "    )(encoded)\n",
    "    \n",
    "    \n",
    "    bottleneck = Dense(140, activation='relu', name=\"bottleneck\")(encoded)\n",
    "    \n",
    "    decoded = Dense(\n",
    "        150, activation='relu', activity_regularizer=l1(regularization)\n",
    "    )(bottleneck)\n",
    "    \n",
    "    #decoded = BatchNormalization()(decoded)\n",
    "    \n",
    "    #decoded = Dropout(0.05)(decoded)\n",
    "    \n",
    "    decoded = Dense(\n",
    "        160, activation='relu', activity_regularizer=l1(regularization)\n",
    "    )(decoded)\n",
    "\n",
    "    outputs = Dense(168, activation='linear')(decoded)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.002),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model, inputs, bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/30\n",
      " - 4s - loss: 0.2414 - val_loss: 0.1304\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.1216 - val_loss: 0.1068\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.0968 - val_loss: 0.0994\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.0849 - val_loss: 0.0882\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.0767 - val_loss: 0.0779\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.0679 - val_loss: 0.0645\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.0601 - val_loss: 0.0864\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.0534 - val_loss: 0.0581\n",
      "Epoch 9/30\n",
      " - 3s - loss: 0.0514 - val_loss: 0.0421\n",
      "Epoch 10/30\n",
      " - 3s - loss: 0.0477 - val_loss: 0.0415\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.0423 - val_loss: 0.0357\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.0418 - val_loss: 0.0375\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.0376 - val_loss: 0.0726\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.0460 - val_loss: 0.0384\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.0431 - val_loss: 0.0356\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.0425 - val_loss: 0.0261\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.0335 - val_loss: 0.0449\n",
      "Epoch 18/30\n",
      " - 3s - loss: 0.0319 - val_loss: 0.0336\n",
      "Epoch 19/30\n",
      " - 3s - loss: 0.0318 - val_loss: 0.0240\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.0264 - val_loss: 0.0230\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.0278 - val_loss: 0.0472\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.0325 - val_loss: 0.0268\n",
      "Epoch 23/30\n",
      " - 3s - loss: 0.0320 - val_loss: 0.0229\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.0332 - val_loss: 0.0220\n",
      "Epoch 25/30\n",
      " - 3s - loss: 0.0269 - val_loss: 0.0266\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.0282 - val_loss: 0.0180\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.0268 - val_loss: 0.0322\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.0267 - val_loss: 0.0198\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.0383 - val_loss: 0.0285\n",
      "Epoch 30/30\n",
      "Restoring model weights from the end of the best epoch.\n",
      " - 3s - loss: 0.0301 - val_loss: 0.0420\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f469db184a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "experiment_number += 1\n",
    "\n",
    "run_name = 'autoencoderdecoder_ssd_' + str(experiment_number)\n",
    "model_save_path = constants.MODELS_PATH + run_name + '.h5'\n",
    "\n",
    "tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
    "model_ckeckpt = ModelCheckpoint(filepath=model_save_path, monitor='val_loss', save_best_only=True, verbose=0)\n",
    "\n",
    "model, inputs_layer, bottleneck = create_model()\n",
    "\n",
    "model.fit(\n",
    "    x=ftrs, \n",
    "    y=ftrs,\n",
    "    epochs=30,\n",
    "    batch_size=500,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        tk_board,\n",
    "        early_stop,\n",
    "        model_ckeckpt\n",
    "    ],\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = constants.MODELS_PATH + 'autoencoder_ssd_' + str(experiment_number) + '.h5'\n",
    "\n",
    "autoencoder = Model(inputs=inputs_layer, outputs=bottleneck)\n",
    "autoencoder.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
