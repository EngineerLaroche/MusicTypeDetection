{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload chaque module spécifié par %aimport\n",
    "%autoreload 1\n",
    "\n",
    "%aimport src.kerasCallbacks\n",
    "%aimport src.results\n",
    "\n",
    "from IPython.display import display\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "from src import constants\n",
    "from src.kerasCallbacks import BestWeightsRestorer\n",
    "import src.results as resultsUtil\n",
    "import src.runUtil as runUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_feature_set():\n",
    "\n",
    "    file_path = path.join(constants.DATA_PATH, 'ssd_base_split.csv')\n",
    "    \n",
    "    ftrs = np.array(pd.read_csv(file_path, header=None).values[:,2:-1])\n",
    "    lbls = np.array(pd.read_csv(file_path, header=None).values[:,-1])\n",
    "    \n",
    "    return ftrs, lbls\n",
    "\n",
    "def dimensionality_reduce(ftrs, n_components=140):\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_ftrs = pca.fit(ftrs).transform(ftrs)\n",
    "    \n",
    "    return reduced_ftrs\n",
    "\n",
    "def scale_features(ftrs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    ftrs_scld = scaler.fit_transform(ftrs)\n",
    "    \n",
    "    return ftrs_scld\n",
    "\n",
    "def one_hot_labels(lbls):\n",
    "    \n",
    "    lbls_1d = lbls.reshape(len(lbls), 1)\n",
    "        \n",
    "    oh_encoder = OneHotEncoder(sparse=False)\n",
    "    lbls_oh = oh_encoder.fit_transform(lbls_1d)\n",
    "    \n",
    "    return lbls_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "# Load the features and the labels\n",
    "raw_ftrs, raw_lbls = load_feature_set()\n",
    "\n",
    "lbls_oh = one_hot_labels(raw_lbls)\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoded_lbls = lbl_encoder.fit_transform(raw_lbls)\n",
    "\n",
    "ftrs = scale_features(raw_ftrs)\n",
    "#ftrs = dimensionality_reduce(ftrs, n_components=168)\n",
    "\n",
    "print(ftrs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='mlp_ssd_input')\n",
    "    \n",
    "    layer = Dense(130, activation='relu', name='mlp_ssd_dense_1')(inputs)\n",
    "    layer = Dropout(0.025, name='mlp_ssd_dropout_1')(layer)\n",
    "    layer = Dense(100, activation='relu', name='mlp_ssd_dense_2')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_ssd_dropout_2')(layer)\n",
    "    layer = Dense(80, activation='relu', name='mlp_ssd_dense_3')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_ssd_dropout_3')(layer)\n",
    "    layer = Dense(65, activation='relu', name='mlp_ssd_dense_4')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_ssd_dropout_4')(layer)\n",
    "    layer = Dense(45, activation='relu', name='mlp_ssd_dense_5')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_ssd_dropout_5')(layer)\n",
    "    layer = Dense(30, activation='relu', name='mlp_ssd_dense_6')(layer)\n",
    "    \n",
    "    outputs = Dense(25, activation='softmax', name='mlp_ssd_output')(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            CategoricalAccuracy(name='accuracy')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training fold 1\n",
      "Train on 114904 samples, validate on 28740 samples\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "114904/114904 [==============================] - 1s 8us/sample - loss: 2.9523 - accuracy: 0.1204 - val_loss: 2.7104 - val_accuracy: 0.1875\n",
      "Epoch 2/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.6648 - accuracy: 0.1969 - val_loss: 2.5629 - val_accuracy: 0.2180\n",
      "Epoch 3/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.5570 - accuracy: 0.2214 - val_loss: 2.4853 - val_accuracy: 0.2383\n",
      "Epoch 4/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.4918 - accuracy: 0.2406 - val_loss: 2.4411 - val_accuracy: 0.2514\n",
      "Epoch 5/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.4514 - accuracy: 0.2521 - val_loss: 2.4083 - val_accuracy: 0.2621\n",
      "Epoch 6/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4210 - accuracy: 0.2609 - val_loss: 2.3925 - val_accuracy: 0.2656\n",
      "Epoch 7/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3973 - accuracy: 0.2666 - val_loss: 2.3753 - val_accuracy: 0.2693\n",
      "Epoch 8/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3820 - accuracy: 0.2707 - val_loss: 2.3641 - val_accuracy: 0.2752\n",
      "Epoch 9/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3678 - accuracy: 0.2738 - val_loss: 2.3542 - val_accuracy: 0.2757\n",
      "Epoch 10/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3522 - accuracy: 0.2782 - val_loss: 2.3486 - val_accuracy: 0.2784\n",
      "Epoch 11/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3390 - accuracy: 0.2799 - val_loss: 2.3420 - val_accuracy: 0.2799\n",
      "Epoch 12/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3295 - accuracy: 0.2837 - val_loss: 2.3325 - val_accuracy: 0.2807\n",
      "Epoch 13/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3196 - accuracy: 0.2860 - val_loss: 2.3278 - val_accuracy: 0.2827\n",
      "Epoch 14/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3110 - accuracy: 0.2890 - val_loss: 2.3223 - val_accuracy: 0.2860\n",
      "Epoch 15/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.3023 - accuracy: 0.2904 - val_loss: 2.3222 - val_accuracy: 0.2850\n",
      "Epoch 16/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2972 - accuracy: 0.2945 - val_loss: 2.3149 - val_accuracy: 0.2858\n",
      "Epoch 17/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2889 - accuracy: 0.2938 - val_loss: 2.3135 - val_accuracy: 0.2874\n",
      "Epoch 18/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2793 - accuracy: 0.2984 - val_loss: 2.3141 - val_accuracy: 0.2855\n",
      "Epoch 19/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2751 - accuracy: 0.2990 - val_loss: 2.3068 - val_accuracy: 0.2886\n",
      "Epoch 20/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2666 - accuracy: 0.3014 - val_loss: 2.3045 - val_accuracy: 0.2889\n",
      "Epoch 21/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2624 - accuracy: 0.3012 - val_loss: 2.3069 - val_accuracy: 0.2905\n",
      "Epoch 22/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2590 - accuracy: 0.3037 - val_loss: 2.3070 - val_accuracy: 0.2888\n",
      "Epoch 23/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2509 - accuracy: 0.3055 - val_loss: 2.3021 - val_accuracy: 0.2892\n",
      "Epoch 24/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2439 - accuracy: 0.3060 - val_loss: 2.2996 - val_accuracy: 0.2917\n",
      "Epoch 25/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2418 - accuracy: 0.3076 - val_loss: 2.2976 - val_accuracy: 0.2921\n",
      "Epoch 26/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2357 - accuracy: 0.3102 - val_loss: 2.2959 - val_accuracy: 0.2930\n",
      "Epoch 27/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2320 - accuracy: 0.3107 - val_loss: 2.2969 - val_accuracy: 0.2894\n",
      "Epoch 28/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2271 - accuracy: 0.3133 - val_loss: 2.2907 - val_accuracy: 0.2918\n",
      "Epoch 29/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2203 - accuracy: 0.3139 - val_loss: 2.2922 - val_accuracy: 0.2928\n",
      "Epoch 30/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2185 - accuracy: 0.3124 - val_loss: 2.2908 - val_accuracy: 0.2946\n",
      "Epoch 31/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2162 - accuracy: 0.3145 - val_loss: 2.2918 - val_accuracy: 0.2931\n",
      "Epoch 32/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2130 - accuracy: 0.3168 - val_loss: 2.2918 - val_accuracy: 0.2949\n",
      "Epoch 33/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2024 - accuracy: 0.3201 - val_loss: 2.2913 - val_accuracy: 0.2955\n",
      "Epoch 34/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.2033 - accuracy: 0.3182 - val_loss: 2.2928 - val_accuracy: 0.2959\n",
      "Epoch 35/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1993 - accuracy: 0.3205 - val_loss: 2.2880 - val_accuracy: 0.2957\n",
      "Epoch 36/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1956 - accuracy: 0.3206 - val_loss: 2.2886 - val_accuracy: 0.2955\n",
      "Epoch 37/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1904 - accuracy: 0.3221 - val_loss: 2.2891 - val_accuracy: 0.2958\n",
      "Epoch 38/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1879 - accuracy: 0.3223 - val_loss: 2.2883 - val_accuracy: 0.2972\n",
      "Epoch 39/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1825 - accuracy: 0.3245 - val_loss: 2.2929 - val_accuracy: 0.2959\n",
      "Epoch 40/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1792 - accuracy: 0.3263 - val_loss: 2.2875 - val_accuracy: 0.2962\n",
      "Epoch 41/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1768 - accuracy: 0.3259 - val_loss: 2.2853 - val_accuracy: 0.2971\n",
      "Epoch 42/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1757 - accuracy: 0.3262 - val_loss: 2.2881 - val_accuracy: 0.2958\n",
      "Epoch 43/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1723 - accuracy: 0.3269 - val_loss: 2.2871 - val_accuracy: 0.2969\n",
      "Epoch 44/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1671 - accuracy: 0.3296 - val_loss: 2.2875 - val_accuracy: 0.2971\n",
      "Epoch 45/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1669 - accuracy: 0.3288 - val_loss: 2.2888 - val_accuracy: 0.2958\n",
      "Epoch 46/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1633 - accuracy: 0.3297 - val_loss: 2.2856 - val_accuracy: 0.2999\n",
      "Epoch 47/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1580 - accuracy: 0.3311 - val_loss: 2.2909 - val_accuracy: 0.2978\n",
      "Epoch 48/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1543 - accuracy: 0.3316 - val_loss: 2.2881 - val_accuracy: 0.2997\n",
      "Epoch 49/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1563 - accuracy: 0.3300 - val_loss: 2.2867 - val_accuracy: 0.2970\n",
      "Epoch 50/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1518 - accuracy: 0.3309 - val_loss: 2.2871 - val_accuracy: 0.2978\n",
      "Epoch 51/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1483 - accuracy: 0.3350 - val_loss: 2.2906 - val_accuracy: 0.2945\n",
      "Epoch 52/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1460 - accuracy: 0.3351 - val_loss: 2.2856 - val_accuracy: 0.2996\n",
      "Epoch 53/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1447 - accuracy: 0.3335 - val_loss: 2.2872 - val_accuracy: 0.2973\n",
      "Epoch 54/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1417 - accuracy: 0.3364 - val_loss: 2.2874 - val_accuracy: 0.2958\n",
      "Epoch 55/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1374 - accuracy: 0.3361 - val_loss: 2.2887 - val_accuracy: 0.2988\n",
      "Epoch 56/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1363 - accuracy: 0.3388 - val_loss: 2.2887 - val_accuracy: 0.2969\n",
      "Epoch 57/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1328 - accuracy: 0.3381 - val_loss: 2.2854 - val_accuracy: 0.2994\n",
      "Epoch 58/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1312 - accuracy: 0.3383 - val_loss: 2.2913 - val_accuracy: 0.2962\n",
      "Epoch 59/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1308 - accuracy: 0.3401 - val_loss: 2.2891 - val_accuracy: 0.2968\n",
      "Epoch 60/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1264 - accuracy: 0.3402 - val_loss: 2.2933 - val_accuracy: 0.2968\n",
      "Epoch 61/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1274 - accuracy: 0.3390 - val_loss: 2.2887 - val_accuracy: 0.2976\n",
      "Epoch 62/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1259 - accuracy: 0.3400 - val_loss: 2.2950 - val_accuracy: 0.2974\n",
      "Epoch 63/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1222 - accuracy: 0.3418 - val_loss: 2.2899 - val_accuracy: 0.2985\n",
      "Epoch 64/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1188 - accuracy: 0.3415 - val_loss: 2.2951 - val_accuracy: 0.2972\n",
      "Epoch 65/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1174 - accuracy: 0.3422 - val_loss: 2.2948 - val_accuracy: 0.2968\n",
      "Epoch 66/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1145 - accuracy: 0.3430 - val_loss: 2.2941 - val_accuracy: 0.2968\n",
      "Epoch 67/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1128 - accuracy: 0.3432 - val_loss: 2.2936 - val_accuracy: 0.2955\n",
      "Epoch 68/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1110 - accuracy: 0.3440 - val_loss: 2.2943 - val_accuracy: 0.2967\n",
      "Epoch 69/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1088 - accuracy: 0.3446 - val_loss: 2.2977 - val_accuracy: 0.2981\n",
      "Epoch 70/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1071 - accuracy: 0.3451 - val_loss: 2.2953 - val_accuracy: 0.2986\n",
      "Epoch 71/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1092 - accuracy: 0.3444 - val_loss: 2.2944 - val_accuracy: 0.2973\n",
      "Epoch 72/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1034 - accuracy: 0.3442 - val_loss: 2.2944 - val_accuracy: 0.2971\n",
      "Epoch 73/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.1004 - accuracy: 0.3481 - val_loss: 2.3008 - val_accuracy: 0.2970\n",
      "Epoch 74/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.1002 - accuracy: 0.3466 - val_loss: 2.2968 - val_accuracy: 0.2977\n",
      "Epoch 75/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0993 - accuracy: 0.3464 - val_loss: 2.2978 - val_accuracy: 0.2954\n",
      "Epoch 76/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0960 - accuracy: 0.3488 - val_loss: 2.2936 - val_accuracy: 0.2973\n",
      "Epoch 77/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0958 - accuracy: 0.3475 - val_loss: 2.3022 - val_accuracy: 0.2955\n",
      "Epoch 78/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0939 - accuracy: 0.3492 - val_loss: 2.3003 - val_accuracy: 0.2966\n",
      "Epoch 79/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0918 - accuracy: 0.3498 - val_loss: 2.2999 - val_accuracy: 0.2973\n",
      "Epoch 80/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0921 - accuracy: 0.3500 - val_loss: 2.3043 - val_accuracy: 0.2936\n",
      "Epoch 81/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0865 - accuracy: 0.3512 - val_loss: 2.3055 - val_accuracy: 0.2971\n",
      "Epoch 82/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0872 - accuracy: 0.3504 - val_loss: 2.3014 - val_accuracy: 0.2968\n",
      "Epoch 83/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0859 - accuracy: 0.3496 - val_loss: 2.3025 - val_accuracy: 0.2962\n",
      "Epoch 84/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0828 - accuracy: 0.3502 - val_loss: 2.3025 - val_accuracy: 0.2966\n",
      "Epoch 85/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0808 - accuracy: 0.3521 - val_loss: 2.3026 - val_accuracy: 0.2974\n",
      "Epoch 86/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0820 - accuracy: 0.3514 - val_loss: 2.3055 - val_accuracy: 0.2967\n",
      "Epoch 87/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0815 - accuracy: 0.3501 - val_loss: 2.3075 - val_accuracy: 0.2951\n",
      "Epoch 88/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0749 - accuracy: 0.3530 - val_loss: 2.3065 - val_accuracy: 0.2956\n",
      "Epoch 89/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0762 - accuracy: 0.3525 - val_loss: 2.3131 - val_accuracy: 0.2966\n",
      "Epoch 90/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0770 - accuracy: 0.3526 - val_loss: 2.3091 - val_accuracy: 0.2959\n",
      "Epoch 91/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0775 - accuracy: 0.3538 - val_loss: 2.3063 - val_accuracy: 0.2977\n",
      "Epoch 92/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0729 - accuracy: 0.3551 - val_loss: 2.3117 - val_accuracy: 0.2952\n",
      "Epoch 93/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0678 - accuracy: 0.3546 - val_loss: 2.3115 - val_accuracy: 0.2972\n",
      "Epoch 94/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0691 - accuracy: 0.3549 - val_loss: 2.3110 - val_accuracy: 0.2954\n",
      "Epoch 95/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0683 - accuracy: 0.3549 - val_loss: 2.3116 - val_accuracy: 0.2947\n",
      "Epoch 96/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0697 - accuracy: 0.3541 - val_loss: 2.3103 - val_accuracy: 0.2956\n",
      "Epoch 97/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0660 - accuracy: 0.3549 - val_loss: 2.3107 - val_accuracy: 0.2954\n",
      "Epoch 98/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0659 - accuracy: 0.3563 - val_loss: 2.3140 - val_accuracy: 0.2943\n",
      "Epoch 99/100\n",
      "114904/114904 [==============================] - 0s 4us/sample - loss: 2.0649 - accuracy: 0.3564 - val_loss: 2.3103 - val_accuracy: 0.2950\n",
      "Epoch 100/100\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.0635 - accuracy: 0.3581 - val_loss: 2.3130 - val_accuracy: 0.2936\n",
      "Restoring the best weights from epoch 100\n",
      "Training fold 2\n",
      "Train on 114911 samples, validate on 28733 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114911/114911 [==============================] - 1s 6us/sample - loss: 2.9451 - accuracy: 0.1284 - val_loss: 2.6799 - val_accuracy: 0.1973\n",
      "Epoch 2/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.6369 - accuracy: 0.2011 - val_loss: 2.5454 - val_accuracy: 0.2236\n",
      "Epoch 3/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.5410 - accuracy: 0.2238 - val_loss: 2.4810 - val_accuracy: 0.2424\n",
      "Epoch 4/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.4914 - accuracy: 0.2381 - val_loss: 2.4463 - val_accuracy: 0.2487\n",
      "Epoch 5/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.4564 - accuracy: 0.2483 - val_loss: 2.4228 - val_accuracy: 0.2552\n",
      "Epoch 6/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.4319 - accuracy: 0.2533 - val_loss: 2.4021 - val_accuracy: 0.2633\n",
      "Epoch 7/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.4105 - accuracy: 0.2603 - val_loss: 2.3888 - val_accuracy: 0.2686\n",
      "Epoch 8/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3924 - accuracy: 0.2639 - val_loss: 2.3711 - val_accuracy: 0.2717\n",
      "Epoch 9/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.3761 - accuracy: 0.2692 - val_loss: 2.3628 - val_accuracy: 0.2743\n",
      "Epoch 10/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.3648 - accuracy: 0.2730 - val_loss: 2.3605 - val_accuracy: 0.2765\n",
      "Epoch 11/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.3498 - accuracy: 0.2765 - val_loss: 2.3467 - val_accuracy: 0.2794\n",
      "Epoch 12/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3395 - accuracy: 0.2805 - val_loss: 2.3426 - val_accuracy: 0.2787\n",
      "Epoch 13/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3284 - accuracy: 0.2837 - val_loss: 2.3335 - val_accuracy: 0.2829\n",
      "Epoch 14/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.3185 - accuracy: 0.2850 - val_loss: 2.3244 - val_accuracy: 0.2858\n",
      "Epoch 15/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3106 - accuracy: 0.2881 - val_loss: 2.3213 - val_accuracy: 0.2887\n",
      "Epoch 16/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.3036 - accuracy: 0.2912 - val_loss: 2.3206 - val_accuracy: 0.2867\n",
      "Epoch 17/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2945 - accuracy: 0.2922 - val_loss: 2.3161 - val_accuracy: 0.2866\n",
      "Epoch 18/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2896 - accuracy: 0.2937 - val_loss: 2.3120 - val_accuracy: 0.2898\n",
      "Epoch 19/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2807 - accuracy: 0.2947 - val_loss: 2.3065 - val_accuracy: 0.2910\n",
      "Epoch 20/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2753 - accuracy: 0.2975 - val_loss: 2.3031 - val_accuracy: 0.2913\n",
      "Epoch 21/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2681 - accuracy: 0.2994 - val_loss: 2.3060 - val_accuracy: 0.2929\n",
      "Epoch 22/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2642 - accuracy: 0.2996 - val_loss: 2.3042 - val_accuracy: 0.2930\n",
      "Epoch 23/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2576 - accuracy: 0.3021 - val_loss: 2.2982 - val_accuracy: 0.2948\n",
      "Epoch 24/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2483 - accuracy: 0.3045 - val_loss: 2.2974 - val_accuracy: 0.2946\n",
      "Epoch 25/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2467 - accuracy: 0.3051 - val_loss: 2.2939 - val_accuracy: 0.2933\n",
      "Epoch 26/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2429 - accuracy: 0.3057 - val_loss: 2.2958 - val_accuracy: 0.2941\n",
      "Epoch 27/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2360 - accuracy: 0.3095 - val_loss: 2.2909 - val_accuracy: 0.2965\n",
      "Epoch 28/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2319 - accuracy: 0.3093 - val_loss: 2.2937 - val_accuracy: 0.2956\n",
      "Epoch 29/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2281 - accuracy: 0.3121 - val_loss: 2.2936 - val_accuracy: 0.2942\n",
      "Epoch 30/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2236 - accuracy: 0.3133 - val_loss: 2.2899 - val_accuracy: 0.2968\n",
      "Epoch 31/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2195 - accuracy: 0.3143 - val_loss: 2.2935 - val_accuracy: 0.2963\n",
      "Epoch 32/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2152 - accuracy: 0.3143 - val_loss: 2.2912 - val_accuracy: 0.2990\n",
      "Epoch 33/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2092 - accuracy: 0.3166 - val_loss: 2.2918 - val_accuracy: 0.2997\n",
      "Epoch 34/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2082 - accuracy: 0.3180 - val_loss: 2.2945 - val_accuracy: 0.2974\n",
      "Epoch 35/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2044 - accuracy: 0.3164 - val_loss: 2.2926 - val_accuracy: 0.2969\n",
      "Epoch 36/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.2012 - accuracy: 0.3180 - val_loss: 2.2898 - val_accuracy: 0.2974\n",
      "Epoch 37/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1955 - accuracy: 0.3194 - val_loss: 2.2874 - val_accuracy: 0.2994\n",
      "Epoch 38/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1926 - accuracy: 0.3195 - val_loss: 2.2889 - val_accuracy: 0.2971\n",
      "Epoch 39/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1897 - accuracy: 0.3210 - val_loss: 2.2926 - val_accuracy: 0.2967\n",
      "Epoch 40/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1853 - accuracy: 0.3223 - val_loss: 2.2914 - val_accuracy: 0.2981\n",
      "Epoch 41/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1836 - accuracy: 0.3244 - val_loss: 2.2915 - val_accuracy: 0.2999\n",
      "Epoch 42/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1813 - accuracy: 0.3233 - val_loss: 2.2896 - val_accuracy: 0.2984\n",
      "Epoch 43/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1764 - accuracy: 0.3268 - val_loss: 2.2891 - val_accuracy: 0.2995\n",
      "Epoch 44/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1726 - accuracy: 0.3264 - val_loss: 2.2937 - val_accuracy: 0.2974\n",
      "Epoch 45/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1697 - accuracy: 0.3260 - val_loss: 2.2894 - val_accuracy: 0.2994\n",
      "Epoch 46/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1694 - accuracy: 0.3267 - val_loss: 2.2917 - val_accuracy: 0.2997\n",
      "Epoch 47/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1630 - accuracy: 0.3284 - val_loss: 2.2879 - val_accuracy: 0.2999\n",
      "Epoch 48/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1618 - accuracy: 0.3289 - val_loss: 2.2901 - val_accuracy: 0.2982\n",
      "Epoch 49/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1569 - accuracy: 0.3300 - val_loss: 2.2897 - val_accuracy: 0.2977\n",
      "Epoch 50/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1560 - accuracy: 0.3307 - val_loss: 2.2903 - val_accuracy: 0.3008\n",
      "Epoch 51/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1538 - accuracy: 0.3314 - val_loss: 2.2930 - val_accuracy: 0.2998\n",
      "Epoch 52/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1507 - accuracy: 0.3324 - val_loss: 2.2911 - val_accuracy: 0.3004\n",
      "Epoch 53/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1477 - accuracy: 0.3317 - val_loss: 2.2909 - val_accuracy: 0.3015\n",
      "Epoch 54/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1438 - accuracy: 0.3337 - val_loss: 2.2944 - val_accuracy: 0.3014\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1459 - accuracy: 0.3350 - val_loss: 2.2930 - val_accuracy: 0.3007\n",
      "Epoch 56/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1432 - accuracy: 0.3339 - val_loss: 2.2926 - val_accuracy: 0.2992\n",
      "Epoch 57/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1392 - accuracy: 0.3348 - val_loss: 2.2920 - val_accuracy: 0.2992\n",
      "Epoch 58/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1384 - accuracy: 0.3363 - val_loss: 2.2958 - val_accuracy: 0.3006\n",
      "Epoch 59/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1358 - accuracy: 0.3362 - val_loss: 2.2923 - val_accuracy: 0.3015\n",
      "Epoch 60/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1314 - accuracy: 0.3375 - val_loss: 2.2924 - val_accuracy: 0.2994\n",
      "Epoch 61/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1295 - accuracy: 0.3385 - val_loss: 2.2969 - val_accuracy: 0.3014\n",
      "Epoch 62/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1255 - accuracy: 0.3391 - val_loss: 2.3010 - val_accuracy: 0.3000\n",
      "Epoch 63/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1279 - accuracy: 0.3389 - val_loss: 2.2947 - val_accuracy: 0.2998\n",
      "Epoch 64/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1230 - accuracy: 0.3401 - val_loss: 2.2966 - val_accuracy: 0.3008\n",
      "Epoch 65/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1199 - accuracy: 0.3410 - val_loss: 2.3007 - val_accuracy: 0.3032\n",
      "Epoch 66/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1186 - accuracy: 0.3418 - val_loss: 2.3045 - val_accuracy: 0.2996\n",
      "Epoch 67/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1159 - accuracy: 0.3414 - val_loss: 2.3019 - val_accuracy: 0.2990\n",
      "Epoch 68/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1128 - accuracy: 0.3422 - val_loss: 2.3056 - val_accuracy: 0.3002\n",
      "Epoch 69/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1133 - accuracy: 0.3435 - val_loss: 2.3011 - val_accuracy: 0.2983\n",
      "Epoch 70/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1114 - accuracy: 0.3416 - val_loss: 2.3026 - val_accuracy: 0.3012\n",
      "Epoch 71/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1101 - accuracy: 0.3441 - val_loss: 2.3054 - val_accuracy: 0.3006\n",
      "Epoch 72/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.1079 - accuracy: 0.3449 - val_loss: 2.3044 - val_accuracy: 0.3000\n",
      "Epoch 73/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1081 - accuracy: 0.3453 - val_loss: 2.3032 - val_accuracy: 0.2992\n",
      "Epoch 74/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1026 - accuracy: 0.3475 - val_loss: 2.3031 - val_accuracy: 0.2976\n",
      "Epoch 75/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1000 - accuracy: 0.3467 - val_loss: 2.3086 - val_accuracy: 0.2970\n",
      "Epoch 76/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.1019 - accuracy: 0.3461 - val_loss: 2.3031 - val_accuracy: 0.2984\n",
      "Epoch 77/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0990 - accuracy: 0.3468 - val_loss: 2.3069 - val_accuracy: 0.2985\n",
      "Epoch 78/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0948 - accuracy: 0.3470 - val_loss: 2.3071 - val_accuracy: 0.2987\n",
      "Epoch 79/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0934 - accuracy: 0.3479 - val_loss: 2.3076 - val_accuracy: 0.2981\n",
      "Epoch 80/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0937 - accuracy: 0.3484 - val_loss: 2.3090 - val_accuracy: 0.2952\n",
      "Epoch 81/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0920 - accuracy: 0.3475 - val_loss: 2.3106 - val_accuracy: 0.3011\n",
      "Epoch 82/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0878 - accuracy: 0.3504 - val_loss: 2.3095 - val_accuracy: 0.2985\n",
      "Epoch 83/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0910 - accuracy: 0.3500 - val_loss: 2.3095 - val_accuracy: 0.2990\n",
      "Epoch 84/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0910 - accuracy: 0.3489 - val_loss: 2.3125 - val_accuracy: 0.2963\n",
      "Epoch 85/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0869 - accuracy: 0.3494 - val_loss: 2.3093 - val_accuracy: 0.2976\n",
      "Epoch 86/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0834 - accuracy: 0.3504 - val_loss: 2.3149 - val_accuracy: 0.2981\n",
      "Epoch 87/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0824 - accuracy: 0.3505 - val_loss: 2.3114 - val_accuracy: 0.2971\n",
      "Epoch 88/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0802 - accuracy: 0.3512 - val_loss: 2.3177 - val_accuracy: 0.2995\n",
      "Epoch 89/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0803 - accuracy: 0.3496 - val_loss: 2.3132 - val_accuracy: 0.2980\n",
      "Epoch 90/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0769 - accuracy: 0.3522 - val_loss: 2.3156 - val_accuracy: 0.2984\n",
      "Epoch 91/100\n",
      "114911/114911 [==============================] - 0s 4us/sample - loss: 2.0750 - accuracy: 0.3526 - val_loss: 2.3186 - val_accuracy: 0.2964\n",
      "Epoch 92/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0782 - accuracy: 0.3512 - val_loss: 2.3188 - val_accuracy: 0.2992\n",
      "Epoch 93/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0731 - accuracy: 0.3533 - val_loss: 2.3124 - val_accuracy: 0.3007\n",
      "Epoch 94/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0733 - accuracy: 0.3535 - val_loss: 2.3202 - val_accuracy: 0.2955\n",
      "Epoch 95/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0738 - accuracy: 0.3536 - val_loss: 2.3225 - val_accuracy: 0.2975\n",
      "Epoch 96/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0688 - accuracy: 0.3552 - val_loss: 2.3178 - val_accuracy: 0.2970\n",
      "Epoch 97/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0700 - accuracy: 0.3540 - val_loss: 2.3200 - val_accuracy: 0.2975\n",
      "Epoch 98/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0667 - accuracy: 0.3544 - val_loss: 2.3222 - val_accuracy: 0.2999\n",
      "Epoch 99/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0657 - accuracy: 0.3548 - val_loss: 2.3233 - val_accuracy: 0.2975\n",
      "Epoch 100/100\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.0634 - accuracy: 0.3577 - val_loss: 2.3249 - val_accuracy: 0.2975\n",
      "Restoring the best weights from epoch 100\n",
      "Training fold 3\n",
      "Train on 114914 samples, validate on 28730 samples\n",
      "Epoch 1/100\n",
      "114914/114914 [==============================] - 1s 7us/sample - loss: 2.9472 - accuracy: 0.1333 - val_loss: 2.7078 - val_accuracy: 0.1812\n",
      "Epoch 2/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.6328 - accuracy: 0.1987 - val_loss: 2.5432 - val_accuracy: 0.2253\n",
      "Epoch 3/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.5291 - accuracy: 0.2300 - val_loss: 2.4759 - val_accuracy: 0.2449\n",
      "Epoch 4/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.4716 - accuracy: 0.2459 - val_loss: 2.4285 - val_accuracy: 0.2587\n",
      "Epoch 5/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.4349 - accuracy: 0.2555 - val_loss: 2.4066 - val_accuracy: 0.2644\n",
      "Epoch 6/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.4070 - accuracy: 0.2624 - val_loss: 2.3862 - val_accuracy: 0.2723\n",
      "Epoch 7/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3875 - accuracy: 0.2675 - val_loss: 2.3728 - val_accuracy: 0.2741\n",
      "Epoch 8/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3725 - accuracy: 0.2718 - val_loss: 2.3625 - val_accuracy: 0.2755\n",
      "Epoch 9/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3561 - accuracy: 0.2751 - val_loss: 2.3573 - val_accuracy: 0.2754\n",
      "Epoch 10/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3426 - accuracy: 0.2795 - val_loss: 2.3498 - val_accuracy: 0.2785\n",
      "Epoch 11/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3328 - accuracy: 0.2815 - val_loss: 2.3430 - val_accuracy: 0.2794\n",
      "Epoch 12/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3233 - accuracy: 0.2835 - val_loss: 2.3362 - val_accuracy: 0.2823\n",
      "Epoch 13/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3127 - accuracy: 0.2883 - val_loss: 2.3294 - val_accuracy: 0.2825\n",
      "Epoch 14/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.3065 - accuracy: 0.2888 - val_loss: 2.3298 - val_accuracy: 0.2831\n",
      "Epoch 15/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2971 - accuracy: 0.2909 - val_loss: 2.3214 - val_accuracy: 0.2856\n",
      "Epoch 16/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2901 - accuracy: 0.2931 - val_loss: 2.3213 - val_accuracy: 0.2853\n",
      "Epoch 17/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2816 - accuracy: 0.2961 - val_loss: 2.3183 - val_accuracy: 0.2861\n",
      "Epoch 18/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2746 - accuracy: 0.2976 - val_loss: 2.3189 - val_accuracy: 0.2862\n",
      "Epoch 19/100\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2716 - accuracy: 0.2986 - val_loss: 2.3106 - val_accuracy: 0.2891\n",
      "Epoch 20/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2629 - accuracy: 0.3015 - val_loss: 2.3089 - val_accuracy: 0.2878\n",
      "Epoch 21/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2591 - accuracy: 0.3027 - val_loss: 2.3078 - val_accuracy: 0.2890\n",
      "Epoch 22/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2529 - accuracy: 0.3041 - val_loss: 2.3061 - val_accuracy: 0.2914\n",
      "Epoch 23/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2471 - accuracy: 0.3068 - val_loss: 2.3033 - val_accuracy: 0.2927\n",
      "Epoch 24/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2413 - accuracy: 0.3069 - val_loss: 2.3029 - val_accuracy: 0.2920\n",
      "Epoch 25/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2382 - accuracy: 0.3098 - val_loss: 2.3013 - val_accuracy: 0.2923\n",
      "Epoch 26/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2331 - accuracy: 0.3085 - val_loss: 2.3046 - val_accuracy: 0.2899\n",
      "Epoch 27/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2298 - accuracy: 0.3108 - val_loss: 2.3046 - val_accuracy: 0.2920\n",
      "Epoch 28/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2217 - accuracy: 0.3127 - val_loss: 2.3023 - val_accuracy: 0.2927\n",
      "Epoch 29/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2184 - accuracy: 0.3140 - val_loss: 2.3004 - val_accuracy: 0.2922\n",
      "Epoch 30/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2171 - accuracy: 0.3143 - val_loss: 2.3006 - val_accuracy: 0.2929\n",
      "Epoch 31/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2113 - accuracy: 0.3144 - val_loss: 2.2995 - val_accuracy: 0.2935\n",
      "Epoch 32/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2081 - accuracy: 0.3162 - val_loss: 2.2989 - val_accuracy: 0.2948\n",
      "Epoch 33/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.2028 - accuracy: 0.3161 - val_loss: 2.2984 - val_accuracy: 0.2927\n",
      "Epoch 34/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1999 - accuracy: 0.3191 - val_loss: 2.2913 - val_accuracy: 0.2956\n",
      "Epoch 35/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1964 - accuracy: 0.3196 - val_loss: 2.2990 - val_accuracy: 0.2931\n",
      "Epoch 36/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1916 - accuracy: 0.3188 - val_loss: 2.2961 - val_accuracy: 0.2949\n",
      "Epoch 37/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1901 - accuracy: 0.3224 - val_loss: 2.2959 - val_accuracy: 0.2956\n",
      "Epoch 38/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1837 - accuracy: 0.3225 - val_loss: 2.2946 - val_accuracy: 0.2958\n",
      "Epoch 39/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1805 - accuracy: 0.3242 - val_loss: 2.2917 - val_accuracy: 0.2960\n",
      "Epoch 40/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1781 - accuracy: 0.3240 - val_loss: 2.2944 - val_accuracy: 0.2963\n",
      "Epoch 41/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1732 - accuracy: 0.3254 - val_loss: 2.2947 - val_accuracy: 0.2954\n",
      "Epoch 42/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1732 - accuracy: 0.3265 - val_loss: 2.2932 - val_accuracy: 0.2971\n",
      "Epoch 43/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1681 - accuracy: 0.3277 - val_loss: 2.2958 - val_accuracy: 0.2963\n",
      "Epoch 44/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1651 - accuracy: 0.3282 - val_loss: 2.2958 - val_accuracy: 0.2950\n",
      "Epoch 45/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1627 - accuracy: 0.3294 - val_loss: 2.2941 - val_accuracy: 0.2978\n",
      "Epoch 46/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1615 - accuracy: 0.3286 - val_loss: 2.2964 - val_accuracy: 0.2978\n",
      "Epoch 47/100\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.1585 - accuracy: 0.3306 - val_loss: 2.2991 - val_accuracy: 0.2982\n",
      "Epoch 48/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1574 - accuracy: 0.3308 - val_loss: 2.2963 - val_accuracy: 0.2957\n",
      "Epoch 49/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1513 - accuracy: 0.3298 - val_loss: 2.2952 - val_accuracy: 0.2944\n",
      "Epoch 50/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1525 - accuracy: 0.3331 - val_loss: 2.2967 - val_accuracy: 0.2975\n",
      "Epoch 51/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1467 - accuracy: 0.3328 - val_loss: 2.2987 - val_accuracy: 0.2961\n",
      "Epoch 52/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1440 - accuracy: 0.3352 - val_loss: 2.2983 - val_accuracy: 0.2985\n",
      "Epoch 53/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1411 - accuracy: 0.3354 - val_loss: 2.2950 - val_accuracy: 0.2977\n",
      "Epoch 54/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1386 - accuracy: 0.3354 - val_loss: 2.2967 - val_accuracy: 0.2964\n",
      "Epoch 55/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1359 - accuracy: 0.3360 - val_loss: 2.2951 - val_accuracy: 0.2975\n",
      "Epoch 56/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1383 - accuracy: 0.3349 - val_loss: 2.2959 - val_accuracy: 0.2958\n",
      "Epoch 57/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1335 - accuracy: 0.3364 - val_loss: 2.2981 - val_accuracy: 0.2979\n",
      "Epoch 58/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1322 - accuracy: 0.3377 - val_loss: 2.2981 - val_accuracy: 0.2971\n",
      "Epoch 59/100\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.1277 - accuracy: 0.3385 - val_loss: 2.3051 - val_accuracy: 0.2962\n",
      "Epoch 60/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1270 - accuracy: 0.3381 - val_loss: 2.3026 - val_accuracy: 0.2955\n",
      "Epoch 61/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1223 - accuracy: 0.3396 - val_loss: 2.3005 - val_accuracy: 0.2992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1204 - accuracy: 0.3398 - val_loss: 2.3004 - val_accuracy: 0.2969\n",
      "Epoch 63/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1200 - accuracy: 0.3408 - val_loss: 2.3021 - val_accuracy: 0.2991\n",
      "Epoch 64/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1174 - accuracy: 0.3417 - val_loss: 2.3011 - val_accuracy: 0.2962\n",
      "Epoch 65/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1180 - accuracy: 0.3415 - val_loss: 2.3040 - val_accuracy: 0.2950\n",
      "Epoch 66/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1158 - accuracy: 0.3428 - val_loss: 2.3013 - val_accuracy: 0.2986\n",
      "Epoch 67/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1131 - accuracy: 0.3417 - val_loss: 2.3021 - val_accuracy: 0.2946\n",
      "Epoch 68/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1094 - accuracy: 0.3441 - val_loss: 2.2979 - val_accuracy: 0.2991\n",
      "Epoch 69/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1075 - accuracy: 0.3442 - val_loss: 2.3056 - val_accuracy: 0.2999\n",
      "Epoch 70/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1045 - accuracy: 0.3447 - val_loss: 2.3016 - val_accuracy: 0.2977\n",
      "Epoch 71/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1028 - accuracy: 0.3455 - val_loss: 2.3038 - val_accuracy: 0.2973\n",
      "Epoch 72/100\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.1028 - accuracy: 0.3440 - val_loss: 2.3056 - val_accuracy: 0.2956\n",
      "Epoch 73/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.1041 - accuracy: 0.3449 - val_loss: 2.3065 - val_accuracy: 0.2983\n",
      "Epoch 74/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0960 - accuracy: 0.3479 - val_loss: 2.3078 - val_accuracy: 0.2978\n",
      "Epoch 75/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0972 - accuracy: 0.3454 - val_loss: 2.3056 - val_accuracy: 0.2955\n",
      "Epoch 76/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0927 - accuracy: 0.3477 - val_loss: 2.3052 - val_accuracy: 0.2974\n",
      "Epoch 77/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0921 - accuracy: 0.3482 - val_loss: 2.3095 - val_accuracy: 0.2961\n",
      "Epoch 78/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0945 - accuracy: 0.3465 - val_loss: 2.3094 - val_accuracy: 0.2984\n",
      "Epoch 79/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0911 - accuracy: 0.3480 - val_loss: 2.3117 - val_accuracy: 0.2960\n",
      "Epoch 80/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0871 - accuracy: 0.3478 - val_loss: 2.3076 - val_accuracy: 0.2978\n",
      "Epoch 81/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0877 - accuracy: 0.3495 - val_loss: 2.3118 - val_accuracy: 0.2961\n",
      "Epoch 82/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0859 - accuracy: 0.3499 - val_loss: 2.3121 - val_accuracy: 0.2966\n",
      "Epoch 83/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0864 - accuracy: 0.3501 - val_loss: 2.3121 - val_accuracy: 0.2959\n",
      "Epoch 84/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0828 - accuracy: 0.3496 - val_loss: 2.3111 - val_accuracy: 0.2956\n",
      "Epoch 85/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0837 - accuracy: 0.3494 - val_loss: 2.3118 - val_accuracy: 0.2952\n",
      "Epoch 86/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0782 - accuracy: 0.3526 - val_loss: 2.3155 - val_accuracy: 0.2962\n",
      "Epoch 87/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0760 - accuracy: 0.3529 - val_loss: 2.3148 - val_accuracy: 0.2968\n",
      "Epoch 88/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0782 - accuracy: 0.3523 - val_loss: 2.3179 - val_accuracy: 0.2938\n",
      "Epoch 89/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0765 - accuracy: 0.3523 - val_loss: 2.3107 - val_accuracy: 0.2967\n",
      "Epoch 90/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0740 - accuracy: 0.3529 - val_loss: 2.3151 - val_accuracy: 0.2973\n",
      "Epoch 91/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0729 - accuracy: 0.3551 - val_loss: 2.3141 - val_accuracy: 0.2954\n",
      "Epoch 92/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0690 - accuracy: 0.3551 - val_loss: 2.3194 - val_accuracy: 0.2957\n",
      "Epoch 93/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0729 - accuracy: 0.3541 - val_loss: 2.3198 - val_accuracy: 0.2952\n",
      "Epoch 94/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0698 - accuracy: 0.3543 - val_loss: 2.3155 - val_accuracy: 0.2962\n",
      "Epoch 95/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0644 - accuracy: 0.3565 - val_loss: 2.3214 - val_accuracy: 0.2954\n",
      "Epoch 96/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0648 - accuracy: 0.3560 - val_loss: 2.3219 - val_accuracy: 0.2974\n",
      "Epoch 97/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0632 - accuracy: 0.3560 - val_loss: 2.3207 - val_accuracy: 0.2959\n",
      "Epoch 98/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0618 - accuracy: 0.3560 - val_loss: 2.3228 - val_accuracy: 0.2949\n",
      "Epoch 99/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0583 - accuracy: 0.3566 - val_loss: 2.3185 - val_accuracy: 0.2973\n",
      "Epoch 100/100\n",
      "114914/114914 [==============================] - 0s 4us/sample - loss: 2.0616 - accuracy: 0.3581 - val_loss: 2.3234 - val_accuracy: 0.2975\n",
      "Restoring the best weights from epoch 100\n",
      "Training fold 4\n",
      "Train on 114922 samples, validate on 28722 samples\n",
      "Epoch 1/100\n",
      "114922/114922 [==============================] - 1s 8us/sample - loss: 2.9664 - accuracy: 0.1279 - val_loss: 2.6656 - val_accuracy: 0.1964\n",
      "Epoch 2/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.6054 - accuracy: 0.2106 - val_loss: 2.5145 - val_accuracy: 0.2337\n",
      "Epoch 3/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.5117 - accuracy: 0.2338 - val_loss: 2.4594 - val_accuracy: 0.2495\n",
      "Epoch 4/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.4666 - accuracy: 0.2454 - val_loss: 2.4246 - val_accuracy: 0.2581\n",
      "Epoch 5/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.4345 - accuracy: 0.2542 - val_loss: 2.4013 - val_accuracy: 0.2622\n",
      "Epoch 6/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.4089 - accuracy: 0.2616 - val_loss: 2.3845 - val_accuracy: 0.2702\n",
      "Epoch 7/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3885 - accuracy: 0.2671 - val_loss: 2.3738 - val_accuracy: 0.2724\n",
      "Epoch 8/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3755 - accuracy: 0.2715 - val_loss: 2.3605 - val_accuracy: 0.2746\n",
      "Epoch 9/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3571 - accuracy: 0.2746 - val_loss: 2.3544 - val_accuracy: 0.2777\n",
      "Epoch 10/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3452 - accuracy: 0.2803 - val_loss: 2.3454 - val_accuracy: 0.2789\n",
      "Epoch 11/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3332 - accuracy: 0.2821 - val_loss: 2.3355 - val_accuracy: 0.2812\n",
      "Epoch 12/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3232 - accuracy: 0.2847 - val_loss: 2.3304 - val_accuracy: 0.2846\n",
      "Epoch 13/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3156 - accuracy: 0.2875 - val_loss: 2.3289 - val_accuracy: 0.2834\n",
      "Epoch 14/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.3052 - accuracy: 0.2907 - val_loss: 2.3268 - val_accuracy: 0.2825\n",
      "Epoch 15/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2988 - accuracy: 0.2916 - val_loss: 2.3185 - val_accuracy: 0.2855\n",
      "Epoch 16/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2896 - accuracy: 0.2943 - val_loss: 2.3149 - val_accuracy: 0.2886\n",
      "Epoch 17/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2838 - accuracy: 0.2973 - val_loss: 2.3157 - val_accuracy: 0.2880\n",
      "Epoch 18/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2743 - accuracy: 0.2996 - val_loss: 2.3155 - val_accuracy: 0.2875\n",
      "Epoch 19/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2698 - accuracy: 0.3001 - val_loss: 2.3085 - val_accuracy: 0.2896\n",
      "Epoch 20/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2639 - accuracy: 0.3020 - val_loss: 2.3107 - val_accuracy: 0.2887\n",
      "Epoch 21/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2576 - accuracy: 0.3042 - val_loss: 2.3026 - val_accuracy: 0.2909\n",
      "Epoch 22/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2525 - accuracy: 0.3052 - val_loss: 2.3007 - val_accuracy: 0.2917\n",
      "Epoch 23/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2471 - accuracy: 0.3071 - val_loss: 2.3004 - val_accuracy: 0.2920\n",
      "Epoch 24/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2432 - accuracy: 0.3075 - val_loss: 2.3037 - val_accuracy: 0.2929\n",
      "Epoch 25/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2360 - accuracy: 0.3098 - val_loss: 2.3045 - val_accuracy: 0.2916\n",
      "Epoch 26/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2304 - accuracy: 0.3114 - val_loss: 2.2996 - val_accuracy: 0.2919\n",
      "Epoch 27/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2273 - accuracy: 0.3131 - val_loss: 2.2992 - val_accuracy: 0.2933\n",
      "Epoch 28/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2234 - accuracy: 0.3134 - val_loss: 2.2990 - val_accuracy: 0.2933\n",
      "Epoch 29/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2213 - accuracy: 0.3139 - val_loss: 2.2940 - val_accuracy: 0.2942\n",
      "Epoch 30/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2152 - accuracy: 0.3159 - val_loss: 2.2932 - val_accuracy: 0.2953\n",
      "Epoch 31/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2103 - accuracy: 0.3168 - val_loss: 2.2933 - val_accuracy: 0.2945\n",
      "Epoch 32/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2074 - accuracy: 0.3177 - val_loss: 2.2945 - val_accuracy: 0.2935\n",
      "Epoch 33/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.2031 - accuracy: 0.3203 - val_loss: 2.2927 - val_accuracy: 0.2943\n",
      "Epoch 34/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1986 - accuracy: 0.3194 - val_loss: 2.2950 - val_accuracy: 0.2941\n",
      "Epoch 35/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1939 - accuracy: 0.3202 - val_loss: 2.2923 - val_accuracy: 0.2932\n",
      "Epoch 36/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1918 - accuracy: 0.3223 - val_loss: 2.2938 - val_accuracy: 0.2955\n",
      "Epoch 37/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1889 - accuracy: 0.3226 - val_loss: 2.2919 - val_accuracy: 0.2960\n",
      "Epoch 38/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1868 - accuracy: 0.3232 - val_loss: 2.2965 - val_accuracy: 0.2939\n",
      "Epoch 39/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1823 - accuracy: 0.3242 - val_loss: 2.2969 - val_accuracy: 0.2912\n",
      "Epoch 40/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1781 - accuracy: 0.3260 - val_loss: 2.2922 - val_accuracy: 0.2960\n",
      "Epoch 41/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1744 - accuracy: 0.3273 - val_loss: 2.2919 - val_accuracy: 0.2954\n",
      "Epoch 42/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1739 - accuracy: 0.3268 - val_loss: 2.2964 - val_accuracy: 0.2948\n",
      "Epoch 43/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1697 - accuracy: 0.3280 - val_loss: 2.2927 - val_accuracy: 0.2947\n",
      "Epoch 44/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1667 - accuracy: 0.3296 - val_loss: 2.2964 - val_accuracy: 0.2958\n",
      "Epoch 45/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1626 - accuracy: 0.3303 - val_loss: 2.3006 - val_accuracy: 0.2945\n",
      "Epoch 46/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1596 - accuracy: 0.3301 - val_loss: 2.2963 - val_accuracy: 0.2940\n",
      "Epoch 47/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1554 - accuracy: 0.3322 - val_loss: 2.2943 - val_accuracy: 0.2952\n",
      "Epoch 48/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1538 - accuracy: 0.3315 - val_loss: 2.2942 - val_accuracy: 0.2969\n",
      "Epoch 49/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1529 - accuracy: 0.3315 - val_loss: 2.2942 - val_accuracy: 0.2948\n",
      "Epoch 50/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1502 - accuracy: 0.3347 - val_loss: 2.2983 - val_accuracy: 0.2954\n",
      "Epoch 51/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1449 - accuracy: 0.3361 - val_loss: 2.2945 - val_accuracy: 0.2939\n",
      "Epoch 52/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1444 - accuracy: 0.3363 - val_loss: 2.2969 - val_accuracy: 0.2923\n",
      "Epoch 53/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1416 - accuracy: 0.3360 - val_loss: 2.2935 - val_accuracy: 0.2942\n",
      "Epoch 54/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1395 - accuracy: 0.3370 - val_loss: 2.3030 - val_accuracy: 0.2948\n",
      "Epoch 55/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1350 - accuracy: 0.3368 - val_loss: 2.2987 - val_accuracy: 0.2960\n",
      "Epoch 56/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1353 - accuracy: 0.3385 - val_loss: 2.2975 - val_accuracy: 0.2951\n",
      "Epoch 57/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.1339 - accuracy: 0.3379 - val_loss: 2.2959 - val_accuracy: 0.2946\n",
      "Epoch 58/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1304 - accuracy: 0.3409 - val_loss: 2.3065 - val_accuracy: 0.2949\n",
      "Epoch 59/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1277 - accuracy: 0.3399 - val_loss: 2.2987 - val_accuracy: 0.2946\n",
      "Epoch 60/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1262 - accuracy: 0.3414 - val_loss: 2.3038 - val_accuracy: 0.2941\n",
      "Epoch 61/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.1241 - accuracy: 0.3398 - val_loss: 2.2992 - val_accuracy: 0.2943\n",
      "Epoch 62/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1206 - accuracy: 0.3425 - val_loss: 2.3058 - val_accuracy: 0.2959\n",
      "Epoch 63/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1199 - accuracy: 0.3425 - val_loss: 2.3028 - val_accuracy: 0.2965\n",
      "Epoch 64/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1192 - accuracy: 0.3434 - val_loss: 2.2973 - val_accuracy: 0.2950\n",
      "Epoch 65/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1135 - accuracy: 0.3436 - val_loss: 2.3008 - val_accuracy: 0.2951\n",
      "Epoch 66/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1118 - accuracy: 0.3455 - val_loss: 2.3015 - val_accuracy: 0.2966\n",
      "Epoch 67/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1111 - accuracy: 0.3440 - val_loss: 2.3043 - val_accuracy: 0.2961\n",
      "Epoch 68/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1077 - accuracy: 0.3452 - val_loss: 2.3059 - val_accuracy: 0.2948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1099 - accuracy: 0.3432 - val_loss: 2.3055 - val_accuracy: 0.2963\n",
      "Epoch 70/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1077 - accuracy: 0.3450 - val_loss: 2.3080 - val_accuracy: 0.2955\n",
      "Epoch 71/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1028 - accuracy: 0.3481 - val_loss: 2.3026 - val_accuracy: 0.2968\n",
      "Epoch 72/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1008 - accuracy: 0.3493 - val_loss: 2.3033 - val_accuracy: 0.2971\n",
      "Epoch 73/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.1037 - accuracy: 0.3460 - val_loss: 2.3053 - val_accuracy: 0.2947\n",
      "Epoch 74/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.0982 - accuracy: 0.3473 - val_loss: 2.3079 - val_accuracy: 0.2944\n",
      "Epoch 75/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0975 - accuracy: 0.3479 - val_loss: 2.3078 - val_accuracy: 0.2952\n",
      "Epoch 76/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0945 - accuracy: 0.3489 - val_loss: 2.3103 - val_accuracy: 0.2954\n",
      "Epoch 77/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0931 - accuracy: 0.3492 - val_loss: 2.3082 - val_accuracy: 0.2942\n",
      "Epoch 78/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0938 - accuracy: 0.3489 - val_loss: 2.3097 - val_accuracy: 0.2967\n",
      "Epoch 79/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0911 - accuracy: 0.3502 - val_loss: 2.3070 - val_accuracy: 0.2955\n",
      "Epoch 80/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0911 - accuracy: 0.3496 - val_loss: 2.3146 - val_accuracy: 0.2951\n",
      "Epoch 81/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0867 - accuracy: 0.3507 - val_loss: 2.3104 - val_accuracy: 0.2982\n",
      "Epoch 82/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0848 - accuracy: 0.3514 - val_loss: 2.3113 - val_accuracy: 0.2960\n",
      "Epoch 83/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0843 - accuracy: 0.3530 - val_loss: 2.3131 - val_accuracy: 0.2952\n",
      "Epoch 84/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0845 - accuracy: 0.3513 - val_loss: 2.3126 - val_accuracy: 0.2944\n",
      "Epoch 85/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0807 - accuracy: 0.3526 - val_loss: 2.3143 - val_accuracy: 0.2970\n",
      "Epoch 86/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.0798 - accuracy: 0.3534 - val_loss: 2.3112 - val_accuracy: 0.2946\n",
      "Epoch 87/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0785 - accuracy: 0.3521 - val_loss: 2.3112 - val_accuracy: 0.2937\n",
      "Epoch 88/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0779 - accuracy: 0.3534 - val_loss: 2.3111 - val_accuracy: 0.2942\n",
      "Epoch 89/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0716 - accuracy: 0.3540 - val_loss: 2.3155 - val_accuracy: 0.2924\n",
      "Epoch 90/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.0744 - accuracy: 0.3551 - val_loss: 2.3192 - val_accuracy: 0.2931\n",
      "Epoch 91/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.0711 - accuracy: 0.3558 - val_loss: 2.3183 - val_accuracy: 0.2934\n",
      "Epoch 92/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0706 - accuracy: 0.3557 - val_loss: 2.3161 - val_accuracy: 0.2953\n",
      "Epoch 93/100\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.0685 - accuracy: 0.3559 - val_loss: 2.3161 - val_accuracy: 0.2961\n",
      "Epoch 94/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0677 - accuracy: 0.3574 - val_loss: 2.3158 - val_accuracy: 0.2953\n",
      "Epoch 95/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0670 - accuracy: 0.3564 - val_loss: 2.3186 - val_accuracy: 0.2971\n",
      "Epoch 96/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0650 - accuracy: 0.3583 - val_loss: 2.3204 - val_accuracy: 0.2950\n",
      "Epoch 97/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0644 - accuracy: 0.3563 - val_loss: 2.3188 - val_accuracy: 0.2938\n",
      "Epoch 98/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0638 - accuracy: 0.3578 - val_loss: 2.3231 - val_accuracy: 0.2941\n",
      "Epoch 99/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0616 - accuracy: 0.3585 - val_loss: 2.3159 - val_accuracy: 0.2940\n",
      "Epoch 100/100\n",
      "114922/114922 [==============================] - 0s 4us/sample - loss: 2.0591 - accuracy: 0.3590 - val_loss: 2.3263 - val_accuracy: 0.2924\n",
      "Restoring the best weights from epoch 100\n",
      "Training fold 5\n",
      "Train on 114925 samples, validate on 28719 samples\n",
      "Epoch 1/100\n",
      "114925/114925 [==============================] - 1s 8us/sample - loss: 2.9339 - accuracy: 0.1340 - val_loss: 2.6760 - val_accuracy: 0.2028\n",
      "Epoch 2/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.6201 - accuracy: 0.2080 - val_loss: 2.5435 - val_accuracy: 0.2287\n",
      "Epoch 3/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.5285 - accuracy: 0.2302 - val_loss: 2.4901 - val_accuracy: 0.2421\n",
      "Epoch 4/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.4796 - accuracy: 0.2436 - val_loss: 2.4516 - val_accuracy: 0.2548\n",
      "Epoch 5/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.4435 - accuracy: 0.2542 - val_loss: 2.4263 - val_accuracy: 0.2597\n",
      "Epoch 6/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.4170 - accuracy: 0.2596 - val_loss: 2.4052 - val_accuracy: 0.2650\n",
      "Epoch 7/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3958 - accuracy: 0.2653 - val_loss: 2.3857 - val_accuracy: 0.2727\n",
      "Epoch 8/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3792 - accuracy: 0.2697 - val_loss: 2.3769 - val_accuracy: 0.2744\n",
      "Epoch 9/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3594 - accuracy: 0.2749 - val_loss: 2.3748 - val_accuracy: 0.2735\n",
      "Epoch 10/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3479 - accuracy: 0.2798 - val_loss: 2.3704 - val_accuracy: 0.2759\n",
      "Epoch 11/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3350 - accuracy: 0.2831 - val_loss: 2.3518 - val_accuracy: 0.2821\n",
      "Epoch 12/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3263 - accuracy: 0.2839 - val_loss: 2.3528 - val_accuracy: 0.2797\n",
      "Epoch 13/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3157 - accuracy: 0.2875 - val_loss: 2.3434 - val_accuracy: 0.2834\n",
      "Epoch 14/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.3091 - accuracy: 0.2876 - val_loss: 2.3362 - val_accuracy: 0.2835\n",
      "Epoch 15/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2994 - accuracy: 0.2922 - val_loss: 2.3371 - val_accuracy: 0.2841\n",
      "Epoch 16/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2938 - accuracy: 0.2924 - val_loss: 2.3298 - val_accuracy: 0.2846\n",
      "Epoch 17/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2844 - accuracy: 0.2949 - val_loss: 2.3288 - val_accuracy: 0.2873\n",
      "Epoch 18/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2759 - accuracy: 0.2976 - val_loss: 2.3238 - val_accuracy: 0.2871\n",
      "Epoch 19/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2726 - accuracy: 0.2978 - val_loss: 2.3204 - val_accuracy: 0.2901\n",
      "Epoch 20/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2648 - accuracy: 0.2994 - val_loss: 2.3172 - val_accuracy: 0.2906\n",
      "Epoch 21/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2582 - accuracy: 0.3028 - val_loss: 2.3172 - val_accuracy: 0.2900\n",
      "Epoch 22/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2556 - accuracy: 0.3021 - val_loss: 2.3191 - val_accuracy: 0.2920\n",
      "Epoch 23/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2492 - accuracy: 0.3043 - val_loss: 2.3172 - val_accuracy: 0.2924\n",
      "Epoch 24/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2440 - accuracy: 0.3063 - val_loss: 2.3098 - val_accuracy: 0.2929\n",
      "Epoch 25/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2381 - accuracy: 0.3072 - val_loss: 2.3099 - val_accuracy: 0.2934\n",
      "Epoch 26/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2341 - accuracy: 0.3084 - val_loss: 2.3061 - val_accuracy: 0.2940\n",
      "Epoch 27/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2307 - accuracy: 0.3087 - val_loss: 2.3108 - val_accuracy: 0.2923\n",
      "Epoch 28/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2254 - accuracy: 0.3108 - val_loss: 2.3060 - val_accuracy: 0.2934\n",
      "Epoch 29/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2220 - accuracy: 0.3105 - val_loss: 2.3099 - val_accuracy: 0.2929\n",
      "Epoch 30/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2166 - accuracy: 0.3132 - val_loss: 2.3048 - val_accuracy: 0.2933\n",
      "Epoch 31/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2147 - accuracy: 0.3132 - val_loss: 2.3091 - val_accuracy: 0.2943\n",
      "Epoch 32/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2075 - accuracy: 0.3150 - val_loss: 2.3022 - val_accuracy: 0.2965\n",
      "Epoch 33/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2064 - accuracy: 0.3141 - val_loss: 2.3053 - val_accuracy: 0.2936\n",
      "Epoch 34/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.2025 - accuracy: 0.3169 - val_loss: 2.3007 - val_accuracy: 0.2963\n",
      "Epoch 35/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1968 - accuracy: 0.3184 - val_loss: 2.3031 - val_accuracy: 0.2961\n",
      "Epoch 36/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1939 - accuracy: 0.3193 - val_loss: 2.3033 - val_accuracy: 0.2957\n",
      "Epoch 37/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1929 - accuracy: 0.3195 - val_loss: 2.3067 - val_accuracy: 0.2935\n",
      "Epoch 38/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1881 - accuracy: 0.3218 - val_loss: 2.3036 - val_accuracy: 0.2956\n",
      "Epoch 39/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1845 - accuracy: 0.3219 - val_loss: 2.2995 - val_accuracy: 0.2956\n",
      "Epoch 40/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1802 - accuracy: 0.3223 - val_loss: 2.3007 - val_accuracy: 0.2958\n",
      "Epoch 41/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1779 - accuracy: 0.3227 - val_loss: 2.3035 - val_accuracy: 0.2978\n",
      "Epoch 42/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1787 - accuracy: 0.3238 - val_loss: 2.3051 - val_accuracy: 0.2959\n",
      "Epoch 43/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1721 - accuracy: 0.3250 - val_loss: 2.2974 - val_accuracy: 0.2980\n",
      "Epoch 44/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1684 - accuracy: 0.3254 - val_loss: 2.3031 - val_accuracy: 0.2948\n",
      "Epoch 45/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1656 - accuracy: 0.3265 - val_loss: 2.2997 - val_accuracy: 0.2957\n",
      "Epoch 46/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1654 - accuracy: 0.3270 - val_loss: 2.2995 - val_accuracy: 0.2956\n",
      "Epoch 47/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1611 - accuracy: 0.3286 - val_loss: 2.2977 - val_accuracy: 0.2951\n",
      "Epoch 48/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1583 - accuracy: 0.3279 - val_loss: 2.3013 - val_accuracy: 0.2942\n",
      "Epoch 49/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1564 - accuracy: 0.3294 - val_loss: 2.2991 - val_accuracy: 0.2954\n",
      "Epoch 50/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1514 - accuracy: 0.3311 - val_loss: 2.2984 - val_accuracy: 0.2972\n",
      "Epoch 51/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1502 - accuracy: 0.3342 - val_loss: 2.2970 - val_accuracy: 0.2997\n",
      "Epoch 52/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1487 - accuracy: 0.3329 - val_loss: 2.3055 - val_accuracy: 0.2973\n",
      "Epoch 53/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1474 - accuracy: 0.3311 - val_loss: 2.3026 - val_accuracy: 0.2980\n",
      "Epoch 54/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1429 - accuracy: 0.3330 - val_loss: 2.2993 - val_accuracy: 0.2982\n",
      "Epoch 55/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1383 - accuracy: 0.3362 - val_loss: 2.3008 - val_accuracy: 0.2976\n",
      "Epoch 56/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1357 - accuracy: 0.3365 - val_loss: 2.3014 - val_accuracy: 0.2985\n",
      "Epoch 57/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1353 - accuracy: 0.3355 - val_loss: 2.3017 - val_accuracy: 0.2966\n",
      "Epoch 58/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1362 - accuracy: 0.3349 - val_loss: 2.3017 - val_accuracy: 0.2985\n",
      "Epoch 59/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1293 - accuracy: 0.3382 - val_loss: 2.3059 - val_accuracy: 0.2980\n",
      "Epoch 60/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1302 - accuracy: 0.3373 - val_loss: 2.3008 - val_accuracy: 0.2984\n",
      "Epoch 61/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1294 - accuracy: 0.3371 - val_loss: 2.3021 - val_accuracy: 0.2978\n",
      "Epoch 62/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1242 - accuracy: 0.3402 - val_loss: 2.3058 - val_accuracy: 0.2965\n",
      "Epoch 63/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1227 - accuracy: 0.3392 - val_loss: 2.3058 - val_accuracy: 0.2976\n",
      "Epoch 64/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1196 - accuracy: 0.3407 - val_loss: 2.3038 - val_accuracy: 0.2984\n",
      "Epoch 65/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1207 - accuracy: 0.3403 - val_loss: 2.3076 - val_accuracy: 0.2964\n",
      "Epoch 66/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1170 - accuracy: 0.3407 - val_loss: 2.3063 - val_accuracy: 0.2978\n",
      "Epoch 67/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1169 - accuracy: 0.3410 - val_loss: 2.3051 - val_accuracy: 0.2967\n",
      "Epoch 68/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1117 - accuracy: 0.3416 - val_loss: 2.3033 - val_accuracy: 0.2976\n",
      "Epoch 69/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1111 - accuracy: 0.3421 - val_loss: 2.3034 - val_accuracy: 0.2972\n",
      "Epoch 70/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1085 - accuracy: 0.3426 - val_loss: 2.3095 - val_accuracy: 0.2973\n",
      "Epoch 71/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1049 - accuracy: 0.3443 - val_loss: 2.3108 - val_accuracy: 0.2977\n",
      "Epoch 72/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1032 - accuracy: 0.3441 - val_loss: 2.3096 - val_accuracy: 0.2974\n",
      "Epoch 73/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1047 - accuracy: 0.3442 - val_loss: 2.3118 - val_accuracy: 0.2987\n",
      "Epoch 74/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.1033 - accuracy: 0.3436 - val_loss: 2.3119 - val_accuracy: 0.2968\n",
      "Epoch 75/100\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.1003 - accuracy: 0.3449 - val_loss: 2.3139 - val_accuracy: 0.2984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0987 - accuracy: 0.3445 - val_loss: 2.3170 - val_accuracy: 0.2956\n",
      "Epoch 77/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0955 - accuracy: 0.3462 - val_loss: 2.3101 - val_accuracy: 0.3009\n",
      "Epoch 78/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0945 - accuracy: 0.3466 - val_loss: 2.3140 - val_accuracy: 0.2971\n",
      "Epoch 79/100\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.0925 - accuracy: 0.3489 - val_loss: 2.3110 - val_accuracy: 0.2987\n",
      "Epoch 80/100\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.0963 - accuracy: 0.3476 - val_loss: 2.3135 - val_accuracy: 0.2994\n",
      "Epoch 81/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0925 - accuracy: 0.3480 - val_loss: 2.3124 - val_accuracy: 0.2954\n",
      "Epoch 82/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0889 - accuracy: 0.3487 - val_loss: 2.3141 - val_accuracy: 0.2972\n",
      "Epoch 83/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0858 - accuracy: 0.3505 - val_loss: 2.3131 - val_accuracy: 0.2985\n",
      "Epoch 84/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0845 - accuracy: 0.3489 - val_loss: 2.3184 - val_accuracy: 0.2959\n",
      "Epoch 85/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0850 - accuracy: 0.3498 - val_loss: 2.3144 - val_accuracy: 0.2983\n",
      "Epoch 86/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0824 - accuracy: 0.3501 - val_loss: 2.3226 - val_accuracy: 0.2972\n",
      "Epoch 87/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0816 - accuracy: 0.3501 - val_loss: 2.3150 - val_accuracy: 0.2967\n",
      "Epoch 88/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0800 - accuracy: 0.3517 - val_loss: 2.3223 - val_accuracy: 0.2963\n",
      "Epoch 89/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0785 - accuracy: 0.3518 - val_loss: 2.3215 - val_accuracy: 0.2973\n",
      "Epoch 90/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0757 - accuracy: 0.3528 - val_loss: 2.3241 - val_accuracy: 0.2967\n",
      "Epoch 91/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0769 - accuracy: 0.3517 - val_loss: 2.3240 - val_accuracy: 0.2951\n",
      "Epoch 92/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0782 - accuracy: 0.3532 - val_loss: 2.3214 - val_accuracy: 0.2962\n",
      "Epoch 93/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0727 - accuracy: 0.3534 - val_loss: 2.3230 - val_accuracy: 0.2954\n",
      "Epoch 94/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0736 - accuracy: 0.3528 - val_loss: 2.3200 - val_accuracy: 0.2980\n",
      "Epoch 95/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0704 - accuracy: 0.3541 - val_loss: 2.3267 - val_accuracy: 0.2960\n",
      "Epoch 96/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0676 - accuracy: 0.3544 - val_loss: 2.3239 - val_accuracy: 0.2991\n",
      "Epoch 97/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0651 - accuracy: 0.3555 - val_loss: 2.3281 - val_accuracy: 0.2984\n",
      "Epoch 98/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0653 - accuracy: 0.3573 - val_loss: 2.3263 - val_accuracy: 0.2990\n",
      "Epoch 99/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0651 - accuracy: 0.3552 - val_loss: 2.3247 - val_accuracy: 0.2981\n",
      "Epoch 100/100\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.0640 - accuracy: 0.3557 - val_loss: 2.3283 - val_accuracy: 0.2988\n",
      "Restoring the best weights from epoch 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_micro</th>\n",
       "      <td>0.297472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_macro</th>\n",
       "      <td>0.278606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_accuracy</th>\n",
       "      <td>0.297472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_batch_val_accuracy</th>\n",
       "      <td>0.297472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_accuracy</th>\n",
       "      <td>0.325175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_loss</th>\n",
       "      <td>2.290579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loss</th>\n",
       "      <td>2.179349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>223.787570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "avg_val_f1_micro          0.297472\n",
       "avg_val_f1_macro          0.278606\n",
       "avg_val_accuracy          0.297472\n",
       "avg_batch_val_accuracy    0.297472\n",
       "avg_accuracy              0.325175\n",
       "avg_val_loss              2.290579\n",
       "avg_loss                  2.179349\n",
       "train_time              223.787570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_fold(x_train, y_train, x_val, y_val, run_name, fold=None):\n",
    "\n",
    "    input_shape = x_train[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    if fold is not None:\n",
    "        run_name += '_fold' + str(fold)\n",
    "        print('Training fold ' + str(fold))\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    weight_restorer = BestWeightsRestorer(monitor='val_loss', mode='min', verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=[x_val, y_val],\n",
    "        epochs=100,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board, weight_restorer],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    prob_predictions = model.predict(x_val)\n",
    "    predictions = prob_predictions.argmax(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "experiment_number += 1\n",
    "run_name = 'new_base_mlp_ssd_cv_' + str(experiment_number)\n",
    "\n",
    "results = resultsUtil.cross_validate(\n",
    "    x=ftrs,\n",
    "    y=lbls_oh,\n",
    "    y_label_encoded=lbl_encoded_lbls,\n",
    "    n_splits=5,\n",
    "    train_func=train_fold,\n",
    "    run_name=run_name\n",
    ")\n",
    "\n",
    "runUtil.save_run_results(run_name, results)\n",
    "\n",
    "resultsdf = pd.DataFrame([results]).transpose()\n",
    "\n",
    "display(resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 1s 8us/sample - loss: 2.8840 - accuracy: 0.1480\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.5760 - accuracy: 0.2193\n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.4905 - accuracy: 0.2415\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.4412 - accuracy: 0.2541\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.4105 - accuracy: 0.2628\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3856 - accuracy: 0.2689\n",
      "Epoch 7/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3684 - accuracy: 0.2738\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3538 - accuracy: 0.2780\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3435 - accuracy: 0.2792\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3294 - accuracy: 0.2830\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3201 - accuracy: 0.2870\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3107 - accuracy: 0.2882\n",
      "Epoch 13/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.3025 - accuracy: 0.2893\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2917 - accuracy: 0.2941\n",
      "Epoch 15/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2872 - accuracy: 0.2944\n",
      "Epoch 16/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2805 - accuracy: 0.2965\n",
      "Epoch 17/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2743 - accuracy: 0.2996\n",
      "Epoch 18/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2680 - accuracy: 0.3017\n",
      "Epoch 19/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2603 - accuracy: 0.3024\n",
      "Epoch 20/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2551 - accuracy: 0.3026\n",
      "Epoch 21/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2499 - accuracy: 0.3049\n",
      "Epoch 22/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2437 - accuracy: 0.3063\n",
      "Epoch 23/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2380 - accuracy: 0.3083\n",
      "Epoch 24/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2362 - accuracy: 0.3094\n",
      "Epoch 25/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2321 - accuracy: 0.3107\n",
      "Epoch 26/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2252 - accuracy: 0.3123\n",
      "Epoch 27/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2216 - accuracy: 0.3130\n",
      "Epoch 28/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2168 - accuracy: 0.3136\n",
      "Epoch 29/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2146 - accuracy: 0.3155\n",
      "Epoch 30/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2114 - accuracy: 0.3161\n",
      "Epoch 31/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2066 - accuracy: 0.3169\n",
      "Epoch 32/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.2027 - accuracy: 0.3187\n",
      "Epoch 33/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1999 - accuracy: 0.3194\n",
      "Epoch 34/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1953 - accuracy: 0.3215\n",
      "Epoch 35/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1927 - accuracy: 0.3207\n",
      "Epoch 36/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1906 - accuracy: 0.3212\n",
      "Epoch 37/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1871 - accuracy: 0.3226\n",
      "Epoch 38/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1844 - accuracy: 0.3234\n",
      "Epoch 39/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1809 - accuracy: 0.3240\n",
      "Epoch 40/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1783 - accuracy: 0.3251\n",
      "Epoch 41/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1757 - accuracy: 0.3258\n",
      "Epoch 42/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1718 - accuracy: 0.3259\n",
      "Epoch 43/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1695 - accuracy: 0.3281\n",
      "Epoch 44/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1673 - accuracy: 0.3287\n",
      "Epoch 45/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1651 - accuracy: 0.3290\n",
      "Epoch 46/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1599 - accuracy: 0.3304\n",
      "Epoch 47/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1595 - accuracy: 0.3289\n",
      "Epoch 48/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1558 - accuracy: 0.3306\n",
      "Epoch 49/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1535 - accuracy: 0.3321\n",
      "Epoch 50/50\n",
      "143644/143644 [==============================] - 1s 6us/sample - loss: 2.1520 - accuracy: 0.3311\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(x, y, run_name):\n",
    "    \n",
    "    save_path = constants.MODELS_PATH + run_name + '.h5' \n",
    "    \n",
    "    input_shape = x[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    \n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        epochs=50,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.save(save_path)\n",
    "\n",
    "\n",
    "train_final_model(ftrs, lbls_oh, 'base_mlp_ssd_final2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
