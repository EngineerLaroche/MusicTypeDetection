{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload chaque module spécifié par %aimport\n",
    "%autoreload 1\n",
    "\n",
    "# %aimport\n",
    "\n",
    "import joblib\n",
    "import itertools\n",
    "import pickle\n",
    "import os.path as path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from src import constants\n",
    "from src.kerasCallbacks import BestWeightsRestorer\n",
    "import src.results as resultsUtil\n",
    "import src.runUtil as runUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_feature_set(name):\n",
    "\n",
    "    file_path = path.join(constants.DATA_PATH, name + '.csv')\n",
    "    \n",
    "    ftrs = np.array(pd.read_csv(file_path, header=None).values[:,2:-1])\n",
    "    lbls = np.array(pd.read_csv(file_path, header=None).values[:,-1])\n",
    "    \n",
    "    return ftrs, lbls\n",
    "\n",
    "\n",
    "def scale_features(ftrs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    ftrs_scld = scaler.fit_transform(ftrs)\n",
    "    \n",
    "    return ftrs_scld\n",
    "\n",
    "def one_hot_labels(lbls):\n",
    "    \n",
    "    lbls_1d = lbls.reshape(len(lbls), 1)\n",
    "        \n",
    "    oh_encoder = OneHotEncoder(sparse=False)\n",
    "    lbls_oh = oh_encoder.fit_transform(lbls_1d)\n",
    "    \n",
    "    return lbls_oh\n",
    "\n",
    "def label_encode(lbls):\n",
    "    \n",
    "    lbl_encoder = LabelEncoder()\n",
    "    lbl_encoded_lbls = lbl_encoder.fit_transform(lbls)\n",
    "    \n",
    "    return lbl_encoded_lbls\n",
    "\n",
    "def unglue_feature_sets(glued_sets, sets_stop_index):\n",
    "    \n",
    "    sets = []\n",
    "    \n",
    "    stop_index = sets_stop_index[0]\n",
    "    sets.append(glued_sets[:, :stop_index])\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(sets_stop_index) - 1:\n",
    "        \n",
    "        start_index = sets_stop_index[i]\n",
    "        stop_index = sets_stop_index[i + 1]\n",
    "        \n",
    "        sets.append(glued_sets[:, start_index:stop_index])\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return sets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature sets\n",
    "\n",
    "if 'mary_ftrs_raw' in locals():\n",
    "    del mary_ftrs_raw\n",
    "if 'ssd_ftrs_raw' in locals():\n",
    "    del ssd_ftrs_raw\n",
    "if 'derivs_ftrs_raw' in locals():\n",
    "    del derivs_ftrs_raw\n",
    "if 'mfccs_ftrs_raw' in locals():\n",
    "    del mfccs_ftrs_raw\n",
    "\n",
    "mary_ftrs_raw, mary_lbls_raw = load_feature_set('marsyas_meta_split')\n",
    "ssd_ftrs_raw = load_feature_set('ssd_meta_split')[0]\n",
    "derivs_ftrs_raw = load_feature_set('jmirderivatives_meta_split')[0]\n",
    "mfccs_ftrs_raw = load_feature_set('jmirmfccs_meta_split')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marsyas dimension : 124\n",
      "ssd dimension : 168\n",
      "derivatives dimension : 96\n",
      "mfccs dimension : 26\n",
      "x dimension : 678\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "# Note that they are the same for every feature sets\n",
    "lbls_oh = one_hot_labels(mary_lbls_raw)\n",
    "lbls_lb = label_encode(mary_lbls_raw)\n",
    "\n",
    "# Feature pre-processing\n",
    "mary_ftrs = scale_features(mary_ftrs_raw)\n",
    "ssd_ftrs = scale_features(ssd_ftrs_raw)\n",
    "derivs_ftrs = scale_features(derivs_ftrs_raw)\n",
    "mfccs_ftrs = scale_features(mfccs_ftrs_raw)\n",
    "\n",
    "# x's elements order must be the same as the sub-models order \n",
    "# in the stacking ensemble\n",
    "x_split = [mary_ftrs, ssd_ftrs, derivs_ftrs, mfccs_ftrs, derivs_ftrs, ssd_ftrs]\n",
    "sets_len = [ftrs_set.shape[1] for ftrs_set in x_split]\n",
    "\n",
    "# Those are no longer required and use a huge ammount of ram\n",
    "del mary_ftrs_raw\n",
    "del ssd_ftrs_raw\n",
    "del derivs_ftrs_raw\n",
    "del mfccs_ftrs_raw\n",
    "\n",
    "print('marsyas dimension : ' +  str(mary_ftrs.shape[1]))\n",
    "print('ssd dimension : ' +  str(ssd_ftrs.shape[1]))\n",
    "print('derivatives dimension : ' +  str(derivs_ftrs.shape[1]))\n",
    "print('mfccs dimension : ' +  str(mfccs_ftrs.shape[1]))\n",
    "print('x dimension : ' + str(sum(sets_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.21.1 when using version 0.21.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the base models\n",
    "\n",
    "if 'mlp_mary_model' in locals():\n",
    "    del mlp_mary_model\n",
    "if 'mlp_ssd_model' in locals():\n",
    "    del mlp_ssd_model\n",
    "if 'mlp_derivs_model' in locals():\n",
    "    del mlp_derivs_model\n",
    "if 'mlp_mfccs_model' in locals():\n",
    "    del mlp_mfccs_model\n",
    "if 'svm_derivs_model' in locals():\n",
    "    del svm_derivs_model    \n",
    "if 'rf_ssd_model' in locals():\n",
    "    del rf_ssd_model\n",
    "\n",
    "mlp_mary_model = load_model(constants.MODELS_PATH + 'base_mlp_marsyas_final2.h5')\n",
    "mlp_ssd_model = load_model(constants.MODELS_PATH + 'base_mlp_ssd_final2.h5')\n",
    "mlp_derivs_model = load_model(constants.MODELS_PATH + 'base_mlp_deriv_final4.h5')\n",
    "mlp_mfccs_model = load_model(constants.MODELS_PATH + 'base_mlp_mfccs_final1.h5')\n",
    "svm_derivs_model = joblib.load(constants.MODELS_PATH + 'svm_final_1.joblib')\n",
    "rf_ssd_model = pickle.load(open(constants.MODELS_PATH + 'final_random_forest_2.pickle', 'rb'))\n",
    "\n",
    "base_models = [mlp_mary_model, mlp_ssd_model, mlp_derivs_model, mlp_mfccs_model]\n",
    "sklearn_models = [svm_derivs_model, rf_ssd_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_models_outputs_size = [25, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_model(base_keras_models, aux_models_outputs_size):\n",
    "    \"\"\"\n",
    "    Créer le méta-modèle keras. L'entré de ce modèle est la concaténation\n",
    "    des sorties des modèles de base keras et ensuite des inputs auxilières\n",
    "    pour les modèles de base non keras.\n",
    "    \n",
    "    Args:\n",
    "        base_keras_models: Une liste des modèles keras.\n",
    "        aux_inputs_size: Une liste contenant la size de chaque \n",
    "            entrées auxilière pour les modèles non keras.\n",
    "        aux_models_outputs_size: Une liste contenant la size de \n",
    "            la sortie de chaque modèles non keras lié aux entrées auxiliaires.\n",
    "    Returns:\n",
    "        Le modèle\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs_sizes = [model.output_shape[1] for model in base_models]\n",
    "    inputs_sizes.extend(aux_models_outputs_size)\n",
    "    \n",
    "    meta_inputs_size = sum(inputs_sizes)\n",
    "    \n",
    "    bases_outputs = []\n",
    "    ensemble_inputs = []\n",
    "    \n",
    "    for model_i, model in enumerate(base_models):\n",
    "        \n",
    "        ensemble_inputs.append(model.input)\n",
    "        bases_outputs.append(model.output)\n",
    "        \n",
    "        model.trainable = False\n",
    "        \n",
    "        for layer_i, layer in enumerate(model.layers):\n",
    "            layer.trainable = False\n",
    "    \n",
    "    for i, aux_model_output_size in enumerate(aux_models_outputs_size):\n",
    "        \n",
    "        aux_input = Input(shape=(aux_model_output_size,), name='aux_input_' + str(i))\n",
    "        \n",
    "        ensemble_inputs.append(aux_input)\n",
    "        bases_outputs.append(aux_input)\n",
    "    \n",
    "    meta_inputs = concatenate(bases_outputs)\n",
    "    \n",
    "    layer = Dense(meta_inputs_size, activation='relu', name='meta_input')(meta_inputs)\n",
    "    #layer = Dense(110, activation='relu', name='meta_1')(layer)\n",
    "    \n",
    "    layer = Dense(75, activation='relu', name='meta_1')(layer)\n",
    "    \n",
    "    meta_outputs= Dense(25, activation='softmax', name='meta_output')(layer)\n",
    "    \n",
    "    ensemble_model = Model(inputs=ensemble_inputs, outputs=meta_outputs)\n",
    "    \n",
    "    ensemble_model.compile(\n",
    "        optimizer=Adam(lr=0.001), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            CategoricalAccuracy(name='accuracy')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_ensemble_model(base_models, aux_models_outputs_size)\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=False, to_file='ensembl32.png')\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28716 samples, validate on 7195 samples\n",
      "Epoch 1/250\n",
      "28716/28716 [==============================] - 2s 87us/sample - loss: 3.1314 - accuracy: 0.1317 - val_loss: 3.0232 - val_accuracy: 0.1484\n",
      "Epoch 2/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.9015 - accuracy: 0.1805 - val_loss: 2.7319 - val_accuracy: 0.2357\n",
      "Epoch 3/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.6007 - accuracy: 0.2604 - val_loss: 2.4618 - val_accuracy: 0.2888\n",
      "Epoch 4/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.3810 - accuracy: 0.2977 - val_loss: 2.3084 - val_accuracy: 0.3130\n",
      "Epoch 5/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.2720 - accuracy: 0.3187 - val_loss: 2.2395 - val_accuracy: 0.3277\n",
      "Epoch 6/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.2185 - accuracy: 0.3266 - val_loss: 2.2056 - val_accuracy: 0.3326\n",
      "Epoch 7/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1885 - accuracy: 0.3315 - val_loss: 2.1801 - val_accuracy: 0.3395\n",
      "Epoch 8/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1694 - accuracy: 0.3351 - val_loss: 2.1659 - val_accuracy: 0.3433\n",
      "Epoch 9/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1551 - accuracy: 0.3403 - val_loss: 2.1559 - val_accuracy: 0.3433\n",
      "Epoch 10/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1463 - accuracy: 0.3448 - val_loss: 2.1511 - val_accuracy: 0.3469\n",
      "Epoch 11/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1370 - accuracy: 0.3457 - val_loss: 2.1436 - val_accuracy: 0.3457\n",
      "Epoch 12/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1310 - accuracy: 0.3450 - val_loss: 2.1417 - val_accuracy: 0.3455\n",
      "Epoch 13/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1255 - accuracy: 0.3482 - val_loss: 2.1354 - val_accuracy: 0.3476\n",
      "Epoch 14/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1191 - accuracy: 0.3514 - val_loss: 2.1340 - val_accuracy: 0.3497\n",
      "Epoch 15/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1186 - accuracy: 0.3490 - val_loss: 2.1327 - val_accuracy: 0.3514\n",
      "Epoch 16/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1132 - accuracy: 0.3504 - val_loss: 2.1290 - val_accuracy: 0.3504\n",
      "Epoch 17/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1064 - accuracy: 0.3533 - val_loss: 2.1293 - val_accuracy: 0.3508\n",
      "Epoch 18/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1046 - accuracy: 0.3531 - val_loss: 2.1268 - val_accuracy: 0.3537\n",
      "Epoch 19/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.1020 - accuracy: 0.3537 - val_loss: 2.1250 - val_accuracy: 0.3537\n",
      "Epoch 20/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0975 - accuracy: 0.3560 - val_loss: 2.1244 - val_accuracy: 0.3530\n",
      "Epoch 21/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0952 - accuracy: 0.3584 - val_loss: 2.1229 - val_accuracy: 0.3546\n",
      "Epoch 22/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0941 - accuracy: 0.3567 - val_loss: 2.1195 - val_accuracy: 0.3559\n",
      "Epoch 23/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0896 - accuracy: 0.3583 - val_loss: 2.1212 - val_accuracy: 0.3564\n",
      "Epoch 24/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0902 - accuracy: 0.3582 - val_loss: 2.1180 - val_accuracy: 0.3569\n",
      "Epoch 25/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0865 - accuracy: 0.3564 - val_loss: 2.1193 - val_accuracy: 0.3576\n",
      "Epoch 26/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0847 - accuracy: 0.3588 - val_loss: 2.1172 - val_accuracy: 0.3566\n",
      "Epoch 27/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0816 - accuracy: 0.3582 - val_loss: 2.1173 - val_accuracy: 0.3566\n",
      "Epoch 28/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0810 - accuracy: 0.3596 - val_loss: 2.1180 - val_accuracy: 0.3543\n",
      "Epoch 29/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0785 - accuracy: 0.3600 - val_loss: 2.1149 - val_accuracy: 0.3577\n",
      "Epoch 30/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0761 - accuracy: 0.3610 - val_loss: 2.1150 - val_accuracy: 0.3568\n",
      "Epoch 31/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0742 - accuracy: 0.3624 - val_loss: 2.1133 - val_accuracy: 0.3569\n",
      "Epoch 32/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0729 - accuracy: 0.3610 - val_loss: 2.1136 - val_accuracy: 0.3568\n",
      "Epoch 33/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0727 - accuracy: 0.3613 - val_loss: 2.1117 - val_accuracy: 0.3571\n",
      "Epoch 34/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0724 - accuracy: 0.3628 - val_loss: 2.1133 - val_accuracy: 0.3569\n",
      "Epoch 35/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0690 - accuracy: 0.3643 - val_loss: 2.1133 - val_accuracy: 0.3584\n",
      "Epoch 36/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0683 - accuracy: 0.3619 - val_loss: 2.1136 - val_accuracy: 0.3575\n",
      "Epoch 37/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0650 - accuracy: 0.3630 - val_loss: 2.1097 - val_accuracy: 0.3582\n",
      "Epoch 38/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0649 - accuracy: 0.3654 - val_loss: 2.1091 - val_accuracy: 0.3572\n",
      "Epoch 39/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0628 - accuracy: 0.3642 - val_loss: 2.1112 - val_accuracy: 0.3608\n",
      "Epoch 40/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0624 - accuracy: 0.3642 - val_loss: 2.1113 - val_accuracy: 0.3600\n",
      "Epoch 41/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0610 - accuracy: 0.3617 - val_loss: 2.1124 - val_accuracy: 0.3584\n",
      "Epoch 42/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0605 - accuracy: 0.3661 - val_loss: 2.1085 - val_accuracy: 0.3614\n",
      "Epoch 43/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0569 - accuracy: 0.3672 - val_loss: 2.1092 - val_accuracy: 0.3551\n",
      "Epoch 44/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0553 - accuracy: 0.3683 - val_loss: 2.1075 - val_accuracy: 0.3576\n",
      "Epoch 45/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0561 - accuracy: 0.3663 - val_loss: 2.1096 - val_accuracy: 0.3605\n",
      "Epoch 46/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0535 - accuracy: 0.3668 - val_loss: 2.1084 - val_accuracy: 0.3580\n",
      "Epoch 47/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0543 - accuracy: 0.3664 - val_loss: 2.1102 - val_accuracy: 0.3569\n",
      "Epoch 48/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0542 - accuracy: 0.3676 - val_loss: 2.1086 - val_accuracy: 0.3552\n",
      "Epoch 49/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0491 - accuracy: 0.3681 - val_loss: 2.1084 - val_accuracy: 0.3557\n",
      "Epoch 50/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0492 - accuracy: 0.3677 - val_loss: 2.1078 - val_accuracy: 0.3584\n",
      "Epoch 51/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0502 - accuracy: 0.3666 - val_loss: 2.1065 - val_accuracy: 0.3566\n",
      "Epoch 52/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0460 - accuracy: 0.3681 - val_loss: 2.1070 - val_accuracy: 0.3600\n",
      "Epoch 53/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0442 - accuracy: 0.3695 - val_loss: 2.1076 - val_accuracy: 0.3583\n",
      "Epoch 54/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0467 - accuracy: 0.3676 - val_loss: 2.1080 - val_accuracy: 0.3583\n",
      "Epoch 55/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0436 - accuracy: 0.3696 - val_loss: 2.1073 - val_accuracy: 0.3577\n",
      "Epoch 56/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0451 - accuracy: 0.3702 - val_loss: 2.1058 - val_accuracy: 0.3591\n",
      "Epoch 57/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0433 - accuracy: 0.3684 - val_loss: 2.1068 - val_accuracy: 0.3573\n",
      "Epoch 58/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0420 - accuracy: 0.3694 - val_loss: 2.1055 - val_accuracy: 0.3577\n",
      "Epoch 59/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0408 - accuracy: 0.3710 - val_loss: 2.1054 - val_accuracy: 0.3580\n",
      "Epoch 60/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0389 - accuracy: 0.3723 - val_loss: 2.1063 - val_accuracy: 0.3557\n",
      "Epoch 61/250\n",
      "28716/28716 [==============================] - 0s 10us/sample - loss: 2.0405 - accuracy: 0.3693 - val_loss: 2.1074 - val_accuracy: 0.3586\n",
      "Epoch 62/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0380 - accuracy: 0.3690 - val_loss: 2.1051 - val_accuracy: 0.3586\n",
      "Epoch 63/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0394 - accuracy: 0.3697 - val_loss: 2.1087 - val_accuracy: 0.3618\n",
      "Epoch 64/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0370 - accuracy: 0.3704 - val_loss: 2.1078 - val_accuracy: 0.3582\n",
      "Epoch 65/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0353 - accuracy: 0.3732 - val_loss: 2.1047 - val_accuracy: 0.3611\n",
      "Epoch 66/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0341 - accuracy: 0.3739 - val_loss: 2.1070 - val_accuracy: 0.3568\n",
      "Epoch 67/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0354 - accuracy: 0.3716 - val_loss: 2.1047 - val_accuracy: 0.3608\n",
      "Epoch 68/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0322 - accuracy: 0.3720 - val_loss: 2.1056 - val_accuracy: 0.3591\n",
      "Epoch 69/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0317 - accuracy: 0.3715 - val_loss: 2.1048 - val_accuracy: 0.3576\n",
      "Epoch 70/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0296 - accuracy: 0.3738 - val_loss: 2.1070 - val_accuracy: 0.3600\n",
      "Epoch 71/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0316 - accuracy: 0.3732 - val_loss: 2.1072 - val_accuracy: 0.3594\n",
      "Epoch 72/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0279 - accuracy: 0.3717 - val_loss: 2.1080 - val_accuracy: 0.3586\n",
      "Epoch 73/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0254 - accuracy: 0.3748 - val_loss: 2.1053 - val_accuracy: 0.3623\n",
      "Epoch 74/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0280 - accuracy: 0.3719 - val_loss: 2.1042 - val_accuracy: 0.3590\n",
      "Epoch 75/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0238 - accuracy: 0.3743 - val_loss: 2.1047 - val_accuracy: 0.3590\n",
      "Epoch 76/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0232 - accuracy: 0.3763 - val_loss: 2.1046 - val_accuracy: 0.3616\n",
      "Epoch 77/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0244 - accuracy: 0.3748 - val_loss: 2.1060 - val_accuracy: 0.3594\n",
      "Epoch 78/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0245 - accuracy: 0.3745 - val_loss: 2.1054 - val_accuracy: 0.3629\n",
      "Epoch 79/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0244 - accuracy: 0.3743 - val_loss: 2.1039 - val_accuracy: 0.3571\n",
      "Epoch 80/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0224 - accuracy: 0.3753 - val_loss: 2.1048 - val_accuracy: 0.3604\n",
      "Epoch 81/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0188 - accuracy: 0.3751 - val_loss: 2.1079 - val_accuracy: 0.3568\n",
      "Epoch 82/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0205 - accuracy: 0.3760 - val_loss: 2.1050 - val_accuracy: 0.3597\n",
      "Epoch 83/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0195 - accuracy: 0.3757 - val_loss: 2.1054 - val_accuracy: 0.3577\n",
      "Epoch 84/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0199 - accuracy: 0.3745 - val_loss: 2.1048 - val_accuracy: 0.3564\n",
      "Epoch 85/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0189 - accuracy: 0.3745 - val_loss: 2.1034 - val_accuracy: 0.3611\n",
      "Epoch 86/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0176 - accuracy: 0.3754 - val_loss: 2.1045 - val_accuracy: 0.3577\n",
      "Epoch 87/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0172 - accuracy: 0.3759 - val_loss: 2.1059 - val_accuracy: 0.3582\n",
      "Epoch 88/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0161 - accuracy: 0.3770 - val_loss: 2.1047 - val_accuracy: 0.3618\n",
      "Epoch 89/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0147 - accuracy: 0.3756 - val_loss: 2.1063 - val_accuracy: 0.3603\n",
      "Epoch 90/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0152 - accuracy: 0.3764 - val_loss: 2.1045 - val_accuracy: 0.3580\n",
      "Epoch 91/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0144 - accuracy: 0.3747 - val_loss: 2.1039 - val_accuracy: 0.3601\n",
      "Epoch 92/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0130 - accuracy: 0.3771 - val_loss: 2.1036 - val_accuracy: 0.3622\n",
      "Epoch 93/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0123 - accuracy: 0.3743 - val_loss: 2.1038 - val_accuracy: 0.3612\n",
      "Epoch 94/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0119 - accuracy: 0.3762 - val_loss: 2.1025 - val_accuracy: 0.3607\n",
      "Epoch 95/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0083 - accuracy: 0.3784 - val_loss: 2.1061 - val_accuracy: 0.3598\n",
      "Epoch 96/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0074 - accuracy: 0.3769 - val_loss: 2.1048 - val_accuracy: 0.3625\n",
      "Epoch 97/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0096 - accuracy: 0.3770 - val_loss: 2.1035 - val_accuracy: 0.3590\n",
      "Epoch 98/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0062 - accuracy: 0.3786 - val_loss: 2.1072 - val_accuracy: 0.3611\n",
      "Epoch 99/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0068 - accuracy: 0.3788 - val_loss: 2.1043 - val_accuracy: 0.3612\n",
      "Epoch 100/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0084 - accuracy: 0.3758 - val_loss: 2.1040 - val_accuracy: 0.3603\n",
      "Epoch 101/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0046 - accuracy: 0.3788 - val_loss: 2.1050 - val_accuracy: 0.3603\n",
      "Epoch 102/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0041 - accuracy: 0.3777 - val_loss: 2.1055 - val_accuracy: 0.3616\n",
      "Epoch 103/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0051 - accuracy: 0.3789 - val_loss: 2.1042 - val_accuracy: 0.3603\n",
      "Epoch 104/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0044 - accuracy: 0.3785 - val_loss: 2.1054 - val_accuracy: 0.3586\n",
      "Epoch 105/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0033 - accuracy: 0.3784 - val_loss: 2.1044 - val_accuracy: 0.3608\n",
      "Epoch 106/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0006 - accuracy: 0.3808 - val_loss: 2.1064 - val_accuracy: 0.3597\n",
      "Epoch 107/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0028 - accuracy: 0.3797 - val_loss: 2.1076 - val_accuracy: 0.3608\n",
      "Epoch 108/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0027 - accuracy: 0.3785 - val_loss: 2.1071 - val_accuracy: 0.3596\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9999 - accuracy: 0.3799 - val_loss: 2.1069 - val_accuracy: 0.3575\n",
      "Epoch 110/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 2.0016 - accuracy: 0.3785 - val_loss: 2.1067 - val_accuracy: 0.3580\n",
      "Epoch 111/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9992 - accuracy: 0.3797 - val_loss: 2.1060 - val_accuracy: 0.3579\n",
      "Epoch 112/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9981 - accuracy: 0.3807 - val_loss: 2.1055 - val_accuracy: 0.3593\n",
      "Epoch 113/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9992 - accuracy: 0.3792 - val_loss: 2.1076 - val_accuracy: 0.3609\n",
      "Epoch 114/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9972 - accuracy: 0.3793 - val_loss: 2.1037 - val_accuracy: 0.3584\n",
      "Epoch 115/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9961 - accuracy: 0.3808 - val_loss: 2.1042 - val_accuracy: 0.3590\n",
      "Epoch 116/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9960 - accuracy: 0.3818 - val_loss: 2.1048 - val_accuracy: 0.3619\n",
      "Epoch 117/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9953 - accuracy: 0.3801 - val_loss: 2.1061 - val_accuracy: 0.3618\n",
      "Epoch 118/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9950 - accuracy: 0.3795 - val_loss: 2.1086 - val_accuracy: 0.3583\n",
      "Epoch 119/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9955 - accuracy: 0.3776 - val_loss: 2.1059 - val_accuracy: 0.3571\n",
      "Epoch 120/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9924 - accuracy: 0.3805 - val_loss: 2.1039 - val_accuracy: 0.3597\n",
      "Epoch 121/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9906 - accuracy: 0.3824 - val_loss: 2.1050 - val_accuracy: 0.3582\n",
      "Epoch 122/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9898 - accuracy: 0.3804 - val_loss: 2.1049 - val_accuracy: 0.3596\n",
      "Epoch 123/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9901 - accuracy: 0.3789 - val_loss: 2.1055 - val_accuracy: 0.3583\n",
      "Epoch 124/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9883 - accuracy: 0.3812 - val_loss: 2.1064 - val_accuracy: 0.3593\n",
      "Epoch 125/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9888 - accuracy: 0.3821 - val_loss: 2.1050 - val_accuracy: 0.3576\n",
      "Epoch 126/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9878 - accuracy: 0.3824 - val_loss: 2.1066 - val_accuracy: 0.3580\n",
      "Epoch 127/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9875 - accuracy: 0.3816 - val_loss: 2.1064 - val_accuracy: 0.3582\n",
      "Epoch 128/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9860 - accuracy: 0.3828 - val_loss: 2.1074 - val_accuracy: 0.3623\n",
      "Epoch 129/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9868 - accuracy: 0.3836 - val_loss: 2.1050 - val_accuracy: 0.3586\n",
      "Epoch 130/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9867 - accuracy: 0.3817 - val_loss: 2.1061 - val_accuracy: 0.3605\n",
      "Epoch 131/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9837 - accuracy: 0.3846 - val_loss: 2.1052 - val_accuracy: 0.3589\n",
      "Epoch 132/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9842 - accuracy: 0.3823 - val_loss: 2.1052 - val_accuracy: 0.3571\n",
      "Epoch 133/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9813 - accuracy: 0.3852 - val_loss: 2.1051 - val_accuracy: 0.3590\n",
      "Epoch 134/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9822 - accuracy: 0.3825 - val_loss: 2.1082 - val_accuracy: 0.3607\n",
      "Epoch 135/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9809 - accuracy: 0.3844 - val_loss: 2.1071 - val_accuracy: 0.3584\n",
      "Epoch 136/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9831 - accuracy: 0.3858 - val_loss: 2.1087 - val_accuracy: 0.3566\n",
      "Epoch 137/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9822 - accuracy: 0.3840 - val_loss: 2.1101 - val_accuracy: 0.3576\n",
      "Epoch 138/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9795 - accuracy: 0.3856 - val_loss: 2.1081 - val_accuracy: 0.3596\n",
      "Epoch 139/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9808 - accuracy: 0.3859 - val_loss: 2.1082 - val_accuracy: 0.3618\n",
      "Epoch 140/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9791 - accuracy: 0.3862 - val_loss: 2.1070 - val_accuracy: 0.3598\n",
      "Epoch 141/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9785 - accuracy: 0.3847 - val_loss: 2.1053 - val_accuracy: 0.3584\n",
      "Epoch 142/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9783 - accuracy: 0.3837 - val_loss: 2.1047 - val_accuracy: 0.3596\n",
      "Epoch 143/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9759 - accuracy: 0.3863 - val_loss: 2.1079 - val_accuracy: 0.3573\n",
      "Epoch 144/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9756 - accuracy: 0.3856 - val_loss: 2.1078 - val_accuracy: 0.3569\n",
      "Epoch 145/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9756 - accuracy: 0.3846 - val_loss: 2.1093 - val_accuracy: 0.3571\n",
      "Epoch 146/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9747 - accuracy: 0.3881 - val_loss: 2.1075 - val_accuracy: 0.3577\n",
      "Epoch 147/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9697 - accuracy: 0.3878 - val_loss: 2.1088 - val_accuracy: 0.3605\n",
      "Epoch 148/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9732 - accuracy: 0.3831 - val_loss: 2.1084 - val_accuracy: 0.3586\n",
      "Epoch 149/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9718 - accuracy: 0.3869 - val_loss: 2.1071 - val_accuracy: 0.3584\n",
      "Epoch 150/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9749 - accuracy: 0.3855 - val_loss: 2.1074 - val_accuracy: 0.3572\n",
      "Epoch 151/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9716 - accuracy: 0.3856 - val_loss: 2.1078 - val_accuracy: 0.3559\n",
      "Epoch 152/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9699 - accuracy: 0.3888 - val_loss: 2.1100 - val_accuracy: 0.3593\n",
      "Epoch 153/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9714 - accuracy: 0.3860 - val_loss: 2.1070 - val_accuracy: 0.3572\n",
      "Epoch 154/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9699 - accuracy: 0.3862 - val_loss: 2.1088 - val_accuracy: 0.3557\n",
      "Epoch 155/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9674 - accuracy: 0.3884 - val_loss: 2.1088 - val_accuracy: 0.3562\n",
      "Epoch 156/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9668 - accuracy: 0.3879 - val_loss: 2.1072 - val_accuracy: 0.3565\n",
      "Epoch 157/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9638 - accuracy: 0.3874 - val_loss: 2.1100 - val_accuracy: 0.3587\n",
      "Epoch 158/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9657 - accuracy: 0.3873 - val_loss: 2.1087 - val_accuracy: 0.3594\n",
      "Epoch 159/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9643 - accuracy: 0.3893 - val_loss: 2.1102 - val_accuracy: 0.3609\n",
      "Epoch 160/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9660 - accuracy: 0.3884 - val_loss: 2.1098 - val_accuracy: 0.3621\n",
      "Epoch 161/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9645 - accuracy: 0.3873 - val_loss: 2.1077 - val_accuracy: 0.3596\n",
      "Epoch 162/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9656 - accuracy: 0.3890 - val_loss: 2.1087 - val_accuracy: 0.3576\n",
      "Epoch 163/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9616 - accuracy: 0.3897 - val_loss: 2.1091 - val_accuracy: 0.3584\n",
      "Epoch 164/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9624 - accuracy: 0.3879 - val_loss: 2.1089 - val_accuracy: 0.3594\n",
      "Epoch 165/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9614 - accuracy: 0.3903 - val_loss: 2.1123 - val_accuracy: 0.3561\n",
      "Epoch 166/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9600 - accuracy: 0.3910 - val_loss: 2.1113 - val_accuracy: 0.3579\n",
      "Epoch 167/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9624 - accuracy: 0.3867 - val_loss: 2.1094 - val_accuracy: 0.3580\n",
      "Epoch 168/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9622 - accuracy: 0.3898 - val_loss: 2.1087 - val_accuracy: 0.3558\n",
      "Epoch 169/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9602 - accuracy: 0.3915 - val_loss: 2.1100 - val_accuracy: 0.3566\n",
      "Epoch 170/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9577 - accuracy: 0.3912 - val_loss: 2.1094 - val_accuracy: 0.3584\n",
      "Epoch 171/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9570 - accuracy: 0.3915 - val_loss: 2.1117 - val_accuracy: 0.3576\n",
      "Epoch 172/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9570 - accuracy: 0.3903 - val_loss: 2.1135 - val_accuracy: 0.3575\n",
      "Epoch 173/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9554 - accuracy: 0.3902 - val_loss: 2.1113 - val_accuracy: 0.3575\n",
      "Epoch 174/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9541 - accuracy: 0.3938 - val_loss: 2.1119 - val_accuracy: 0.3579\n",
      "Epoch 175/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9560 - accuracy: 0.3926 - val_loss: 2.1117 - val_accuracy: 0.3575\n",
      "Epoch 176/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9550 - accuracy: 0.3913 - val_loss: 2.1116 - val_accuracy: 0.3614\n",
      "Epoch 177/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9534 - accuracy: 0.3916 - val_loss: 2.1100 - val_accuracy: 0.3590\n",
      "Epoch 178/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9531 - accuracy: 0.3920 - val_loss: 2.1121 - val_accuracy: 0.3596\n",
      "Epoch 179/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9510 - accuracy: 0.3925 - val_loss: 2.1125 - val_accuracy: 0.3608\n",
      "Epoch 180/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9509 - accuracy: 0.3915 - val_loss: 2.1148 - val_accuracy: 0.3544\n",
      "Epoch 181/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9508 - accuracy: 0.3916 - val_loss: 2.1118 - val_accuracy: 0.3583\n",
      "Epoch 182/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9517 - accuracy: 0.3915 - val_loss: 2.1121 - val_accuracy: 0.3593\n",
      "Epoch 183/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9482 - accuracy: 0.3918 - val_loss: 2.1122 - val_accuracy: 0.3579\n",
      "Epoch 184/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9484 - accuracy: 0.3914 - val_loss: 2.1111 - val_accuracy: 0.3609\n",
      "Epoch 185/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9469 - accuracy: 0.3948 - val_loss: 2.1131 - val_accuracy: 0.3625\n",
      "Epoch 186/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9487 - accuracy: 0.3915 - val_loss: 2.1175 - val_accuracy: 0.3598\n",
      "Epoch 187/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9477 - accuracy: 0.3911 - val_loss: 2.1135 - val_accuracy: 0.3569\n",
      "Epoch 188/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9462 - accuracy: 0.3938 - val_loss: 2.1133 - val_accuracy: 0.3611\n",
      "Epoch 189/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9451 - accuracy: 0.3927 - val_loss: 2.1166 - val_accuracy: 0.3597\n",
      "Epoch 190/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9449 - accuracy: 0.3924 - val_loss: 2.1130 - val_accuracy: 0.3609\n",
      "Epoch 191/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9429 - accuracy: 0.3939 - val_loss: 2.1164 - val_accuracy: 0.3557\n",
      "Epoch 192/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9422 - accuracy: 0.3945 - val_loss: 2.1150 - val_accuracy: 0.3562\n",
      "Epoch 193/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9424 - accuracy: 0.3950 - val_loss: 2.1158 - val_accuracy: 0.3568\n",
      "Epoch 194/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9437 - accuracy: 0.3930 - val_loss: 2.1169 - val_accuracy: 0.3566\n",
      "Epoch 195/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9424 - accuracy: 0.3941 - val_loss: 2.1165 - val_accuracy: 0.3612\n",
      "Epoch 196/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9416 - accuracy: 0.3939 - val_loss: 2.1161 - val_accuracy: 0.3550\n",
      "Epoch 197/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9395 - accuracy: 0.3944 - val_loss: 2.1147 - val_accuracy: 0.3577\n",
      "Epoch 198/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9393 - accuracy: 0.3945 - val_loss: 2.1178 - val_accuracy: 0.3565\n",
      "Epoch 199/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9368 - accuracy: 0.3946 - val_loss: 2.1174 - val_accuracy: 0.3582\n",
      "Epoch 200/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9384 - accuracy: 0.3954 - val_loss: 2.1174 - val_accuracy: 0.3540\n",
      "Epoch 201/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9358 - accuracy: 0.3964 - val_loss: 2.1158 - val_accuracy: 0.3576\n",
      "Epoch 202/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9357 - accuracy: 0.3958 - val_loss: 2.1182 - val_accuracy: 0.3540\n",
      "Epoch 203/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9382 - accuracy: 0.3943 - val_loss: 2.1184 - val_accuracy: 0.3540\n",
      "Epoch 204/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9353 - accuracy: 0.3980 - val_loss: 2.1174 - val_accuracy: 0.3573\n",
      "Epoch 205/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9353 - accuracy: 0.3962 - val_loss: 2.1158 - val_accuracy: 0.3565\n",
      "Epoch 206/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9318 - accuracy: 0.3971 - val_loss: 2.1193 - val_accuracy: 0.3579\n",
      "Epoch 207/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9332 - accuracy: 0.3961 - val_loss: 2.1186 - val_accuracy: 0.3562\n",
      "Epoch 208/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9308 - accuracy: 0.3972 - val_loss: 2.1214 - val_accuracy: 0.3537\n",
      "Epoch 209/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9337 - accuracy: 0.3964 - val_loss: 2.1181 - val_accuracy: 0.3568\n",
      "Epoch 210/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9305 - accuracy: 0.3953 - val_loss: 2.1213 - val_accuracy: 0.3562\n",
      "Epoch 211/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9327 - accuracy: 0.3981 - val_loss: 2.1177 - val_accuracy: 0.3591\n",
      "Epoch 212/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9265 - accuracy: 0.3980 - val_loss: 2.1186 - val_accuracy: 0.3577\n",
      "Epoch 213/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9306 - accuracy: 0.3971 - val_loss: 2.1183 - val_accuracy: 0.3594\n",
      "Epoch 214/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9292 - accuracy: 0.3978 - val_loss: 2.1180 - val_accuracy: 0.3576\n",
      "Epoch 215/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9303 - accuracy: 0.3959 - val_loss: 2.1183 - val_accuracy: 0.3558\n",
      "Epoch 216/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9298 - accuracy: 0.3961 - val_loss: 2.1243 - val_accuracy: 0.3569\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9274 - accuracy: 0.3982 - val_loss: 2.1233 - val_accuracy: 0.3537\n",
      "Epoch 218/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9268 - accuracy: 0.3978 - val_loss: 2.1204 - val_accuracy: 0.3594\n",
      "Epoch 219/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9258 - accuracy: 0.3975 - val_loss: 2.1206 - val_accuracy: 0.3582\n",
      "Epoch 220/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9253 - accuracy: 0.3973 - val_loss: 2.1213 - val_accuracy: 0.3579\n",
      "Epoch 221/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9235 - accuracy: 0.4008 - val_loss: 2.1217 - val_accuracy: 0.3569\n",
      "Epoch 222/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9237 - accuracy: 0.3993 - val_loss: 2.1199 - val_accuracy: 0.3582\n",
      "Epoch 223/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9247 - accuracy: 0.3994 - val_loss: 2.1212 - val_accuracy: 0.3589\n",
      "Epoch 224/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9265 - accuracy: 0.3983 - val_loss: 2.1213 - val_accuracy: 0.3571\n",
      "Epoch 225/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9221 - accuracy: 0.3986 - val_loss: 2.1221 - val_accuracy: 0.3557\n",
      "Epoch 226/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9195 - accuracy: 0.4019 - val_loss: 2.1238 - val_accuracy: 0.3554\n",
      "Epoch 227/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9211 - accuracy: 0.3998 - val_loss: 2.1213 - val_accuracy: 0.3561\n",
      "Epoch 228/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9225 - accuracy: 0.3978 - val_loss: 2.1220 - val_accuracy: 0.3571\n",
      "Epoch 229/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9191 - accuracy: 0.4000 - val_loss: 2.1220 - val_accuracy: 0.3593\n",
      "Epoch 230/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9171 - accuracy: 0.4014 - val_loss: 2.1229 - val_accuracy: 0.3576\n",
      "Epoch 231/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9166 - accuracy: 0.4004 - val_loss: 2.1249 - val_accuracy: 0.3543\n",
      "Epoch 232/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9161 - accuracy: 0.4005 - val_loss: 2.1238 - val_accuracy: 0.3586\n",
      "Epoch 233/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9156 - accuracy: 0.4024 - val_loss: 2.1223 - val_accuracy: 0.3601\n",
      "Epoch 234/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9144 - accuracy: 0.4009 - val_loss: 2.1242 - val_accuracy: 0.3555\n",
      "Epoch 235/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9124 - accuracy: 0.4008 - val_loss: 2.1257 - val_accuracy: 0.3565\n",
      "Epoch 236/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9152 - accuracy: 0.4012 - val_loss: 2.1246 - val_accuracy: 0.3562\n",
      "Epoch 237/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9152 - accuracy: 0.3998 - val_loss: 2.1265 - val_accuracy: 0.3591\n",
      "Epoch 238/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9135 - accuracy: 0.4002 - val_loss: 2.1241 - val_accuracy: 0.3587\n",
      "Epoch 239/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9123 - accuracy: 0.4035 - val_loss: 2.1269 - val_accuracy: 0.3558\n",
      "Epoch 240/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9104 - accuracy: 0.4058 - val_loss: 2.1291 - val_accuracy: 0.3552\n",
      "Epoch 241/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9116 - accuracy: 0.3994 - val_loss: 2.1283 - val_accuracy: 0.3551\n",
      "Epoch 242/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9122 - accuracy: 0.4027 - val_loss: 2.1331 - val_accuracy: 0.3514\n",
      "Epoch 243/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9115 - accuracy: 0.4027 - val_loss: 2.1273 - val_accuracy: 0.3544\n",
      "Epoch 244/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9081 - accuracy: 0.4028 - val_loss: 2.1265 - val_accuracy: 0.3576\n",
      "Epoch 245/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9065 - accuracy: 0.4027 - val_loss: 2.1262 - val_accuracy: 0.3568\n",
      "Epoch 246/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9075 - accuracy: 0.4026 - val_loss: 2.1261 - val_accuracy: 0.3572\n",
      "Epoch 247/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9058 - accuracy: 0.4057 - val_loss: 2.1270 - val_accuracy: 0.3590\n",
      "Epoch 248/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9034 - accuracy: 0.4052 - val_loss: 2.1275 - val_accuracy: 0.3554\n",
      "Epoch 249/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9072 - accuracy: 0.4037 - val_loss: 2.1278 - val_accuracy: 0.3575\n",
      "Epoch 250/250\n",
      "28716/28716 [==============================] - 0s 8us/sample - loss: 1.9025 - accuracy: 0.4063 - val_loss: 2.1280 - val_accuracy: 0.3604\n",
      "Training fold 2\n",
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28724 samples, validate on 7187 samples\n",
      "Epoch 1/250\n",
      "28724/28724 [==============================] - 3s 88us/sample - loss: 3.1568 - accuracy: 0.1380 - val_loss: 3.0550 - val_accuracy: 0.2251\n",
      "Epoch 2/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.9438 - accuracy: 0.2262 - val_loss: 2.7698 - val_accuracy: 0.2518\n",
      "Epoch 3/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.6353 - accuracy: 0.2641 - val_loss: 2.4587 - val_accuracy: 0.2823\n",
      "Epoch 4/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.3824 - accuracy: 0.2979 - val_loss: 2.2831 - val_accuracy: 0.3190\n",
      "Epoch 5/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.2617 - accuracy: 0.3194 - val_loss: 2.2153 - val_accuracy: 0.3305\n",
      "Epoch 6/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.2111 - accuracy: 0.3299 - val_loss: 2.1827 - val_accuracy: 0.3330\n",
      "Epoch 7/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1835 - accuracy: 0.3339 - val_loss: 2.1608 - val_accuracy: 0.3406\n",
      "Epoch 8/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1667 - accuracy: 0.3371 - val_loss: 2.1484 - val_accuracy: 0.3441\n",
      "Epoch 9/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1538 - accuracy: 0.3406 - val_loss: 2.1393 - val_accuracy: 0.3453\n",
      "Epoch 10/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1463 - accuracy: 0.3444 - val_loss: 2.1327 - val_accuracy: 0.3484\n",
      "Epoch 11/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1379 - accuracy: 0.3453 - val_loss: 2.1269 - val_accuracy: 0.3494\n",
      "Epoch 12/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1326 - accuracy: 0.3463 - val_loss: 2.1225 - val_accuracy: 0.3502\n",
      "Epoch 13/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1296 - accuracy: 0.3479 - val_loss: 2.1224 - val_accuracy: 0.3511\n",
      "Epoch 14/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1238 - accuracy: 0.3484 - val_loss: 2.1178 - val_accuracy: 0.3499\n",
      "Epoch 15/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1232 - accuracy: 0.3482 - val_loss: 2.1151 - val_accuracy: 0.3504\n",
      "Epoch 16/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1180 - accuracy: 0.3501 - val_loss: 2.1117 - val_accuracy: 0.3547\n",
      "Epoch 17/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1159 - accuracy: 0.3533 - val_loss: 2.1096 - val_accuracy: 0.3561\n",
      "Epoch 18/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1101 - accuracy: 0.3549 - val_loss: 2.1076 - val_accuracy: 0.3544\n",
      "Epoch 19/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1069 - accuracy: 0.3531 - val_loss: 2.1057 - val_accuracy: 0.3538\n",
      "Epoch 20/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1056 - accuracy: 0.3543 - val_loss: 2.1052 - val_accuracy: 0.3558\n",
      "Epoch 21/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1019 - accuracy: 0.3552 - val_loss: 2.1022 - val_accuracy: 0.3563\n",
      "Epoch 22/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.1011 - accuracy: 0.3554 - val_loss: 2.1018 - val_accuracy: 0.3544\n",
      "Epoch 23/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0963 - accuracy: 0.3580 - val_loss: 2.1009 - val_accuracy: 0.3554\n",
      "Epoch 24/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0958 - accuracy: 0.3576 - val_loss: 2.1022 - val_accuracy: 0.3538\n",
      "Epoch 25/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0932 - accuracy: 0.3589 - val_loss: 2.0983 - val_accuracy: 0.3568\n",
      "Epoch 26/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0905 - accuracy: 0.3582 - val_loss: 2.0975 - val_accuracy: 0.3587\n",
      "Epoch 27/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0885 - accuracy: 0.3587 - val_loss: 2.0948 - val_accuracy: 0.3568\n",
      "Epoch 28/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0872 - accuracy: 0.3598 - val_loss: 2.0971 - val_accuracy: 0.3573\n",
      "Epoch 29/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0848 - accuracy: 0.3618 - val_loss: 2.0951 - val_accuracy: 0.3569\n",
      "Epoch 30/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0824 - accuracy: 0.3620 - val_loss: 2.0939 - val_accuracy: 0.3573\n",
      "Epoch 31/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0815 - accuracy: 0.3630 - val_loss: 2.0947 - val_accuracy: 0.3573\n",
      "Epoch 32/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0803 - accuracy: 0.3644 - val_loss: 2.0907 - val_accuracy: 0.3615\n",
      "Epoch 33/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0780 - accuracy: 0.3625 - val_loss: 2.0915 - val_accuracy: 0.3600\n",
      "Epoch 34/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0756 - accuracy: 0.3618 - val_loss: 2.0892 - val_accuracy: 0.3604\n",
      "Epoch 35/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0743 - accuracy: 0.3651 - val_loss: 2.0898 - val_accuracy: 0.3575\n",
      "Epoch 36/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0740 - accuracy: 0.3630 - val_loss: 2.0888 - val_accuracy: 0.3583\n",
      "Epoch 37/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0703 - accuracy: 0.3652 - val_loss: 2.0884 - val_accuracy: 0.3625\n",
      "Epoch 38/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0708 - accuracy: 0.3657 - val_loss: 2.0878 - val_accuracy: 0.3581\n",
      "Epoch 39/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0658 - accuracy: 0.3656 - val_loss: 2.0893 - val_accuracy: 0.3566\n",
      "Epoch 40/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0647 - accuracy: 0.3663 - val_loss: 2.0890 - val_accuracy: 0.3602\n",
      "Epoch 41/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0673 - accuracy: 0.3655 - val_loss: 2.0880 - val_accuracy: 0.3570\n",
      "Epoch 42/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0649 - accuracy: 0.3665 - val_loss: 2.0858 - val_accuracy: 0.3615\n",
      "Epoch 43/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0616 - accuracy: 0.3675 - val_loss: 2.0862 - val_accuracy: 0.3620\n",
      "Epoch 44/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0619 - accuracy: 0.3677 - val_loss: 2.0847 - val_accuracy: 0.3630\n",
      "Epoch 45/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0623 - accuracy: 0.3662 - val_loss: 2.0854 - val_accuracy: 0.3622\n",
      "Epoch 46/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0588 - accuracy: 0.3682 - val_loss: 2.0853 - val_accuracy: 0.3605\n",
      "Epoch 47/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0573 - accuracy: 0.3667 - val_loss: 2.0848 - val_accuracy: 0.3612\n",
      "Epoch 48/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0569 - accuracy: 0.3682 - val_loss: 2.0859 - val_accuracy: 0.3609\n",
      "Epoch 49/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0573 - accuracy: 0.3671 - val_loss: 2.0853 - val_accuracy: 0.3601\n",
      "Epoch 50/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0536 - accuracy: 0.3704 - val_loss: 2.0852 - val_accuracy: 0.3588\n",
      "Epoch 51/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0550 - accuracy: 0.3670 - val_loss: 2.0844 - val_accuracy: 0.3629\n",
      "Epoch 52/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0522 - accuracy: 0.3701 - val_loss: 2.0852 - val_accuracy: 0.3604\n",
      "Epoch 53/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0518 - accuracy: 0.3687 - val_loss: 2.0835 - val_accuracy: 0.3625\n",
      "Epoch 54/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0495 - accuracy: 0.3723 - val_loss: 2.0859 - val_accuracy: 0.3593\n",
      "Epoch 55/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0495 - accuracy: 0.3681 - val_loss: 2.0831 - val_accuracy: 0.3613\n",
      "Epoch 56/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0474 - accuracy: 0.3712 - val_loss: 2.0834 - val_accuracy: 0.3611\n",
      "Epoch 57/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0471 - accuracy: 0.3727 - val_loss: 2.0856 - val_accuracy: 0.3611\n",
      "Epoch 58/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0471 - accuracy: 0.3718 - val_loss: 2.0828 - val_accuracy: 0.3634\n",
      "Epoch 59/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0462 - accuracy: 0.3717 - val_loss: 2.0826 - val_accuracy: 0.3633\n",
      "Epoch 60/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0453 - accuracy: 0.3702 - val_loss: 2.0834 - val_accuracy: 0.3602\n",
      "Epoch 61/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0415 - accuracy: 0.3731 - val_loss: 2.0829 - val_accuracy: 0.3602\n",
      "Epoch 62/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0408 - accuracy: 0.3718 - val_loss: 2.0828 - val_accuracy: 0.3629\n",
      "Epoch 63/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0407 - accuracy: 0.3744 - val_loss: 2.0827 - val_accuracy: 0.3634\n",
      "Epoch 64/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0380 - accuracy: 0.3726 - val_loss: 2.0837 - val_accuracy: 0.3632\n",
      "Epoch 65/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0391 - accuracy: 0.3726 - val_loss: 2.0827 - val_accuracy: 0.3623\n",
      "Epoch 66/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0388 - accuracy: 0.3722 - val_loss: 2.0846 - val_accuracy: 0.3640\n",
      "Epoch 67/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0389 - accuracy: 0.3733 - val_loss: 2.0835 - val_accuracy: 0.3619\n",
      "Epoch 68/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0373 - accuracy: 0.3728 - val_loss: 2.0839 - val_accuracy: 0.3637\n",
      "Epoch 69/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0351 - accuracy: 0.3771 - val_loss: 2.0840 - val_accuracy: 0.3615\n",
      "Epoch 70/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0357 - accuracy: 0.3743 - val_loss: 2.0834 - val_accuracy: 0.3622\n",
      "Epoch 71/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0355 - accuracy: 0.3738 - val_loss: 2.0845 - val_accuracy: 0.3637\n",
      "Epoch 72/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0317 - accuracy: 0.3748 - val_loss: 2.0817 - val_accuracy: 0.3609\n",
      "Epoch 73/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0330 - accuracy: 0.3737 - val_loss: 2.0825 - val_accuracy: 0.3629\n",
      "Epoch 74/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0293 - accuracy: 0.3752 - val_loss: 2.0824 - val_accuracy: 0.3659\n",
      "Epoch 75/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0287 - accuracy: 0.3747 - val_loss: 2.0811 - val_accuracy: 0.3643\n",
      "Epoch 76/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0278 - accuracy: 0.3759 - val_loss: 2.0823 - val_accuracy: 0.3626\n",
      "Epoch 77/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0277 - accuracy: 0.3773 - val_loss: 2.0827 - val_accuracy: 0.3622\n",
      "Epoch 78/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0261 - accuracy: 0.3771 - val_loss: 2.0828 - val_accuracy: 0.3645\n",
      "Epoch 79/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0273 - accuracy: 0.3784 - val_loss: 2.0833 - val_accuracy: 0.3632\n",
      "Epoch 80/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0250 - accuracy: 0.3763 - val_loss: 2.0811 - val_accuracy: 0.3675\n",
      "Epoch 81/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0249 - accuracy: 0.3763 - val_loss: 2.0857 - val_accuracy: 0.3594\n",
      "Epoch 82/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0213 - accuracy: 0.3783 - val_loss: 2.0851 - val_accuracy: 0.3634\n",
      "Epoch 83/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0236 - accuracy: 0.3769 - val_loss: 2.0824 - val_accuracy: 0.3657\n",
      "Epoch 84/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0209 - accuracy: 0.3790 - val_loss: 2.0828 - val_accuracy: 0.3609\n",
      "Epoch 85/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0218 - accuracy: 0.3783 - val_loss: 2.0812 - val_accuracy: 0.3627\n",
      "Epoch 86/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0202 - accuracy: 0.3799 - val_loss: 2.0815 - val_accuracy: 0.3650\n",
      "Epoch 87/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0184 - accuracy: 0.3768 - val_loss: 2.0832 - val_accuracy: 0.3616\n",
      "Epoch 88/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0187 - accuracy: 0.3773 - val_loss: 2.0840 - val_accuracy: 0.3601\n",
      "Epoch 89/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0178 - accuracy: 0.3785 - val_loss: 2.0819 - val_accuracy: 0.3636\n",
      "Epoch 90/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0165 - accuracy: 0.3783 - val_loss: 2.0817 - val_accuracy: 0.3679\n",
      "Epoch 91/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0190 - accuracy: 0.3776 - val_loss: 2.0828 - val_accuracy: 0.3645\n",
      "Epoch 92/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0149 - accuracy: 0.3795 - val_loss: 2.0830 - val_accuracy: 0.3623\n",
      "Epoch 93/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0147 - accuracy: 0.3788 - val_loss: 2.0820 - val_accuracy: 0.3659\n",
      "Epoch 94/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0132 - accuracy: 0.3799 - val_loss: 2.0854 - val_accuracy: 0.3619\n",
      "Epoch 95/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0131 - accuracy: 0.3802 - val_loss: 2.0846 - val_accuracy: 0.3607\n",
      "Epoch 96/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0110 - accuracy: 0.3802 - val_loss: 2.0826 - val_accuracy: 0.3632\n",
      "Epoch 97/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0093 - accuracy: 0.3790 - val_loss: 2.0822 - val_accuracy: 0.3643\n",
      "Epoch 98/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0124 - accuracy: 0.3794 - val_loss: 2.0836 - val_accuracy: 0.3643\n",
      "Epoch 99/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0099 - accuracy: 0.3796 - val_loss: 2.0843 - val_accuracy: 0.3615\n",
      "Epoch 100/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0097 - accuracy: 0.3788 - val_loss: 2.0839 - val_accuracy: 0.3615\n",
      "Epoch 101/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0084 - accuracy: 0.3833 - val_loss: 2.0845 - val_accuracy: 0.3595\n",
      "Epoch 102/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0108 - accuracy: 0.3822 - val_loss: 2.0836 - val_accuracy: 0.3641\n",
      "Epoch 103/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0071 - accuracy: 0.3811 - val_loss: 2.0826 - val_accuracy: 0.3632\n",
      "Epoch 104/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0038 - accuracy: 0.3823 - val_loss: 2.0824 - val_accuracy: 0.3651\n",
      "Epoch 105/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0080 - accuracy: 0.3802 - val_loss: 2.0871 - val_accuracy: 0.3625\n",
      "Epoch 106/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0068 - accuracy: 0.3814 - val_loss: 2.0840 - val_accuracy: 0.3616\n",
      "Epoch 107/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0029 - accuracy: 0.3824 - val_loss: 2.0828 - val_accuracy: 0.3657\n",
      "Epoch 108/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0015 - accuracy: 0.3836 - val_loss: 2.0836 - val_accuracy: 0.3634\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0024 - accuracy: 0.3799 - val_loss: 2.0837 - val_accuracy: 0.3625\n",
      "Epoch 110/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9991 - accuracy: 0.3828 - val_loss: 2.0853 - val_accuracy: 0.3655\n",
      "Epoch 111/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0007 - accuracy: 0.3830 - val_loss: 2.0838 - val_accuracy: 0.3627\n",
      "Epoch 112/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0028 - accuracy: 0.3814 - val_loss: 2.0847 - val_accuracy: 0.3616\n",
      "Epoch 113/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 2.0010 - accuracy: 0.3820 - val_loss: 2.0842 - val_accuracy: 0.3625\n",
      "Epoch 114/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9982 - accuracy: 0.3814 - val_loss: 2.0856 - val_accuracy: 0.3615\n",
      "Epoch 115/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9991 - accuracy: 0.3852 - val_loss: 2.0842 - val_accuracy: 0.3594\n",
      "Epoch 116/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9975 - accuracy: 0.3843 - val_loss: 2.0844 - val_accuracy: 0.3633\n",
      "Epoch 117/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9977 - accuracy: 0.3819 - val_loss: 2.0851 - val_accuracy: 0.3626\n",
      "Epoch 118/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9950 - accuracy: 0.3830 - val_loss: 2.0855 - val_accuracy: 0.3647\n",
      "Epoch 119/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9967 - accuracy: 0.3846 - val_loss: 2.0849 - val_accuracy: 0.3664\n",
      "Epoch 120/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9937 - accuracy: 0.3832 - val_loss: 2.0854 - val_accuracy: 0.3630\n",
      "Epoch 121/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9933 - accuracy: 0.3848 - val_loss: 2.0850 - val_accuracy: 0.3636\n",
      "Epoch 122/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9951 - accuracy: 0.3835 - val_loss: 2.0851 - val_accuracy: 0.3641\n",
      "Epoch 123/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9927 - accuracy: 0.3843 - val_loss: 2.0862 - val_accuracy: 0.3613\n",
      "Epoch 124/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9931 - accuracy: 0.3841 - val_loss: 2.0852 - val_accuracy: 0.3600\n",
      "Epoch 125/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9932 - accuracy: 0.3833 - val_loss: 2.0859 - val_accuracy: 0.3619\n",
      "Epoch 126/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9916 - accuracy: 0.3842 - val_loss: 2.0860 - val_accuracy: 0.3622\n",
      "Epoch 127/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9899 - accuracy: 0.3852 - val_loss: 2.0846 - val_accuracy: 0.3618\n",
      "Epoch 128/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9897 - accuracy: 0.3849 - val_loss: 2.0860 - val_accuracy: 0.3616\n",
      "Epoch 129/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9890 - accuracy: 0.3857 - val_loss: 2.0866 - val_accuracy: 0.3615\n",
      "Epoch 130/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9903 - accuracy: 0.3841 - val_loss: 2.0855 - val_accuracy: 0.3620\n",
      "Epoch 131/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9870 - accuracy: 0.3859 - val_loss: 2.0861 - val_accuracy: 0.3629\n",
      "Epoch 132/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9852 - accuracy: 0.3879 - val_loss: 2.0877 - val_accuracy: 0.3639\n",
      "Epoch 133/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9864 - accuracy: 0.3848 - val_loss: 2.0880 - val_accuracy: 0.3637\n",
      "Epoch 134/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9843 - accuracy: 0.3877 - val_loss: 2.0887 - val_accuracy: 0.3601\n",
      "Epoch 135/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9824 - accuracy: 0.3876 - val_loss: 2.0878 - val_accuracy: 0.3586\n",
      "Epoch 136/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9845 - accuracy: 0.3881 - val_loss: 2.0884 - val_accuracy: 0.3602\n",
      "Epoch 137/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9832 - accuracy: 0.3879 - val_loss: 2.0861 - val_accuracy: 0.3629\n",
      "Epoch 138/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9824 - accuracy: 0.3897 - val_loss: 2.0877 - val_accuracy: 0.3595\n",
      "Epoch 139/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9809 - accuracy: 0.3881 - val_loss: 2.0867 - val_accuracy: 0.3634\n",
      "Epoch 140/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9810 - accuracy: 0.3880 - val_loss: 2.0901 - val_accuracy: 0.3643\n",
      "Epoch 141/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9803 - accuracy: 0.3872 - val_loss: 2.0886 - val_accuracy: 0.3613\n",
      "Epoch 142/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9820 - accuracy: 0.3877 - val_loss: 2.0876 - val_accuracy: 0.3627\n",
      "Epoch 143/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9805 - accuracy: 0.3891 - val_loss: 2.0871 - val_accuracy: 0.3625\n",
      "Epoch 144/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9778 - accuracy: 0.3894 - val_loss: 2.0885 - val_accuracy: 0.3607\n",
      "Epoch 145/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9767 - accuracy: 0.3870 - val_loss: 2.0885 - val_accuracy: 0.3607\n",
      "Epoch 146/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9781 - accuracy: 0.3874 - val_loss: 2.0896 - val_accuracy: 0.3598\n",
      "Epoch 147/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9770 - accuracy: 0.3870 - val_loss: 2.0862 - val_accuracy: 0.3629\n",
      "Epoch 148/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9738 - accuracy: 0.3896 - val_loss: 2.0878 - val_accuracy: 0.3626\n",
      "Epoch 149/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9715 - accuracy: 0.3902 - val_loss: 2.0883 - val_accuracy: 0.3637\n",
      "Epoch 150/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9742 - accuracy: 0.3888 - val_loss: 2.0875 - val_accuracy: 0.3627\n",
      "Epoch 151/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9748 - accuracy: 0.3890 - val_loss: 2.0880 - val_accuracy: 0.3612\n",
      "Epoch 152/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9725 - accuracy: 0.3880 - val_loss: 2.0885 - val_accuracy: 0.3633\n",
      "Epoch 153/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9701 - accuracy: 0.3901 - val_loss: 2.0893 - val_accuracy: 0.3630\n",
      "Epoch 154/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9709 - accuracy: 0.3908 - val_loss: 2.0880 - val_accuracy: 0.3636\n",
      "Epoch 155/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9712 - accuracy: 0.3902 - val_loss: 2.0884 - val_accuracy: 0.3632\n",
      "Epoch 156/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9694 - accuracy: 0.3903 - val_loss: 2.0901 - val_accuracy: 0.3579\n",
      "Epoch 157/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9677 - accuracy: 0.3912 - val_loss: 2.0898 - val_accuracy: 0.3623\n",
      "Epoch 158/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9696 - accuracy: 0.3924 - val_loss: 2.0902 - val_accuracy: 0.3591\n",
      "Epoch 159/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9702 - accuracy: 0.3894 - val_loss: 2.0903 - val_accuracy: 0.3600\n",
      "Epoch 160/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9656 - accuracy: 0.3921 - val_loss: 2.0921 - val_accuracy: 0.3593\n",
      "Epoch 161/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9661 - accuracy: 0.3913 - val_loss: 2.0919 - val_accuracy: 0.3595\n",
      "Epoch 162/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9671 - accuracy: 0.3902 - val_loss: 2.0898 - val_accuracy: 0.3609\n",
      "Epoch 163/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9650 - accuracy: 0.3931 - val_loss: 2.0899 - val_accuracy: 0.3622\n",
      "Epoch 164/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9652 - accuracy: 0.3913 - val_loss: 2.0908 - val_accuracy: 0.3609\n",
      "Epoch 165/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9642 - accuracy: 0.3937 - val_loss: 2.0901 - val_accuracy: 0.3613\n",
      "Epoch 166/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9641 - accuracy: 0.3940 - val_loss: 2.0905 - val_accuracy: 0.3583\n",
      "Epoch 167/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9654 - accuracy: 0.3923 - val_loss: 2.0912 - val_accuracy: 0.3602\n",
      "Epoch 168/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9616 - accuracy: 0.3932 - val_loss: 2.0925 - val_accuracy: 0.3602\n",
      "Epoch 169/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9602 - accuracy: 0.3916 - val_loss: 2.0904 - val_accuracy: 0.3630\n",
      "Epoch 170/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9616 - accuracy: 0.3924 - val_loss: 2.0908 - val_accuracy: 0.3611\n",
      "Epoch 171/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9617 - accuracy: 0.3950 - val_loss: 2.0916 - val_accuracy: 0.3605\n",
      "Epoch 172/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9580 - accuracy: 0.3929 - val_loss: 2.0931 - val_accuracy: 0.3623\n",
      "Epoch 173/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9581 - accuracy: 0.3940 - val_loss: 2.0912 - val_accuracy: 0.3607\n",
      "Epoch 174/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9572 - accuracy: 0.3954 - val_loss: 2.0914 - val_accuracy: 0.3613\n",
      "Epoch 175/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9605 - accuracy: 0.3935 - val_loss: 2.0927 - val_accuracy: 0.3605\n",
      "Epoch 176/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9585 - accuracy: 0.3939 - val_loss: 2.0921 - val_accuracy: 0.3605\n",
      "Epoch 177/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9562 - accuracy: 0.3972 - val_loss: 2.0911 - val_accuracy: 0.3625\n",
      "Epoch 178/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9541 - accuracy: 0.3953 - val_loss: 2.0919 - val_accuracy: 0.3604\n",
      "Epoch 179/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9556 - accuracy: 0.3937 - val_loss: 2.0926 - val_accuracy: 0.3630\n",
      "Epoch 180/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9537 - accuracy: 0.3943 - val_loss: 2.0943 - val_accuracy: 0.3612\n",
      "Epoch 181/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9518 - accuracy: 0.3959 - val_loss: 2.0946 - val_accuracy: 0.3622\n",
      "Epoch 182/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9546 - accuracy: 0.3965 - val_loss: 2.0908 - val_accuracy: 0.3611\n",
      "Epoch 183/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9504 - accuracy: 0.3950 - val_loss: 2.0933 - val_accuracy: 0.3608\n",
      "Epoch 184/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9520 - accuracy: 0.3948 - val_loss: 2.0916 - val_accuracy: 0.3629\n",
      "Epoch 185/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9484 - accuracy: 0.3946 - val_loss: 2.0911 - val_accuracy: 0.3620\n",
      "Epoch 186/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9511 - accuracy: 0.3957 - val_loss: 2.0919 - val_accuracy: 0.3608\n",
      "Epoch 187/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9497 - accuracy: 0.3952 - val_loss: 2.0912 - val_accuracy: 0.3633\n",
      "Epoch 188/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9497 - accuracy: 0.3932 - val_loss: 2.0925 - val_accuracy: 0.3623\n",
      "Epoch 189/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9489 - accuracy: 0.3969 - val_loss: 2.0937 - val_accuracy: 0.3576\n",
      "Epoch 190/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9483 - accuracy: 0.3970 - val_loss: 2.0916 - val_accuracy: 0.3607\n",
      "Epoch 191/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9468 - accuracy: 0.3980 - val_loss: 2.0940 - val_accuracy: 0.3608\n",
      "Epoch 192/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9450 - accuracy: 0.3965 - val_loss: 2.0965 - val_accuracy: 0.3598\n",
      "Epoch 193/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9459 - accuracy: 0.3981 - val_loss: 2.0970 - val_accuracy: 0.3597\n",
      "Epoch 194/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9472 - accuracy: 0.3962 - val_loss: 2.0935 - val_accuracy: 0.3601\n",
      "Epoch 195/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9440 - accuracy: 0.3985 - val_loss: 2.0937 - val_accuracy: 0.3597\n",
      "Epoch 196/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9440 - accuracy: 0.3983 - val_loss: 2.0933 - val_accuracy: 0.3615\n",
      "Epoch 197/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9421 - accuracy: 0.3978 - val_loss: 2.0962 - val_accuracy: 0.3605\n",
      "Epoch 198/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9391 - accuracy: 0.4001 - val_loss: 2.0957 - val_accuracy: 0.3630\n",
      "Epoch 199/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9398 - accuracy: 0.3991 - val_loss: 2.0963 - val_accuracy: 0.3601\n",
      "Epoch 200/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9422 - accuracy: 0.3976 - val_loss: 2.0943 - val_accuracy: 0.3591\n",
      "Epoch 201/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9413 - accuracy: 0.3981 - val_loss: 2.0957 - val_accuracy: 0.3587\n",
      "Epoch 202/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9395 - accuracy: 0.4005 - val_loss: 2.0946 - val_accuracy: 0.3575\n",
      "Epoch 203/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9393 - accuracy: 0.4009 - val_loss: 2.0961 - val_accuracy: 0.3597\n",
      "Epoch 204/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9365 - accuracy: 0.4016 - val_loss: 2.0954 - val_accuracy: 0.3570\n",
      "Epoch 205/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9374 - accuracy: 0.4014 - val_loss: 2.0952 - val_accuracy: 0.3590\n",
      "Epoch 206/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9359 - accuracy: 0.4013 - val_loss: 2.0963 - val_accuracy: 0.3623\n",
      "Epoch 207/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9347 - accuracy: 0.3994 - val_loss: 2.0952 - val_accuracy: 0.3600\n",
      "Epoch 208/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9330 - accuracy: 0.4014 - val_loss: 2.0956 - val_accuracy: 0.3608\n",
      "Epoch 209/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9336 - accuracy: 0.4008 - val_loss: 2.0963 - val_accuracy: 0.3583\n",
      "Epoch 210/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9331 - accuracy: 0.3998 - val_loss: 2.0965 - val_accuracy: 0.3587\n",
      "Epoch 211/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9316 - accuracy: 0.4037 - val_loss: 2.0983 - val_accuracy: 0.3569\n",
      "Epoch 212/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9330 - accuracy: 0.3996 - val_loss: 2.0977 - val_accuracy: 0.3576\n",
      "Epoch 213/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9271 - accuracy: 0.4034 - val_loss: 2.0960 - val_accuracy: 0.3591\n",
      "Epoch 214/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9303 - accuracy: 0.3998 - val_loss: 2.0991 - val_accuracy: 0.3587\n",
      "Epoch 215/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9317 - accuracy: 0.3994 - val_loss: 2.0968 - val_accuracy: 0.3580\n",
      "Epoch 216/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9283 - accuracy: 0.4022 - val_loss: 2.0971 - val_accuracy: 0.3593\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9273 - accuracy: 0.4036 - val_loss: 2.0976 - val_accuracy: 0.3579\n",
      "Epoch 218/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9260 - accuracy: 0.4026 - val_loss: 2.0965 - val_accuracy: 0.3600\n",
      "Epoch 219/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9265 - accuracy: 0.4032 - val_loss: 2.0975 - val_accuracy: 0.3598\n",
      "Epoch 220/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9262 - accuracy: 0.4042 - val_loss: 2.0982 - val_accuracy: 0.3608\n",
      "Epoch 221/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9268 - accuracy: 0.4014 - val_loss: 2.0977 - val_accuracy: 0.3588\n",
      "Epoch 222/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9242 - accuracy: 0.4028 - val_loss: 2.0995 - val_accuracy: 0.3620\n",
      "Epoch 223/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9261 - accuracy: 0.4025 - val_loss: 2.0973 - val_accuracy: 0.3611\n",
      "Epoch 224/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9218 - accuracy: 0.4038 - val_loss: 2.0995 - val_accuracy: 0.3629\n",
      "Epoch 225/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9235 - accuracy: 0.4033 - val_loss: 2.0983 - val_accuracy: 0.3554\n",
      "Epoch 226/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9209 - accuracy: 0.4051 - val_loss: 2.1008 - val_accuracy: 0.3602\n",
      "Epoch 227/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9210 - accuracy: 0.4023 - val_loss: 2.1003 - val_accuracy: 0.3598\n",
      "Epoch 228/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9224 - accuracy: 0.4048 - val_loss: 2.0996 - val_accuracy: 0.3595\n",
      "Epoch 229/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9198 - accuracy: 0.4041 - val_loss: 2.1001 - val_accuracy: 0.3590\n",
      "Epoch 230/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9192 - accuracy: 0.4034 - val_loss: 2.1009 - val_accuracy: 0.3597\n",
      "Epoch 231/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9221 - accuracy: 0.4045 - val_loss: 2.0988 - val_accuracy: 0.3615\n",
      "Epoch 232/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9177 - accuracy: 0.4054 - val_loss: 2.1013 - val_accuracy: 0.3555\n",
      "Epoch 233/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9168 - accuracy: 0.4037 - val_loss: 2.1002 - val_accuracy: 0.3572\n",
      "Epoch 234/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9157 - accuracy: 0.4048 - val_loss: 2.1021 - val_accuracy: 0.3570\n",
      "Epoch 235/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9150 - accuracy: 0.4045 - val_loss: 2.1000 - val_accuracy: 0.3608\n",
      "Epoch 236/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9146 - accuracy: 0.4052 - val_loss: 2.1014 - val_accuracy: 0.3591\n",
      "Epoch 237/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9150 - accuracy: 0.4048 - val_loss: 2.1016 - val_accuracy: 0.3590\n",
      "Epoch 238/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9125 - accuracy: 0.4064 - val_loss: 2.1052 - val_accuracy: 0.3551\n",
      "Epoch 239/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9116 - accuracy: 0.4083 - val_loss: 2.1023 - val_accuracy: 0.3565\n",
      "Epoch 240/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9123 - accuracy: 0.4056 - val_loss: 2.1004 - val_accuracy: 0.3609\n",
      "Epoch 241/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9108 - accuracy: 0.4073 - val_loss: 2.1021 - val_accuracy: 0.3591\n",
      "Epoch 242/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9100 - accuracy: 0.4080 - val_loss: 2.1016 - val_accuracy: 0.3598\n",
      "Epoch 243/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9082 - accuracy: 0.4062 - val_loss: 2.1014 - val_accuracy: 0.3594\n",
      "Epoch 244/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9075 - accuracy: 0.4090 - val_loss: 2.1053 - val_accuracy: 0.3588\n",
      "Epoch 245/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9059 - accuracy: 0.4057 - val_loss: 2.1034 - val_accuracy: 0.3573\n",
      "Epoch 246/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9053 - accuracy: 0.4085 - val_loss: 2.1053 - val_accuracy: 0.3541\n",
      "Epoch 247/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9032 - accuracy: 0.4107 - val_loss: 2.1068 - val_accuracy: 0.3608\n",
      "Epoch 248/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9044 - accuracy: 0.4104 - val_loss: 2.1028 - val_accuracy: 0.3581\n",
      "Epoch 249/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9059 - accuracy: 0.4097 - val_loss: 2.1035 - val_accuracy: 0.3588\n",
      "Epoch 250/250\n",
      "28724/28724 [==============================] - 0s 8us/sample - loss: 1.9038 - accuracy: 0.4076 - val_loss: 2.1054 - val_accuracy: 0.3547\n",
      "Training fold 3\n",
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28731 samples, validate on 7180 samples\n",
      "Epoch 1/250\n",
      "28731/28731 [==============================] - 3s 88us/sample - loss: 3.1307 - accuracy: 0.1290 - val_loss: 3.0118 - val_accuracy: 0.1865\n",
      "Epoch 2/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.8868 - accuracy: 0.2153 - val_loss: 2.7112 - val_accuracy: 0.2458\n",
      "Epoch 3/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.5857 - accuracy: 0.2645 - val_loss: 2.4370 - val_accuracy: 0.2986\n",
      "Epoch 4/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.3661 - accuracy: 0.3046 - val_loss: 2.2887 - val_accuracy: 0.3208\n",
      "Epoch 5/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.2621 - accuracy: 0.3219 - val_loss: 2.2248 - val_accuracy: 0.3286\n",
      "Epoch 6/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.2143 - accuracy: 0.3305 - val_loss: 2.1928 - val_accuracy: 0.3322\n",
      "Epoch 7/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1881 - accuracy: 0.3359 - val_loss: 2.1730 - val_accuracy: 0.3361\n",
      "Epoch 8/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1691 - accuracy: 0.3399 - val_loss: 2.1603 - val_accuracy: 0.3432\n",
      "Epoch 9/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1537 - accuracy: 0.3414 - val_loss: 2.1489 - val_accuracy: 0.3435\n",
      "Epoch 10/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1461 - accuracy: 0.3445 - val_loss: 2.1450 - val_accuracy: 0.3464\n",
      "Epoch 11/250\n",
      "28731/28731 [==============================] - 0s 9us/sample - loss: 2.1386 - accuracy: 0.3448 - val_loss: 2.1383 - val_accuracy: 0.3468\n",
      "Epoch 12/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1328 - accuracy: 0.3476 - val_loss: 2.1320 - val_accuracy: 0.3515\n",
      "Epoch 13/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1282 - accuracy: 0.3495 - val_loss: 2.1297 - val_accuracy: 0.3528\n",
      "Epoch 14/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1211 - accuracy: 0.3508 - val_loss: 2.1259 - val_accuracy: 0.3524\n",
      "Epoch 15/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1171 - accuracy: 0.3514 - val_loss: 2.1227 - val_accuracy: 0.3546\n",
      "Epoch 16/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1156 - accuracy: 0.3504 - val_loss: 2.1200 - val_accuracy: 0.3540\n",
      "Epoch 17/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1119 - accuracy: 0.3533 - val_loss: 2.1189 - val_accuracy: 0.3532\n",
      "Epoch 18/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1072 - accuracy: 0.3576 - val_loss: 2.1163 - val_accuracy: 0.3556\n",
      "Epoch 19/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1066 - accuracy: 0.3543 - val_loss: 2.1151 - val_accuracy: 0.3560\n",
      "Epoch 20/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1002 - accuracy: 0.3541 - val_loss: 2.1116 - val_accuracy: 0.3570\n",
      "Epoch 21/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.1000 - accuracy: 0.3570 - val_loss: 2.1086 - val_accuracy: 0.3558\n",
      "Epoch 22/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0947 - accuracy: 0.3583 - val_loss: 2.1090 - val_accuracy: 0.3586\n",
      "Epoch 23/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0929 - accuracy: 0.3591 - val_loss: 2.1069 - val_accuracy: 0.3556\n",
      "Epoch 24/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0917 - accuracy: 0.3578 - val_loss: 2.1073 - val_accuracy: 0.3538\n",
      "Epoch 25/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0884 - accuracy: 0.3605 - val_loss: 2.1037 - val_accuracy: 0.3572\n",
      "Epoch 26/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0859 - accuracy: 0.3606 - val_loss: 2.1063 - val_accuracy: 0.3595\n",
      "Epoch 27/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0849 - accuracy: 0.3627 - val_loss: 2.1025 - val_accuracy: 0.3596\n",
      "Epoch 28/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0834 - accuracy: 0.3617 - val_loss: 2.1015 - val_accuracy: 0.3577\n",
      "Epoch 29/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0854 - accuracy: 0.3612 - val_loss: 2.1037 - val_accuracy: 0.3585\n",
      "Epoch 30/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0793 - accuracy: 0.3623 - val_loss: 2.0984 - val_accuracy: 0.3603\n",
      "Epoch 31/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0752 - accuracy: 0.3626 - val_loss: 2.0999 - val_accuracy: 0.3631\n",
      "Epoch 32/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0758 - accuracy: 0.3612 - val_loss: 2.0978 - val_accuracy: 0.3599\n",
      "Epoch 33/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0772 - accuracy: 0.3627 - val_loss: 2.0993 - val_accuracy: 0.3620\n",
      "Epoch 34/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0750 - accuracy: 0.3650 - val_loss: 2.0965 - val_accuracy: 0.3616\n",
      "Epoch 35/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0725 - accuracy: 0.3624 - val_loss: 2.0956 - val_accuracy: 0.3591\n",
      "Epoch 36/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0693 - accuracy: 0.3646 - val_loss: 2.0940 - val_accuracy: 0.3631\n",
      "Epoch 37/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0665 - accuracy: 0.3660 - val_loss: 2.0924 - val_accuracy: 0.3613\n",
      "Epoch 38/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0678 - accuracy: 0.3649 - val_loss: 2.0927 - val_accuracy: 0.3636\n",
      "Epoch 39/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0683 - accuracy: 0.3656 - val_loss: 2.0961 - val_accuracy: 0.3603\n",
      "Epoch 40/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0642 - accuracy: 0.3641 - val_loss: 2.0976 - val_accuracy: 0.3606\n",
      "Epoch 41/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0653 - accuracy: 0.3656 - val_loss: 2.0939 - val_accuracy: 0.3610\n",
      "Epoch 42/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0632 - accuracy: 0.3654 - val_loss: 2.0914 - val_accuracy: 0.3643\n",
      "Epoch 43/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0597 - accuracy: 0.3693 - val_loss: 2.0889 - val_accuracy: 0.3624\n",
      "Epoch 44/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0606 - accuracy: 0.3671 - val_loss: 2.0893 - val_accuracy: 0.3635\n",
      "Epoch 45/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0567 - accuracy: 0.3692 - val_loss: 2.0889 - val_accuracy: 0.3655\n",
      "Epoch 46/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0575 - accuracy: 0.3661 - val_loss: 2.0896 - val_accuracy: 0.3632\n",
      "Epoch 47/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0543 - accuracy: 0.3675 - val_loss: 2.0916 - val_accuracy: 0.3643\n",
      "Epoch 48/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0566 - accuracy: 0.3669 - val_loss: 2.0890 - val_accuracy: 0.3653\n",
      "Epoch 49/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0546 - accuracy: 0.3677 - val_loss: 2.0873 - val_accuracy: 0.3610\n",
      "Epoch 50/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0514 - accuracy: 0.3695 - val_loss: 2.0875 - val_accuracy: 0.3645\n",
      "Epoch 51/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0514 - accuracy: 0.3680 - val_loss: 2.0888 - val_accuracy: 0.3641\n",
      "Epoch 52/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0522 - accuracy: 0.3681 - val_loss: 2.0876 - val_accuracy: 0.3638\n",
      "Epoch 53/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0512 - accuracy: 0.3696 - val_loss: 2.0864 - val_accuracy: 0.3635\n",
      "Epoch 54/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0471 - accuracy: 0.3709 - val_loss: 2.0850 - val_accuracy: 0.3636\n",
      "Epoch 55/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0461 - accuracy: 0.3704 - val_loss: 2.0848 - val_accuracy: 0.3639\n",
      "Epoch 56/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0463 - accuracy: 0.3689 - val_loss: 2.0854 - val_accuracy: 0.3624\n",
      "Epoch 57/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0439 - accuracy: 0.3706 - val_loss: 2.0846 - val_accuracy: 0.3638\n",
      "Epoch 58/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0451 - accuracy: 0.3714 - val_loss: 2.0843 - val_accuracy: 0.3659\n",
      "Epoch 59/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0443 - accuracy: 0.3707 - val_loss: 2.0864 - val_accuracy: 0.3639\n",
      "Epoch 60/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0408 - accuracy: 0.3708 - val_loss: 2.0847 - val_accuracy: 0.3630\n",
      "Epoch 61/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0411 - accuracy: 0.3706 - val_loss: 2.0860 - val_accuracy: 0.3655\n",
      "Epoch 62/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0405 - accuracy: 0.3714 - val_loss: 2.0850 - val_accuracy: 0.3611\n",
      "Epoch 63/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0404 - accuracy: 0.3731 - val_loss: 2.0848 - val_accuracy: 0.3662\n",
      "Epoch 64/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0395 - accuracy: 0.3714 - val_loss: 2.0850 - val_accuracy: 0.3664\n",
      "Epoch 65/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0373 - accuracy: 0.3744 - val_loss: 2.0830 - val_accuracy: 0.3638\n",
      "Epoch 66/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0379 - accuracy: 0.3736 - val_loss: 2.0860 - val_accuracy: 0.3655\n",
      "Epoch 67/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0387 - accuracy: 0.3719 - val_loss: 2.0848 - val_accuracy: 0.3652\n",
      "Epoch 68/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0341 - accuracy: 0.3735 - val_loss: 2.0867 - val_accuracy: 0.3639\n",
      "Epoch 69/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0347 - accuracy: 0.3733 - val_loss: 2.0825 - val_accuracy: 0.3648\n",
      "Epoch 70/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0330 - accuracy: 0.3732 - val_loss: 2.0819 - val_accuracy: 0.3645\n",
      "Epoch 71/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0299 - accuracy: 0.3754 - val_loss: 2.0809 - val_accuracy: 0.3648\n",
      "Epoch 72/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0311 - accuracy: 0.3746 - val_loss: 2.0839 - val_accuracy: 0.3673\n",
      "Epoch 73/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0306 - accuracy: 0.3761 - val_loss: 2.0814 - val_accuracy: 0.3664\n",
      "Epoch 74/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0307 - accuracy: 0.3753 - val_loss: 2.0831 - val_accuracy: 0.3660\n",
      "Epoch 75/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0298 - accuracy: 0.3741 - val_loss: 2.0841 - val_accuracy: 0.3636\n",
      "Epoch 76/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0287 - accuracy: 0.3733 - val_loss: 2.0816 - val_accuracy: 0.3680\n",
      "Epoch 77/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0256 - accuracy: 0.3767 - val_loss: 2.0829 - val_accuracy: 0.3650\n",
      "Epoch 78/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0238 - accuracy: 0.3768 - val_loss: 2.0835 - val_accuracy: 0.3684\n",
      "Epoch 79/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0255 - accuracy: 0.3770 - val_loss: 2.0845 - val_accuracy: 0.3649\n",
      "Epoch 80/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0249 - accuracy: 0.3758 - val_loss: 2.0818 - val_accuracy: 0.3674\n",
      "Epoch 81/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0248 - accuracy: 0.3753 - val_loss: 2.0821 - val_accuracy: 0.3660\n",
      "Epoch 82/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0239 - accuracy: 0.3754 - val_loss: 2.0837 - val_accuracy: 0.3649\n",
      "Epoch 83/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0212 - accuracy: 0.3776 - val_loss: 2.0811 - val_accuracy: 0.3667\n",
      "Epoch 84/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0245 - accuracy: 0.3771 - val_loss: 2.0841 - val_accuracy: 0.3653\n",
      "Epoch 85/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0205 - accuracy: 0.3763 - val_loss: 2.0823 - val_accuracy: 0.3673\n",
      "Epoch 86/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0173 - accuracy: 0.3761 - val_loss: 2.0830 - val_accuracy: 0.3673\n",
      "Epoch 87/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0223 - accuracy: 0.3765 - val_loss: 2.0815 - val_accuracy: 0.3655\n",
      "Epoch 88/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0172 - accuracy: 0.3782 - val_loss: 2.0812 - val_accuracy: 0.3652\n",
      "Epoch 89/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0170 - accuracy: 0.3773 - val_loss: 2.0861 - val_accuracy: 0.3684\n",
      "Epoch 90/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0189 - accuracy: 0.3774 - val_loss: 2.0824 - val_accuracy: 0.3653\n",
      "Epoch 91/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0165 - accuracy: 0.3794 - val_loss: 2.0833 - val_accuracy: 0.3664\n",
      "Epoch 92/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0172 - accuracy: 0.3760 - val_loss: 2.0822 - val_accuracy: 0.3663\n",
      "Epoch 93/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0149 - accuracy: 0.3782 - val_loss: 2.0826 - val_accuracy: 0.3673\n",
      "Epoch 94/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0129 - accuracy: 0.3791 - val_loss: 2.0809 - val_accuracy: 0.3689\n",
      "Epoch 95/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0124 - accuracy: 0.3777 - val_loss: 2.0833 - val_accuracy: 0.3664\n",
      "Epoch 96/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0134 - accuracy: 0.3783 - val_loss: 2.0813 - val_accuracy: 0.3667\n",
      "Epoch 97/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0151 - accuracy: 0.3796 - val_loss: 2.0826 - val_accuracy: 0.3670\n",
      "Epoch 98/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0111 - accuracy: 0.3799 - val_loss: 2.0808 - val_accuracy: 0.3649\n",
      "Epoch 99/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0095 - accuracy: 0.3782 - val_loss: 2.0819 - val_accuracy: 0.3642\n",
      "Epoch 100/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0115 - accuracy: 0.3774 - val_loss: 2.0800 - val_accuracy: 0.3662\n",
      "Epoch 101/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0096 - accuracy: 0.3812 - val_loss: 2.0812 - val_accuracy: 0.3657\n",
      "Epoch 102/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0078 - accuracy: 0.3807 - val_loss: 2.0837 - val_accuracy: 0.3680\n",
      "Epoch 103/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0077 - accuracy: 0.3798 - val_loss: 2.0828 - val_accuracy: 0.3674\n",
      "Epoch 104/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0071 - accuracy: 0.3803 - val_loss: 2.0805 - val_accuracy: 0.3670\n",
      "Epoch 105/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0058 - accuracy: 0.3804 - val_loss: 2.0795 - val_accuracy: 0.3677\n",
      "Epoch 106/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0045 - accuracy: 0.3814 - val_loss: 2.0817 - val_accuracy: 0.3675\n",
      "Epoch 107/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0051 - accuracy: 0.3817 - val_loss: 2.0816 - val_accuracy: 0.3662\n",
      "Epoch 108/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0033 - accuracy: 0.3790 - val_loss: 2.0817 - val_accuracy: 0.3666\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0048 - accuracy: 0.3807 - val_loss: 2.0828 - val_accuracy: 0.3674\n",
      "Epoch 110/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0032 - accuracy: 0.3808 - val_loss: 2.0820 - val_accuracy: 0.3667\n",
      "Epoch 111/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0023 - accuracy: 0.3817 - val_loss: 2.0813 - val_accuracy: 0.3671\n",
      "Epoch 112/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0005 - accuracy: 0.3838 - val_loss: 2.0813 - val_accuracy: 0.3660\n",
      "Epoch 113/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0018 - accuracy: 0.3827 - val_loss: 2.0822 - val_accuracy: 0.3650\n",
      "Epoch 114/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 2.0008 - accuracy: 0.3803 - val_loss: 2.0829 - val_accuracy: 0.3655\n",
      "Epoch 115/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9971 - accuracy: 0.3841 - val_loss: 2.0809 - val_accuracy: 0.3673\n",
      "Epoch 116/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9993 - accuracy: 0.3805 - val_loss: 2.0801 - val_accuracy: 0.3681\n",
      "Epoch 117/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9966 - accuracy: 0.3835 - val_loss: 2.0815 - val_accuracy: 0.3682\n",
      "Epoch 118/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9962 - accuracy: 0.3807 - val_loss: 2.0807 - val_accuracy: 0.3671\n",
      "Epoch 119/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9956 - accuracy: 0.3859 - val_loss: 2.0831 - val_accuracy: 0.3639\n",
      "Epoch 120/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9953 - accuracy: 0.3842 - val_loss: 2.0838 - val_accuracy: 0.3653\n",
      "Epoch 121/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9948 - accuracy: 0.3821 - val_loss: 2.0822 - val_accuracy: 0.3649\n",
      "Epoch 122/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9926 - accuracy: 0.3828 - val_loss: 2.0816 - val_accuracy: 0.3678\n",
      "Epoch 123/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9904 - accuracy: 0.3843 - val_loss: 2.0810 - val_accuracy: 0.3671\n",
      "Epoch 124/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9930 - accuracy: 0.3830 - val_loss: 2.0816 - val_accuracy: 0.3659\n",
      "Epoch 125/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9946 - accuracy: 0.3814 - val_loss: 2.0815 - val_accuracy: 0.3671\n",
      "Epoch 126/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9917 - accuracy: 0.3836 - val_loss: 2.0812 - val_accuracy: 0.3674\n",
      "Epoch 127/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9875 - accuracy: 0.3837 - val_loss: 2.0807 - val_accuracy: 0.3663\n",
      "Epoch 128/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9892 - accuracy: 0.3830 - val_loss: 2.0824 - val_accuracy: 0.3689\n",
      "Epoch 129/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9912 - accuracy: 0.3826 - val_loss: 2.0829 - val_accuracy: 0.3677\n",
      "Epoch 130/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9879 - accuracy: 0.3839 - val_loss: 2.0830 - val_accuracy: 0.3662\n",
      "Epoch 131/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9860 - accuracy: 0.3846 - val_loss: 2.0823 - val_accuracy: 0.3675\n",
      "Epoch 132/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9864 - accuracy: 0.3842 - val_loss: 2.0804 - val_accuracy: 0.3670\n",
      "Epoch 133/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9852 - accuracy: 0.3866 - val_loss: 2.0818 - val_accuracy: 0.3646\n",
      "Epoch 134/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9876 - accuracy: 0.3847 - val_loss: 2.0808 - val_accuracy: 0.3701\n",
      "Epoch 135/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9861 - accuracy: 0.3835 - val_loss: 2.0847 - val_accuracy: 0.3670\n",
      "Epoch 136/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9821 - accuracy: 0.3859 - val_loss: 2.0812 - val_accuracy: 0.3652\n",
      "Epoch 137/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9825 - accuracy: 0.3865 - val_loss: 2.0819 - val_accuracy: 0.3669\n",
      "Epoch 138/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9834 - accuracy: 0.3861 - val_loss: 2.0803 - val_accuracy: 0.3692\n",
      "Epoch 139/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9806 - accuracy: 0.3870 - val_loss: 2.0826 - val_accuracy: 0.3664\n",
      "Epoch 140/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9803 - accuracy: 0.3859 - val_loss: 2.0827 - val_accuracy: 0.3670\n",
      "Epoch 141/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9796 - accuracy: 0.3877 - val_loss: 2.0811 - val_accuracy: 0.3691\n",
      "Epoch 142/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9820 - accuracy: 0.3860 - val_loss: 2.0822 - val_accuracy: 0.3664\n",
      "Epoch 143/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9781 - accuracy: 0.3876 - val_loss: 2.0829 - val_accuracy: 0.3641\n",
      "Epoch 144/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9774 - accuracy: 0.3887 - val_loss: 2.0826 - val_accuracy: 0.3684\n",
      "Epoch 145/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9792 - accuracy: 0.3880 - val_loss: 2.0851 - val_accuracy: 0.3682\n",
      "Epoch 146/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9755 - accuracy: 0.3869 - val_loss: 2.0822 - val_accuracy: 0.3669\n",
      "Epoch 147/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9750 - accuracy: 0.3854 - val_loss: 2.0823 - val_accuracy: 0.3680\n",
      "Epoch 148/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9745 - accuracy: 0.3878 - val_loss: 2.0843 - val_accuracy: 0.3663\n",
      "Epoch 149/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9755 - accuracy: 0.3883 - val_loss: 2.0831 - val_accuracy: 0.3687\n",
      "Epoch 150/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9746 - accuracy: 0.3881 - val_loss: 2.0841 - val_accuracy: 0.3694\n",
      "Epoch 151/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9750 - accuracy: 0.3882 - val_loss: 2.0834 - val_accuracy: 0.3685\n",
      "Epoch 152/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9722 - accuracy: 0.3871 - val_loss: 2.0851 - val_accuracy: 0.3692\n",
      "Epoch 153/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9727 - accuracy: 0.3876 - val_loss: 2.0832 - val_accuracy: 0.3666\n",
      "Epoch 154/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9721 - accuracy: 0.3864 - val_loss: 2.0825 - val_accuracy: 0.3687\n",
      "Epoch 155/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9679 - accuracy: 0.3886 - val_loss: 2.0848 - val_accuracy: 0.3687\n",
      "Epoch 156/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9704 - accuracy: 0.3874 - val_loss: 2.0858 - val_accuracy: 0.3663\n",
      "Epoch 157/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9687 - accuracy: 0.3887 - val_loss: 2.0848 - val_accuracy: 0.3664\n",
      "Epoch 158/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9676 - accuracy: 0.3906 - val_loss: 2.0831 - val_accuracy: 0.3663\n",
      "Epoch 159/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9687 - accuracy: 0.3892 - val_loss: 2.0847 - val_accuracy: 0.3656\n",
      "Epoch 160/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9653 - accuracy: 0.3903 - val_loss: 2.0827 - val_accuracy: 0.3677\n",
      "Epoch 161/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9654 - accuracy: 0.3885 - val_loss: 2.0846 - val_accuracy: 0.3662\n",
      "Epoch 162/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9659 - accuracy: 0.3911 - val_loss: 2.0849 - val_accuracy: 0.3675\n",
      "Epoch 163/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9634 - accuracy: 0.3924 - val_loss: 2.0825 - val_accuracy: 0.3692\n",
      "Epoch 164/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9625 - accuracy: 0.3902 - val_loss: 2.0861 - val_accuracy: 0.3685\n",
      "Epoch 165/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9619 - accuracy: 0.3915 - val_loss: 2.0858 - val_accuracy: 0.3680\n",
      "Epoch 166/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9605 - accuracy: 0.3912 - val_loss: 2.0865 - val_accuracy: 0.3664\n",
      "Epoch 167/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9626 - accuracy: 0.3925 - val_loss: 2.0842 - val_accuracy: 0.3710\n",
      "Epoch 168/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9605 - accuracy: 0.3909 - val_loss: 2.0880 - val_accuracy: 0.3674\n",
      "Epoch 169/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9630 - accuracy: 0.3887 - val_loss: 2.0843 - val_accuracy: 0.3692\n",
      "Epoch 170/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9600 - accuracy: 0.3928 - val_loss: 2.0835 - val_accuracy: 0.3720\n",
      "Epoch 171/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9584 - accuracy: 0.3903 - val_loss: 2.0861 - val_accuracy: 0.3666\n",
      "Epoch 172/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9579 - accuracy: 0.3897 - val_loss: 2.0870 - val_accuracy: 0.3657\n",
      "Epoch 173/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9575 - accuracy: 0.3940 - val_loss: 2.0840 - val_accuracy: 0.3699\n",
      "Epoch 174/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9547 - accuracy: 0.3921 - val_loss: 2.0870 - val_accuracy: 0.3671\n",
      "Epoch 175/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9552 - accuracy: 0.3911 - val_loss: 2.0856 - val_accuracy: 0.3705\n",
      "Epoch 176/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9551 - accuracy: 0.3932 - val_loss: 2.0854 - val_accuracy: 0.3673\n",
      "Epoch 177/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9561 - accuracy: 0.3925 - val_loss: 2.0859 - val_accuracy: 0.3657\n",
      "Epoch 178/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9555 - accuracy: 0.3918 - val_loss: 2.0850 - val_accuracy: 0.3695\n",
      "Epoch 179/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9528 - accuracy: 0.3924 - val_loss: 2.0866 - val_accuracy: 0.3660\n",
      "Epoch 180/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9541 - accuracy: 0.3890 - val_loss: 2.0851 - val_accuracy: 0.3682\n",
      "Epoch 181/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9529 - accuracy: 0.3934 - val_loss: 2.0859 - val_accuracy: 0.3703\n",
      "Epoch 182/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9514 - accuracy: 0.3912 - val_loss: 2.0896 - val_accuracy: 0.3662\n",
      "Epoch 183/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9495 - accuracy: 0.3944 - val_loss: 2.0859 - val_accuracy: 0.3685\n",
      "Epoch 184/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9463 - accuracy: 0.3938 - val_loss: 2.0891 - val_accuracy: 0.3680\n",
      "Epoch 185/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9520 - accuracy: 0.3923 - val_loss: 2.0876 - val_accuracy: 0.3648\n",
      "Epoch 186/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9513 - accuracy: 0.3932 - val_loss: 2.0881 - val_accuracy: 0.3698\n",
      "Epoch 187/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9479 - accuracy: 0.3954 - val_loss: 2.0879 - val_accuracy: 0.3673\n",
      "Epoch 188/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9471 - accuracy: 0.3946 - val_loss: 2.0890 - val_accuracy: 0.3678\n",
      "Epoch 189/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9434 - accuracy: 0.3955 - val_loss: 2.0890 - val_accuracy: 0.3657\n",
      "Epoch 190/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9452 - accuracy: 0.3922 - val_loss: 2.0892 - val_accuracy: 0.3684\n",
      "Epoch 191/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9482 - accuracy: 0.3930 - val_loss: 2.0891 - val_accuracy: 0.3687\n",
      "Epoch 192/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9436 - accuracy: 0.3942 - val_loss: 2.0888 - val_accuracy: 0.3691\n",
      "Epoch 193/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9455 - accuracy: 0.3950 - val_loss: 2.0895 - val_accuracy: 0.3675\n",
      "Epoch 194/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9455 - accuracy: 0.3932 - val_loss: 2.0883 - val_accuracy: 0.3687\n",
      "Epoch 195/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9421 - accuracy: 0.3957 - val_loss: 2.0935 - val_accuracy: 0.3650\n",
      "Epoch 196/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9413 - accuracy: 0.3967 - val_loss: 2.0880 - val_accuracy: 0.3701\n",
      "Epoch 197/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9397 - accuracy: 0.3962 - val_loss: 2.0889 - val_accuracy: 0.3675\n",
      "Epoch 198/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9377 - accuracy: 0.3970 - val_loss: 2.0909 - val_accuracy: 0.3659\n",
      "Epoch 199/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9398 - accuracy: 0.3954 - val_loss: 2.0909 - val_accuracy: 0.3691\n",
      "Epoch 200/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9390 - accuracy: 0.3952 - val_loss: 2.0917 - val_accuracy: 0.3667\n",
      "Epoch 201/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9396 - accuracy: 0.3959 - val_loss: 2.0938 - val_accuracy: 0.3671\n",
      "Epoch 202/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9377 - accuracy: 0.3970 - val_loss: 2.0905 - val_accuracy: 0.3675\n",
      "Epoch 203/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9398 - accuracy: 0.3986 - val_loss: 2.0907 - val_accuracy: 0.3663\n",
      "Epoch 204/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9337 - accuracy: 0.3965 - val_loss: 2.0926 - val_accuracy: 0.3660\n",
      "Epoch 205/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9350 - accuracy: 0.3967 - val_loss: 2.0917 - val_accuracy: 0.3674\n",
      "Epoch 206/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9342 - accuracy: 0.3984 - val_loss: 2.0923 - val_accuracy: 0.3691\n",
      "Epoch 207/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9359 - accuracy: 0.3955 - val_loss: 2.0933 - val_accuracy: 0.3632\n",
      "Epoch 208/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9322 - accuracy: 0.3982 - val_loss: 2.0927 - val_accuracy: 0.3666\n",
      "Epoch 209/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9317 - accuracy: 0.3989 - val_loss: 2.0921 - val_accuracy: 0.3648\n",
      "Epoch 210/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9341 - accuracy: 0.3976 - val_loss: 2.0938 - val_accuracy: 0.3664\n",
      "Epoch 211/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9313 - accuracy: 0.3987 - val_loss: 2.0936 - val_accuracy: 0.3657\n",
      "Epoch 212/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9322 - accuracy: 0.3973 - val_loss: 2.0932 - val_accuracy: 0.3657\n",
      "Epoch 213/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9277 - accuracy: 0.3989 - val_loss: 2.0919 - val_accuracy: 0.3671\n",
      "Epoch 214/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9277 - accuracy: 0.3984 - val_loss: 2.0930 - val_accuracy: 0.3694\n",
      "Epoch 215/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9301 - accuracy: 0.3958 - val_loss: 2.0941 - val_accuracy: 0.3685\n",
      "Epoch 216/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9275 - accuracy: 0.3992 - val_loss: 2.0953 - val_accuracy: 0.3681\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9268 - accuracy: 0.4008 - val_loss: 2.0934 - val_accuracy: 0.3702\n",
      "Epoch 218/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9238 - accuracy: 0.4013 - val_loss: 2.0945 - val_accuracy: 0.3675\n",
      "Epoch 219/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9254 - accuracy: 0.3993 - val_loss: 2.0958 - val_accuracy: 0.3666\n",
      "Epoch 220/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9220 - accuracy: 0.3996 - val_loss: 2.0963 - val_accuracy: 0.3670\n",
      "Epoch 221/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9226 - accuracy: 0.3992 - val_loss: 2.0969 - val_accuracy: 0.3638\n",
      "Epoch 222/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9210 - accuracy: 0.3997 - val_loss: 2.0976 - val_accuracy: 0.3596\n",
      "Epoch 223/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9221 - accuracy: 0.3992 - val_loss: 2.0965 - val_accuracy: 0.3653\n",
      "Epoch 224/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9220 - accuracy: 0.4003 - val_loss: 2.0948 - val_accuracy: 0.3684\n",
      "Epoch 225/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9210 - accuracy: 0.4000 - val_loss: 2.0955 - val_accuracy: 0.3643\n",
      "Epoch 226/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9185 - accuracy: 0.4004 - val_loss: 2.0962 - val_accuracy: 0.3656\n",
      "Epoch 227/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9218 - accuracy: 0.3994 - val_loss: 2.0962 - val_accuracy: 0.3646\n",
      "Epoch 228/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9206 - accuracy: 0.3985 - val_loss: 2.0979 - val_accuracy: 0.3663\n",
      "Epoch 229/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9211 - accuracy: 0.4003 - val_loss: 2.0991 - val_accuracy: 0.3659\n",
      "Epoch 230/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9193 - accuracy: 0.4009 - val_loss: 2.1019 - val_accuracy: 0.3680\n",
      "Epoch 231/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9164 - accuracy: 0.4004 - val_loss: 2.0987 - val_accuracy: 0.3674\n",
      "Epoch 232/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9182 - accuracy: 0.4004 - val_loss: 2.0990 - val_accuracy: 0.3666\n",
      "Epoch 233/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9169 - accuracy: 0.4014 - val_loss: 2.0977 - val_accuracy: 0.3677\n",
      "Epoch 234/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9152 - accuracy: 0.4022 - val_loss: 2.1005 - val_accuracy: 0.3678\n",
      "Epoch 235/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9147 - accuracy: 0.4014 - val_loss: 2.0977 - val_accuracy: 0.3667\n",
      "Epoch 236/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9121 - accuracy: 0.4022 - val_loss: 2.0975 - val_accuracy: 0.3653\n",
      "Epoch 237/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9097 - accuracy: 0.4029 - val_loss: 2.1010 - val_accuracy: 0.3652\n",
      "Epoch 238/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9151 - accuracy: 0.4007 - val_loss: 2.1031 - val_accuracy: 0.3607\n",
      "Epoch 239/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9121 - accuracy: 0.3990 - val_loss: 2.0993 - val_accuracy: 0.3660\n",
      "Epoch 240/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9091 - accuracy: 0.4046 - val_loss: 2.0991 - val_accuracy: 0.3666\n",
      "Epoch 241/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9100 - accuracy: 0.4028 - val_loss: 2.1013 - val_accuracy: 0.3657\n",
      "Epoch 242/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9094 - accuracy: 0.4020 - val_loss: 2.1027 - val_accuracy: 0.3662\n",
      "Epoch 243/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9060 - accuracy: 0.4031 - val_loss: 2.1013 - val_accuracy: 0.3673\n",
      "Epoch 244/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9110 - accuracy: 0.4017 - val_loss: 2.0997 - val_accuracy: 0.3638\n",
      "Epoch 245/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9067 - accuracy: 0.4043 - val_loss: 2.1043 - val_accuracy: 0.3646\n",
      "Epoch 246/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9059 - accuracy: 0.4030 - val_loss: 2.1037 - val_accuracy: 0.3659\n",
      "Epoch 247/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9073 - accuracy: 0.4030 - val_loss: 2.1034 - val_accuracy: 0.3652\n",
      "Epoch 248/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9057 - accuracy: 0.4038 - val_loss: 2.1046 - val_accuracy: 0.3649\n",
      "Epoch 249/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9053 - accuracy: 0.4045 - val_loss: 2.1026 - val_accuracy: 0.3657\n",
      "Epoch 250/250\n",
      "28731/28731 [==============================] - 0s 8us/sample - loss: 1.9008 - accuracy: 0.4034 - val_loss: 2.1049 - val_accuracy: 0.3620\n",
      "Training fold 4\n",
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28734 samples, validate on 7177 samples\n",
      "Epoch 1/250\n",
      "28734/28734 [==============================] - 3s 96us/sample - loss: 3.1454 - accuracy: 0.1262 - val_loss: 3.0338 - val_accuracy: 0.1712\n",
      "Epoch 2/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.9075 - accuracy: 0.1884 - val_loss: 2.7303 - val_accuracy: 0.2098\n",
      "Epoch 3/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.6016 - accuracy: 0.2313 - val_loss: 2.4533 - val_accuracy: 0.2700\n",
      "Epoch 4/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.3812 - accuracy: 0.2954 - val_loss: 2.2969 - val_accuracy: 0.3145\n",
      "Epoch 5/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.2701 - accuracy: 0.3180 - val_loss: 2.2240 - val_accuracy: 0.3246\n",
      "Epoch 6/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.2152 - accuracy: 0.3275 - val_loss: 2.1887 - val_accuracy: 0.3272\n",
      "Epoch 7/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1886 - accuracy: 0.3322 - val_loss: 2.1670 - val_accuracy: 0.3369\n",
      "Epoch 8/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1717 - accuracy: 0.3362 - val_loss: 2.1517 - val_accuracy: 0.3458\n",
      "Epoch 9/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1581 - accuracy: 0.3397 - val_loss: 2.1436 - val_accuracy: 0.3482\n",
      "Epoch 10/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1505 - accuracy: 0.3418 - val_loss: 2.1349 - val_accuracy: 0.3513\n",
      "Epoch 11/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1422 - accuracy: 0.3432 - val_loss: 2.1269 - val_accuracy: 0.3497\n",
      "Epoch 12/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1394 - accuracy: 0.3460 - val_loss: 2.1218 - val_accuracy: 0.3552\n",
      "Epoch 13/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1281 - accuracy: 0.3490 - val_loss: 2.1175 - val_accuracy: 0.3553\n",
      "Epoch 14/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1251 - accuracy: 0.3490 - val_loss: 2.1149 - val_accuracy: 0.3552\n",
      "Epoch 15/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1220 - accuracy: 0.3493 - val_loss: 2.1134 - val_accuracy: 0.3578\n",
      "Epoch 16/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1200 - accuracy: 0.3512 - val_loss: 2.1111 - val_accuracy: 0.3592\n",
      "Epoch 17/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1153 - accuracy: 0.3524 - val_loss: 2.1054 - val_accuracy: 0.3599\n",
      "Epoch 18/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1120 - accuracy: 0.3539 - val_loss: 2.1022 - val_accuracy: 0.3585\n",
      "Epoch 19/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1087 - accuracy: 0.3528 - val_loss: 2.1008 - val_accuracy: 0.3614\n",
      "Epoch 20/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1060 - accuracy: 0.3574 - val_loss: 2.0977 - val_accuracy: 0.3630\n",
      "Epoch 21/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.1031 - accuracy: 0.3581 - val_loss: 2.0971 - val_accuracy: 0.3624\n",
      "Epoch 22/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0991 - accuracy: 0.3567 - val_loss: 2.0955 - val_accuracy: 0.3613\n",
      "Epoch 23/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0962 - accuracy: 0.3572 - val_loss: 2.0928 - val_accuracy: 0.3648\n",
      "Epoch 24/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0975 - accuracy: 0.3562 - val_loss: 2.0930 - val_accuracy: 0.3639\n",
      "Epoch 25/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0924 - accuracy: 0.3562 - val_loss: 2.0937 - val_accuracy: 0.3652\n",
      "Epoch 26/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0918 - accuracy: 0.3582 - val_loss: 2.0902 - val_accuracy: 0.3656\n",
      "Epoch 27/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0904 - accuracy: 0.3573 - val_loss: 2.0887 - val_accuracy: 0.3669\n",
      "Epoch 28/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0880 - accuracy: 0.3602 - val_loss: 2.0887 - val_accuracy: 0.3670\n",
      "Epoch 29/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0849 - accuracy: 0.3600 - val_loss: 2.0860 - val_accuracy: 0.3662\n",
      "Epoch 30/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0852 - accuracy: 0.3597 - val_loss: 2.0872 - val_accuracy: 0.3674\n",
      "Epoch 31/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0819 - accuracy: 0.3592 - val_loss: 2.0844 - val_accuracy: 0.3667\n",
      "Epoch 32/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0782 - accuracy: 0.3627 - val_loss: 2.0841 - val_accuracy: 0.3671\n",
      "Epoch 33/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0772 - accuracy: 0.3628 - val_loss: 2.0834 - val_accuracy: 0.3684\n",
      "Epoch 34/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0771 - accuracy: 0.3607 - val_loss: 2.0845 - val_accuracy: 0.3667\n",
      "Epoch 35/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0762 - accuracy: 0.3629 - val_loss: 2.0845 - val_accuracy: 0.3635\n",
      "Epoch 36/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0774 - accuracy: 0.3604 - val_loss: 2.0811 - val_accuracy: 0.3671\n",
      "Epoch 37/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0712 - accuracy: 0.3632 - val_loss: 2.0827 - val_accuracy: 0.3628\n",
      "Epoch 38/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0712 - accuracy: 0.3620 - val_loss: 2.0833 - val_accuracy: 0.3642\n",
      "Epoch 39/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0703 - accuracy: 0.3638 - val_loss: 2.0790 - val_accuracy: 0.3681\n",
      "Epoch 40/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0664 - accuracy: 0.3663 - val_loss: 2.0800 - val_accuracy: 0.3710\n",
      "Epoch 41/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0677 - accuracy: 0.3648 - val_loss: 2.0796 - val_accuracy: 0.3698\n",
      "Epoch 42/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0675 - accuracy: 0.3654 - val_loss: 2.0783 - val_accuracy: 0.3690\n",
      "Epoch 43/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0625 - accuracy: 0.3647 - val_loss: 2.0776 - val_accuracy: 0.3688\n",
      "Epoch 44/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0612 - accuracy: 0.3652 - val_loss: 2.0781 - val_accuracy: 0.3646\n",
      "Epoch 45/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0611 - accuracy: 0.3671 - val_loss: 2.0813 - val_accuracy: 0.3639\n",
      "Epoch 46/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0623 - accuracy: 0.3674 - val_loss: 2.0793 - val_accuracy: 0.3666\n",
      "Epoch 47/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0601 - accuracy: 0.3672 - val_loss: 2.0773 - val_accuracy: 0.3660\n",
      "Epoch 48/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0569 - accuracy: 0.3664 - val_loss: 2.0768 - val_accuracy: 0.3702\n",
      "Epoch 49/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0577 - accuracy: 0.3655 - val_loss: 2.0791 - val_accuracy: 0.3690\n",
      "Epoch 50/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0571 - accuracy: 0.3676 - val_loss: 2.0763 - val_accuracy: 0.3697\n",
      "Epoch 51/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0559 - accuracy: 0.3679 - val_loss: 2.0787 - val_accuracy: 0.3652\n",
      "Epoch 52/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0533 - accuracy: 0.3681 - val_loss: 2.0781 - val_accuracy: 0.3716\n",
      "Epoch 53/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0542 - accuracy: 0.3689 - val_loss: 2.0767 - val_accuracy: 0.3697\n",
      "Epoch 54/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0495 - accuracy: 0.3687 - val_loss: 2.0746 - val_accuracy: 0.3706\n",
      "Epoch 55/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0520 - accuracy: 0.3686 - val_loss: 2.0768 - val_accuracy: 0.3681\n",
      "Epoch 56/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0499 - accuracy: 0.3690 - val_loss: 2.0753 - val_accuracy: 0.3702\n",
      "Epoch 57/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0469 - accuracy: 0.3700 - val_loss: 2.0738 - val_accuracy: 0.3710\n",
      "Epoch 58/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0513 - accuracy: 0.3685 - val_loss: 2.0737 - val_accuracy: 0.3708\n",
      "Epoch 59/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0461 - accuracy: 0.3710 - val_loss: 2.0740 - val_accuracy: 0.3729\n",
      "Epoch 60/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0474 - accuracy: 0.3708 - val_loss: 2.0750 - val_accuracy: 0.3716\n",
      "Epoch 61/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0448 - accuracy: 0.3708 - val_loss: 2.0733 - val_accuracy: 0.3708\n",
      "Epoch 62/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0439 - accuracy: 0.3697 - val_loss: 2.0731 - val_accuracy: 0.3722\n",
      "Epoch 63/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0420 - accuracy: 0.3705 - val_loss: 2.0725 - val_accuracy: 0.3723\n",
      "Epoch 64/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0410 - accuracy: 0.3699 - val_loss: 2.0732 - val_accuracy: 0.3699\n",
      "Epoch 65/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0399 - accuracy: 0.3721 - val_loss: 2.0716 - val_accuracy: 0.3720\n",
      "Epoch 66/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0409 - accuracy: 0.3731 - val_loss: 2.0724 - val_accuracy: 0.3706\n",
      "Epoch 67/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0363 - accuracy: 0.3739 - val_loss: 2.0735 - val_accuracy: 0.3697\n",
      "Epoch 68/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0400 - accuracy: 0.3708 - val_loss: 2.0725 - val_accuracy: 0.3688\n",
      "Epoch 69/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0377 - accuracy: 0.3724 - val_loss: 2.0724 - val_accuracy: 0.3716\n",
      "Epoch 70/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0362 - accuracy: 0.3723 - val_loss: 2.0710 - val_accuracy: 0.3722\n",
      "Epoch 71/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0361 - accuracy: 0.3743 - val_loss: 2.0736 - val_accuracy: 0.3697\n",
      "Epoch 72/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0356 - accuracy: 0.3735 - val_loss: 2.0738 - val_accuracy: 0.3713\n",
      "Epoch 73/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0333 - accuracy: 0.3735 - val_loss: 2.0732 - val_accuracy: 0.3717\n",
      "Epoch 74/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0322 - accuracy: 0.3759 - val_loss: 2.0715 - val_accuracy: 0.3723\n",
      "Epoch 75/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0320 - accuracy: 0.3731 - val_loss: 2.0717 - val_accuracy: 0.3702\n",
      "Epoch 76/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0303 - accuracy: 0.3731 - val_loss: 2.0713 - val_accuracy: 0.3701\n",
      "Epoch 77/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0315 - accuracy: 0.3740 - val_loss: 2.0735 - val_accuracy: 0.3719\n",
      "Epoch 78/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0293 - accuracy: 0.3744 - val_loss: 2.0721 - val_accuracy: 0.3683\n",
      "Epoch 79/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0296 - accuracy: 0.3746 - val_loss: 2.0708 - val_accuracy: 0.3677\n",
      "Epoch 80/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0269 - accuracy: 0.3752 - val_loss: 2.0721 - val_accuracy: 0.3720\n",
      "Epoch 81/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0271 - accuracy: 0.3752 - val_loss: 2.0704 - val_accuracy: 0.3729\n",
      "Epoch 82/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0246 - accuracy: 0.3769 - val_loss: 2.0706 - val_accuracy: 0.3703\n",
      "Epoch 83/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0273 - accuracy: 0.3753 - val_loss: 2.0738 - val_accuracy: 0.3684\n",
      "Epoch 84/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0244 - accuracy: 0.3777 - val_loss: 2.0721 - val_accuracy: 0.3715\n",
      "Epoch 85/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0248 - accuracy: 0.3765 - val_loss: 2.0713 - val_accuracy: 0.3726\n",
      "Epoch 86/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0234 - accuracy: 0.3759 - val_loss: 2.0701 - val_accuracy: 0.3706\n",
      "Epoch 87/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0213 - accuracy: 0.3749 - val_loss: 2.0707 - val_accuracy: 0.3702\n",
      "Epoch 88/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0234 - accuracy: 0.3751 - val_loss: 2.0729 - val_accuracy: 0.3681\n",
      "Epoch 89/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0196 - accuracy: 0.3762 - val_loss: 2.0727 - val_accuracy: 0.3708\n",
      "Epoch 90/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0187 - accuracy: 0.3764 - val_loss: 2.0729 - val_accuracy: 0.3698\n",
      "Epoch 91/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0198 - accuracy: 0.3758 - val_loss: 2.0717 - val_accuracy: 0.3680\n",
      "Epoch 92/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0192 - accuracy: 0.3759 - val_loss: 2.0726 - val_accuracy: 0.3681\n",
      "Epoch 93/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0172 - accuracy: 0.3762 - val_loss: 2.0719 - val_accuracy: 0.3676\n",
      "Epoch 94/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0172 - accuracy: 0.3775 - val_loss: 2.0721 - val_accuracy: 0.3688\n",
      "Epoch 95/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0158 - accuracy: 0.3781 - val_loss: 2.0733 - val_accuracy: 0.3699\n",
      "Epoch 96/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0145 - accuracy: 0.3782 - val_loss: 2.0725 - val_accuracy: 0.3695\n",
      "Epoch 97/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0157 - accuracy: 0.3779 - val_loss: 2.0709 - val_accuracy: 0.3698\n",
      "Epoch 98/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0144 - accuracy: 0.3781 - val_loss: 2.0725 - val_accuracy: 0.3687\n",
      "Epoch 99/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0115 - accuracy: 0.3803 - val_loss: 2.0719 - val_accuracy: 0.3685\n",
      "Epoch 100/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0133 - accuracy: 0.3794 - val_loss: 2.0709 - val_accuracy: 0.3697\n",
      "Epoch 101/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0107 - accuracy: 0.3801 - val_loss: 2.0726 - val_accuracy: 0.3697\n",
      "Epoch 102/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0089 - accuracy: 0.3810 - val_loss: 2.0721 - val_accuracy: 0.3715\n",
      "Epoch 103/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0098 - accuracy: 0.3803 - val_loss: 2.0730 - val_accuracy: 0.3681\n",
      "Epoch 104/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0125 - accuracy: 0.3770 - val_loss: 2.0717 - val_accuracy: 0.3703\n",
      "Epoch 105/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0081 - accuracy: 0.3774 - val_loss: 2.0710 - val_accuracy: 0.3695\n",
      "Epoch 106/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0088 - accuracy: 0.3809 - val_loss: 2.0729 - val_accuracy: 0.3667\n",
      "Epoch 107/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0078 - accuracy: 0.3803 - val_loss: 2.0722 - val_accuracy: 0.3710\n",
      "Epoch 108/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0064 - accuracy: 0.3813 - val_loss: 2.0721 - val_accuracy: 0.3698\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0061 - accuracy: 0.3780 - val_loss: 2.0704 - val_accuracy: 0.3694\n",
      "Epoch 110/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0056 - accuracy: 0.3815 - val_loss: 2.0726 - val_accuracy: 0.3681\n",
      "Epoch 111/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0067 - accuracy: 0.3810 - val_loss: 2.0712 - val_accuracy: 0.3726\n",
      "Epoch 112/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0039 - accuracy: 0.3799 - val_loss: 2.0733 - val_accuracy: 0.3729\n",
      "Epoch 113/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0040 - accuracy: 0.3815 - val_loss: 2.0732 - val_accuracy: 0.3692\n",
      "Epoch 114/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0014 - accuracy: 0.3814 - val_loss: 2.0732 - val_accuracy: 0.3695\n",
      "Epoch 115/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0047 - accuracy: 0.3821 - val_loss: 2.0717 - val_accuracy: 0.3684\n",
      "Epoch 116/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0007 - accuracy: 0.3801 - val_loss: 2.0718 - val_accuracy: 0.3722\n",
      "Epoch 117/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0001 - accuracy: 0.3815 - val_loss: 2.0732 - val_accuracy: 0.3730\n",
      "Epoch 118/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9983 - accuracy: 0.3820 - val_loss: 2.0728 - val_accuracy: 0.3688\n",
      "Epoch 119/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9999 - accuracy: 0.3826 - val_loss: 2.0736 - val_accuracy: 0.3701\n",
      "Epoch 120/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 2.0018 - accuracy: 0.3805 - val_loss: 2.0726 - val_accuracy: 0.3681\n",
      "Epoch 121/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9964 - accuracy: 0.3841 - val_loss: 2.0733 - val_accuracy: 0.3710\n",
      "Epoch 122/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9982 - accuracy: 0.3833 - val_loss: 2.0737 - val_accuracy: 0.3695\n",
      "Epoch 123/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9956 - accuracy: 0.3840 - val_loss: 2.0754 - val_accuracy: 0.3670\n",
      "Epoch 124/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9971 - accuracy: 0.3839 - val_loss: 2.0751 - val_accuracy: 0.3667\n",
      "Epoch 125/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9956 - accuracy: 0.3831 - val_loss: 2.0733 - val_accuracy: 0.3670\n",
      "Epoch 126/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9940 - accuracy: 0.3833 - val_loss: 2.0731 - val_accuracy: 0.3639\n",
      "Epoch 127/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9932 - accuracy: 0.3837 - val_loss: 2.0762 - val_accuracy: 0.3690\n",
      "Epoch 128/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9935 - accuracy: 0.3813 - val_loss: 2.0733 - val_accuracy: 0.3697\n",
      "Epoch 129/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9935 - accuracy: 0.3810 - val_loss: 2.0734 - val_accuracy: 0.3671\n",
      "Epoch 130/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9913 - accuracy: 0.3836 - val_loss: 2.0732 - val_accuracy: 0.3690\n",
      "Epoch 131/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9885 - accuracy: 0.3849 - val_loss: 2.0740 - val_accuracy: 0.3666\n",
      "Epoch 132/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9905 - accuracy: 0.3841 - val_loss: 2.0744 - val_accuracy: 0.3694\n",
      "Epoch 133/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9892 - accuracy: 0.3848 - val_loss: 2.0743 - val_accuracy: 0.3691\n",
      "Epoch 134/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9905 - accuracy: 0.3833 - val_loss: 2.0742 - val_accuracy: 0.3687\n",
      "Epoch 135/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9885 - accuracy: 0.3829 - val_loss: 2.0738 - val_accuracy: 0.3699\n",
      "Epoch 136/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9884 - accuracy: 0.3861 - val_loss: 2.0772 - val_accuracy: 0.3683\n",
      "Epoch 137/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9880 - accuracy: 0.3861 - val_loss: 2.0735 - val_accuracy: 0.3692\n",
      "Epoch 138/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9863 - accuracy: 0.3842 - val_loss: 2.0740 - val_accuracy: 0.3677\n",
      "Epoch 139/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9858 - accuracy: 0.3870 - val_loss: 2.0742 - val_accuracy: 0.3670\n",
      "Epoch 140/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9835 - accuracy: 0.3858 - val_loss: 2.0732 - val_accuracy: 0.3680\n",
      "Epoch 141/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9846 - accuracy: 0.3843 - val_loss: 2.0753 - val_accuracy: 0.3699\n",
      "Epoch 142/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9858 - accuracy: 0.3844 - val_loss: 2.0749 - val_accuracy: 0.3712\n",
      "Epoch 143/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9810 - accuracy: 0.3870 - val_loss: 2.0757 - val_accuracy: 0.3678\n",
      "Epoch 144/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9836 - accuracy: 0.3852 - val_loss: 2.0767 - val_accuracy: 0.3664\n",
      "Epoch 145/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9835 - accuracy: 0.3842 - val_loss: 2.0736 - val_accuracy: 0.3666\n",
      "Epoch 146/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9803 - accuracy: 0.3846 - val_loss: 2.0735 - val_accuracy: 0.3670\n",
      "Epoch 147/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9811 - accuracy: 0.3853 - val_loss: 2.0734 - val_accuracy: 0.3681\n",
      "Epoch 148/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9788 - accuracy: 0.3880 - val_loss: 2.0747 - val_accuracy: 0.3666\n",
      "Epoch 149/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9789 - accuracy: 0.3866 - val_loss: 2.0776 - val_accuracy: 0.3655\n",
      "Epoch 150/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9800 - accuracy: 0.3864 - val_loss: 2.0790 - val_accuracy: 0.3681\n",
      "Epoch 151/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9783 - accuracy: 0.3885 - val_loss: 2.0760 - val_accuracy: 0.3637\n",
      "Epoch 152/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9779 - accuracy: 0.3884 - val_loss: 2.0783 - val_accuracy: 0.3648\n",
      "Epoch 153/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9755 - accuracy: 0.3895 - val_loss: 2.0750 - val_accuracy: 0.3659\n",
      "Epoch 154/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9791 - accuracy: 0.3867 - val_loss: 2.0774 - val_accuracy: 0.3677\n",
      "Epoch 155/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9750 - accuracy: 0.3878 - val_loss: 2.0775 - val_accuracy: 0.3638\n",
      "Epoch 156/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9780 - accuracy: 0.3875 - val_loss: 2.0778 - val_accuracy: 0.3660\n",
      "Epoch 157/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9741 - accuracy: 0.3857 - val_loss: 2.0780 - val_accuracy: 0.3646\n",
      "Epoch 158/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9749 - accuracy: 0.3891 - val_loss: 2.0770 - val_accuracy: 0.3667\n",
      "Epoch 159/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9734 - accuracy: 0.3878 - val_loss: 2.0767 - val_accuracy: 0.3673\n",
      "Epoch 160/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9716 - accuracy: 0.3875 - val_loss: 2.0766 - val_accuracy: 0.3697\n",
      "Epoch 161/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9702 - accuracy: 0.3892 - val_loss: 2.0757 - val_accuracy: 0.3666\n",
      "Epoch 162/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9698 - accuracy: 0.3888 - val_loss: 2.0780 - val_accuracy: 0.3667\n",
      "Epoch 163/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9708 - accuracy: 0.3907 - val_loss: 2.0781 - val_accuracy: 0.3667\n",
      "Epoch 164/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9688 - accuracy: 0.3882 - val_loss: 2.0774 - val_accuracy: 0.3669\n",
      "Epoch 165/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9680 - accuracy: 0.3890 - val_loss: 2.0773 - val_accuracy: 0.3656\n",
      "Epoch 166/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9688 - accuracy: 0.3894 - val_loss: 2.0762 - val_accuracy: 0.3695\n",
      "Epoch 167/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9670 - accuracy: 0.3893 - val_loss: 2.0763 - val_accuracy: 0.3669\n",
      "Epoch 168/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9652 - accuracy: 0.3901 - val_loss: 2.0760 - val_accuracy: 0.3683\n",
      "Epoch 169/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9654 - accuracy: 0.3904 - val_loss: 2.0775 - val_accuracy: 0.3678\n",
      "Epoch 170/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9659 - accuracy: 0.3883 - val_loss: 2.0776 - val_accuracy: 0.3649\n",
      "Epoch 171/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9653 - accuracy: 0.3872 - val_loss: 2.0767 - val_accuracy: 0.3706\n",
      "Epoch 172/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9651 - accuracy: 0.3906 - val_loss: 2.0805 - val_accuracy: 0.3642\n",
      "Epoch 173/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9647 - accuracy: 0.3894 - val_loss: 2.0784 - val_accuracy: 0.3663\n",
      "Epoch 174/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9636 - accuracy: 0.3923 - val_loss: 2.0812 - val_accuracy: 0.3681\n",
      "Epoch 175/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9642 - accuracy: 0.3907 - val_loss: 2.0802 - val_accuracy: 0.3670\n",
      "Epoch 176/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9630 - accuracy: 0.3898 - val_loss: 2.0774 - val_accuracy: 0.3685\n",
      "Epoch 177/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9587 - accuracy: 0.3921 - val_loss: 2.0770 - val_accuracy: 0.3684\n",
      "Epoch 178/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9582 - accuracy: 0.3919 - val_loss: 2.0786 - val_accuracy: 0.3698\n",
      "Epoch 179/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9593 - accuracy: 0.3896 - val_loss: 2.0795 - val_accuracy: 0.3667\n",
      "Epoch 180/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9599 - accuracy: 0.3903 - val_loss: 2.0785 - val_accuracy: 0.3646\n",
      "Epoch 181/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9588 - accuracy: 0.3908 - val_loss: 2.0793 - val_accuracy: 0.3676\n",
      "Epoch 182/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9582 - accuracy: 0.3914 - val_loss: 2.0805 - val_accuracy: 0.3678\n",
      "Epoch 183/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9579 - accuracy: 0.3909 - val_loss: 2.0797 - val_accuracy: 0.3685\n",
      "Epoch 184/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9561 - accuracy: 0.3902 - val_loss: 2.0825 - val_accuracy: 0.3649\n",
      "Epoch 185/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9573 - accuracy: 0.3887 - val_loss: 2.0812 - val_accuracy: 0.3659\n",
      "Epoch 186/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9566 - accuracy: 0.3938 - val_loss: 2.0790 - val_accuracy: 0.3678\n",
      "Epoch 187/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9554 - accuracy: 0.3933 - val_loss: 2.0826 - val_accuracy: 0.3666\n",
      "Epoch 188/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9557 - accuracy: 0.3908 - val_loss: 2.0788 - val_accuracy: 0.3671\n",
      "Epoch 189/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9525 - accuracy: 0.3948 - val_loss: 2.0822 - val_accuracy: 0.3660\n",
      "Epoch 190/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9529 - accuracy: 0.3923 - val_loss: 2.0820 - val_accuracy: 0.3659\n",
      "Epoch 191/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9529 - accuracy: 0.3918 - val_loss: 2.0819 - val_accuracy: 0.3688\n",
      "Epoch 192/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9514 - accuracy: 0.3929 - val_loss: 2.0838 - val_accuracy: 0.3641\n",
      "Epoch 193/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9522 - accuracy: 0.3931 - val_loss: 2.0808 - val_accuracy: 0.3667\n",
      "Epoch 194/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9503 - accuracy: 0.3949 - val_loss: 2.0825 - val_accuracy: 0.3651\n",
      "Epoch 195/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9512 - accuracy: 0.3924 - val_loss: 2.0825 - val_accuracy: 0.3667\n",
      "Epoch 196/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9495 - accuracy: 0.3942 - val_loss: 2.0832 - val_accuracy: 0.3655\n",
      "Epoch 197/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9464 - accuracy: 0.3946 - val_loss: 2.0817 - val_accuracy: 0.3662\n",
      "Epoch 198/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9512 - accuracy: 0.3928 - val_loss: 2.0804 - val_accuracy: 0.3676\n",
      "Epoch 199/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9496 - accuracy: 0.3933 - val_loss: 2.0809 - val_accuracy: 0.3678\n",
      "Epoch 200/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9441 - accuracy: 0.3966 - val_loss: 2.0807 - val_accuracy: 0.3658\n",
      "Epoch 201/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9469 - accuracy: 0.3940 - val_loss: 2.0835 - val_accuracy: 0.3656\n",
      "Epoch 202/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9434 - accuracy: 0.3959 - val_loss: 2.0829 - val_accuracy: 0.3662\n",
      "Epoch 203/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9452 - accuracy: 0.3945 - val_loss: 2.0832 - val_accuracy: 0.3658\n",
      "Epoch 204/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9454 - accuracy: 0.3959 - val_loss: 2.0826 - val_accuracy: 0.3677\n",
      "Epoch 205/250\n",
      "28734/28734 [==============================] - 0s 11us/sample - loss: 1.9440 - accuracy: 0.3961 - val_loss: 2.0870 - val_accuracy: 0.3649\n",
      "Epoch 206/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9467 - accuracy: 0.3931 - val_loss: 2.0865 - val_accuracy: 0.3681\n",
      "Epoch 207/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9433 - accuracy: 0.3950 - val_loss: 2.0821 - val_accuracy: 0.3663\n",
      "Epoch 208/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9424 - accuracy: 0.3969 - val_loss: 2.0832 - val_accuracy: 0.3655\n",
      "Epoch 209/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9387 - accuracy: 0.3974 - val_loss: 2.0837 - val_accuracy: 0.3674\n",
      "Epoch 210/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9412 - accuracy: 0.3962 - val_loss: 2.0830 - val_accuracy: 0.3690\n",
      "Epoch 211/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9400 - accuracy: 0.3966 - val_loss: 2.0858 - val_accuracy: 0.3673\n",
      "Epoch 212/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9384 - accuracy: 0.3952 - val_loss: 2.0862 - val_accuracy: 0.3656\n",
      "Epoch 213/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9393 - accuracy: 0.3968 - val_loss: 2.0850 - val_accuracy: 0.3703\n",
      "Epoch 214/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9362 - accuracy: 0.3968 - val_loss: 2.0861 - val_accuracy: 0.3663\n",
      "Epoch 215/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9373 - accuracy: 0.3972 - val_loss: 2.0883 - val_accuracy: 0.3648\n",
      "Epoch 216/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9364 - accuracy: 0.3956 - val_loss: 2.0866 - val_accuracy: 0.3664\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9345 - accuracy: 0.3991 - val_loss: 2.0850 - val_accuracy: 0.3670\n",
      "Epoch 218/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9357 - accuracy: 0.3974 - val_loss: 2.0857 - val_accuracy: 0.3663\n",
      "Epoch 219/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9345 - accuracy: 0.3978 - val_loss: 2.0882 - val_accuracy: 0.3648\n",
      "Epoch 220/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9347 - accuracy: 0.3963 - val_loss: 2.0852 - val_accuracy: 0.3635\n",
      "Epoch 221/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9308 - accuracy: 0.3981 - val_loss: 2.0864 - val_accuracy: 0.3652\n",
      "Epoch 222/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9315 - accuracy: 0.3983 - val_loss: 2.0864 - val_accuracy: 0.3659\n",
      "Epoch 223/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9298 - accuracy: 0.3995 - val_loss: 2.0890 - val_accuracy: 0.3642\n",
      "Epoch 224/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9298 - accuracy: 0.3991 - val_loss: 2.0865 - val_accuracy: 0.3669\n",
      "Epoch 225/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9281 - accuracy: 0.3997 - val_loss: 2.0876 - val_accuracy: 0.3642\n",
      "Epoch 226/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9294 - accuracy: 0.3992 - val_loss: 2.0897 - val_accuracy: 0.3663\n",
      "Epoch 227/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9298 - accuracy: 0.4008 - val_loss: 2.0871 - val_accuracy: 0.3660\n",
      "Epoch 228/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9283 - accuracy: 0.3989 - val_loss: 2.0886 - val_accuracy: 0.3662\n",
      "Epoch 229/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9302 - accuracy: 0.3997 - val_loss: 2.0906 - val_accuracy: 0.3642\n",
      "Epoch 230/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9294 - accuracy: 0.3980 - val_loss: 2.0891 - val_accuracy: 0.3646\n",
      "Epoch 231/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9258 - accuracy: 0.3998 - val_loss: 2.0889 - val_accuracy: 0.3651\n",
      "Epoch 232/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9255 - accuracy: 0.3995 - val_loss: 2.0904 - val_accuracy: 0.3606\n",
      "Epoch 233/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9236 - accuracy: 0.4003 - val_loss: 2.0895 - val_accuracy: 0.3677\n",
      "Epoch 234/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9228 - accuracy: 0.3999 - val_loss: 2.0903 - val_accuracy: 0.3659\n",
      "Epoch 235/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9238 - accuracy: 0.4010 - val_loss: 2.0874 - val_accuracy: 0.3649\n",
      "Epoch 236/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9240 - accuracy: 0.3994 - val_loss: 2.0884 - val_accuracy: 0.3624\n",
      "Epoch 237/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9224 - accuracy: 0.4004 - val_loss: 2.0885 - val_accuracy: 0.3658\n",
      "Epoch 238/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9206 - accuracy: 0.4031 - val_loss: 2.0914 - val_accuracy: 0.3625\n",
      "Epoch 239/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9217 - accuracy: 0.3999 - val_loss: 2.0916 - val_accuracy: 0.3656\n",
      "Epoch 240/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9196 - accuracy: 0.4010 - val_loss: 2.0905 - val_accuracy: 0.3674\n",
      "Epoch 241/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9176 - accuracy: 0.3997 - val_loss: 2.0926 - val_accuracy: 0.3641\n",
      "Epoch 242/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9202 - accuracy: 0.4005 - val_loss: 2.0920 - val_accuracy: 0.3663\n",
      "Epoch 243/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9159 - accuracy: 0.4032 - val_loss: 2.0927 - val_accuracy: 0.3666\n",
      "Epoch 244/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9170 - accuracy: 0.4031 - val_loss: 2.0933 - val_accuracy: 0.3638\n",
      "Epoch 245/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9192 - accuracy: 0.4022 - val_loss: 2.0945 - val_accuracy: 0.3625\n",
      "Epoch 246/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9175 - accuracy: 0.4028 - val_loss: 2.0924 - val_accuracy: 0.3667\n",
      "Epoch 247/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9165 - accuracy: 0.4007 - val_loss: 2.0936 - val_accuracy: 0.3674\n",
      "Epoch 248/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9168 - accuracy: 0.4021 - val_loss: 2.0937 - val_accuracy: 0.3642\n",
      "Epoch 249/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9169 - accuracy: 0.4032 - val_loss: 2.0948 - val_accuracy: 0.3667\n",
      "Epoch 250/250\n",
      "28734/28734 [==============================] - 0s 8us/sample - loss: 1.9152 - accuracy: 0.4022 - val_loss: 2.0952 - val_accuracy: 0.3666\n",
      "Training fold 5\n",
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28739 samples, validate on 7172 samples\n",
      "Epoch 1/250\n",
      "28739/28739 [==============================] - 3s 92us/sample - loss: 3.1631 - accuracy: 0.1215 - val_loss: 3.0755 - val_accuracy: 0.1736\n",
      "Epoch 2/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.9700 - accuracy: 0.1982 - val_loss: 2.8143 - val_accuracy: 0.2227\n",
      "Epoch 3/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.6771 - accuracy: 0.2447 - val_loss: 2.5119 - val_accuracy: 0.2645\n",
      "Epoch 4/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.4206 - accuracy: 0.2869 - val_loss: 2.3239 - val_accuracy: 0.3056\n",
      "Epoch 5/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.2842 - accuracy: 0.3131 - val_loss: 2.2392 - val_accuracy: 0.3190\n",
      "Epoch 6/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.2236 - accuracy: 0.3241 - val_loss: 2.2035 - val_accuracy: 0.3300\n",
      "Epoch 7/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1909 - accuracy: 0.3307 - val_loss: 2.1794 - val_accuracy: 0.3355\n",
      "Epoch 8/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1724 - accuracy: 0.3372 - val_loss: 2.1634 - val_accuracy: 0.3398\n",
      "Epoch 9/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1575 - accuracy: 0.3403 - val_loss: 2.1566 - val_accuracy: 0.3415\n",
      "Epoch 10/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1480 - accuracy: 0.3437 - val_loss: 2.1483 - val_accuracy: 0.3408\n",
      "Epoch 11/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1401 - accuracy: 0.3452 - val_loss: 2.1433 - val_accuracy: 0.3454\n",
      "Epoch 12/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1351 - accuracy: 0.3465 - val_loss: 2.1382 - val_accuracy: 0.3480\n",
      "Epoch 13/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1259 - accuracy: 0.3498 - val_loss: 2.1338 - val_accuracy: 0.3487\n",
      "Epoch 14/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1249 - accuracy: 0.3509 - val_loss: 2.1320 - val_accuracy: 0.3470\n",
      "Epoch 15/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1196 - accuracy: 0.3510 - val_loss: 2.1302 - val_accuracy: 0.3518\n",
      "Epoch 16/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1180 - accuracy: 0.3516 - val_loss: 2.1272 - val_accuracy: 0.3491\n",
      "Epoch 17/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1125 - accuracy: 0.3551 - val_loss: 2.1244 - val_accuracy: 0.3496\n",
      "Epoch 18/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1098 - accuracy: 0.3558 - val_loss: 2.1250 - val_accuracy: 0.3504\n",
      "Epoch 19/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1066 - accuracy: 0.3555 - val_loss: 2.1213 - val_accuracy: 0.3503\n",
      "Epoch 20/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.1047 - accuracy: 0.3549 - val_loss: 2.1183 - val_accuracy: 0.3514\n",
      "Epoch 21/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0997 - accuracy: 0.3583 - val_loss: 2.1169 - val_accuracy: 0.3522\n",
      "Epoch 22/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0999 - accuracy: 0.3575 - val_loss: 2.1163 - val_accuracy: 0.3535\n",
      "Epoch 23/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0966 - accuracy: 0.3576 - val_loss: 2.1147 - val_accuracy: 0.3535\n",
      "Epoch 24/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0955 - accuracy: 0.3587 - val_loss: 2.1151 - val_accuracy: 0.3501\n",
      "Epoch 25/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0901 - accuracy: 0.3594 - val_loss: 2.1137 - val_accuracy: 0.3519\n",
      "Epoch 26/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0903 - accuracy: 0.3615 - val_loss: 2.1118 - val_accuracy: 0.3503\n",
      "Epoch 27/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0908 - accuracy: 0.3607 - val_loss: 2.1110 - val_accuracy: 0.3521\n",
      "Epoch 28/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0841 - accuracy: 0.3610 - val_loss: 2.1090 - val_accuracy: 0.3546\n",
      "Epoch 29/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0836 - accuracy: 0.3613 - val_loss: 2.1083 - val_accuracy: 0.3515\n",
      "Epoch 30/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0808 - accuracy: 0.3632 - val_loss: 2.1070 - val_accuracy: 0.3521\n",
      "Epoch 31/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0807 - accuracy: 0.3604 - val_loss: 2.1080 - val_accuracy: 0.3544\n",
      "Epoch 32/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0805 - accuracy: 0.3639 - val_loss: 2.1053 - val_accuracy: 0.3547\n",
      "Epoch 33/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0775 - accuracy: 0.3615 - val_loss: 2.1085 - val_accuracy: 0.3508\n",
      "Epoch 34/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0746 - accuracy: 0.3641 - val_loss: 2.1056 - val_accuracy: 0.3542\n",
      "Epoch 35/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0763 - accuracy: 0.3644 - val_loss: 2.1041 - val_accuracy: 0.3549\n",
      "Epoch 36/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0740 - accuracy: 0.3647 - val_loss: 2.1034 - val_accuracy: 0.3533\n",
      "Epoch 37/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0706 - accuracy: 0.3636 - val_loss: 2.1029 - val_accuracy: 0.3525\n",
      "Epoch 38/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0695 - accuracy: 0.3660 - val_loss: 2.1039 - val_accuracy: 0.3521\n",
      "Epoch 39/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0688 - accuracy: 0.3631 - val_loss: 2.1019 - val_accuracy: 0.3536\n",
      "Epoch 40/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0673 - accuracy: 0.3645 - val_loss: 2.1030 - val_accuracy: 0.3550\n",
      "Epoch 41/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0663 - accuracy: 0.3673 - val_loss: 2.1020 - val_accuracy: 0.3542\n",
      "Epoch 42/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0654 - accuracy: 0.3678 - val_loss: 2.1016 - val_accuracy: 0.3539\n",
      "Epoch 43/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0626 - accuracy: 0.3673 - val_loss: 2.1010 - val_accuracy: 0.3532\n",
      "Epoch 44/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0607 - accuracy: 0.3678 - val_loss: 2.1026 - val_accuracy: 0.3523\n",
      "Epoch 45/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0624 - accuracy: 0.3673 - val_loss: 2.1021 - val_accuracy: 0.3529\n",
      "Epoch 46/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0599 - accuracy: 0.3686 - val_loss: 2.1030 - val_accuracy: 0.3586\n",
      "Epoch 47/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0582 - accuracy: 0.3679 - val_loss: 2.1012 - val_accuracy: 0.3564\n",
      "Epoch 48/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0569 - accuracy: 0.3696 - val_loss: 2.0995 - val_accuracy: 0.3516\n",
      "Epoch 49/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0563 - accuracy: 0.3690 - val_loss: 2.1014 - val_accuracy: 0.3568\n",
      "Epoch 50/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0567 - accuracy: 0.3698 - val_loss: 2.0986 - val_accuracy: 0.3560\n",
      "Epoch 51/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0552 - accuracy: 0.3688 - val_loss: 2.0995 - val_accuracy: 0.3539\n",
      "Epoch 52/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0531 - accuracy: 0.3689 - val_loss: 2.0976 - val_accuracy: 0.3582\n",
      "Epoch 53/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0502 - accuracy: 0.3695 - val_loss: 2.0974 - val_accuracy: 0.3543\n",
      "Epoch 54/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0518 - accuracy: 0.3701 - val_loss: 2.0964 - val_accuracy: 0.3568\n",
      "Epoch 55/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0484 - accuracy: 0.3710 - val_loss: 2.0961 - val_accuracy: 0.3572\n",
      "Epoch 56/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0482 - accuracy: 0.3705 - val_loss: 2.0960 - val_accuracy: 0.3571\n",
      "Epoch 57/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0489 - accuracy: 0.3719 - val_loss: 2.0960 - val_accuracy: 0.3562\n",
      "Epoch 58/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0460 - accuracy: 0.3717 - val_loss: 2.0949 - val_accuracy: 0.3555\n",
      "Epoch 59/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0451 - accuracy: 0.3719 - val_loss: 2.0960 - val_accuracy: 0.3537\n",
      "Epoch 60/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0449 - accuracy: 0.3730 - val_loss: 2.0955 - val_accuracy: 0.3554\n",
      "Epoch 61/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0445 - accuracy: 0.3712 - val_loss: 2.0972 - val_accuracy: 0.3571\n",
      "Epoch 62/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0441 - accuracy: 0.3707 - val_loss: 2.0959 - val_accuracy: 0.3578\n",
      "Epoch 63/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0425 - accuracy: 0.3704 - val_loss: 2.0974 - val_accuracy: 0.3589\n",
      "Epoch 64/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0430 - accuracy: 0.3724 - val_loss: 2.0944 - val_accuracy: 0.3608\n",
      "Epoch 65/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0426 - accuracy: 0.3713 - val_loss: 2.0977 - val_accuracy: 0.3599\n",
      "Epoch 66/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0435 - accuracy: 0.3699 - val_loss: 2.0959 - val_accuracy: 0.3631\n",
      "Epoch 67/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0401 - accuracy: 0.3728 - val_loss: 2.0940 - val_accuracy: 0.3593\n",
      "Epoch 68/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0348 - accuracy: 0.3732 - val_loss: 2.0948 - val_accuracy: 0.3562\n",
      "Epoch 69/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0377 - accuracy: 0.3738 - val_loss: 2.0925 - val_accuracy: 0.3592\n",
      "Epoch 70/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0395 - accuracy: 0.3758 - val_loss: 2.0951 - val_accuracy: 0.3572\n",
      "Epoch 71/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0341 - accuracy: 0.3741 - val_loss: 2.0929 - val_accuracy: 0.3560\n",
      "Epoch 72/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0330 - accuracy: 0.3724 - val_loss: 2.0954 - val_accuracy: 0.3585\n",
      "Epoch 73/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0337 - accuracy: 0.3745 - val_loss: 2.0932 - val_accuracy: 0.3578\n",
      "Epoch 74/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0342 - accuracy: 0.3735 - val_loss: 2.0937 - val_accuracy: 0.3596\n",
      "Epoch 75/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0327 - accuracy: 0.3735 - val_loss: 2.0930 - val_accuracy: 0.3568\n",
      "Epoch 76/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0298 - accuracy: 0.3738 - val_loss: 2.0926 - val_accuracy: 0.3586\n",
      "Epoch 77/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0306 - accuracy: 0.3763 - val_loss: 2.0911 - val_accuracy: 0.3606\n",
      "Epoch 78/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0268 - accuracy: 0.3769 - val_loss: 2.0948 - val_accuracy: 0.3613\n",
      "Epoch 79/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0306 - accuracy: 0.3741 - val_loss: 2.0945 - val_accuracy: 0.3596\n",
      "Epoch 80/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0284 - accuracy: 0.3759 - val_loss: 2.0950 - val_accuracy: 0.3561\n",
      "Epoch 81/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0262 - accuracy: 0.3761 - val_loss: 2.0932 - val_accuracy: 0.3599\n",
      "Epoch 82/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0279 - accuracy: 0.3766 - val_loss: 2.0929 - val_accuracy: 0.3608\n",
      "Epoch 83/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0258 - accuracy: 0.3761 - val_loss: 2.0922 - val_accuracy: 0.3621\n",
      "Epoch 84/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0250 - accuracy: 0.3768 - val_loss: 2.0930 - val_accuracy: 0.3610\n",
      "Epoch 85/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0234 - accuracy: 0.3753 - val_loss: 2.0932 - val_accuracy: 0.3590\n",
      "Epoch 86/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0226 - accuracy: 0.3767 - val_loss: 2.0932 - val_accuracy: 0.3599\n",
      "Epoch 87/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0228 - accuracy: 0.3775 - val_loss: 2.0909 - val_accuracy: 0.3592\n",
      "Epoch 88/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0216 - accuracy: 0.3798 - val_loss: 2.0927 - val_accuracy: 0.3588\n",
      "Epoch 89/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0177 - accuracy: 0.3766 - val_loss: 2.0933 - val_accuracy: 0.3572\n",
      "Epoch 90/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0198 - accuracy: 0.3792 - val_loss: 2.0918 - val_accuracy: 0.3606\n",
      "Epoch 91/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0207 - accuracy: 0.3782 - val_loss: 2.0913 - val_accuracy: 0.3622\n",
      "Epoch 92/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0188 - accuracy: 0.3770 - val_loss: 2.0910 - val_accuracy: 0.3628\n",
      "Epoch 93/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0167 - accuracy: 0.3786 - val_loss: 2.0920 - val_accuracy: 0.3639\n",
      "Epoch 94/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0185 - accuracy: 0.3788 - val_loss: 2.0918 - val_accuracy: 0.3582\n",
      "Epoch 95/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0182 - accuracy: 0.3758 - val_loss: 2.0911 - val_accuracy: 0.3606\n",
      "Epoch 96/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0153 - accuracy: 0.3805 - val_loss: 2.0908 - val_accuracy: 0.3599\n",
      "Epoch 97/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0139 - accuracy: 0.3769 - val_loss: 2.0922 - val_accuracy: 0.3590\n",
      "Epoch 98/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0138 - accuracy: 0.3788 - val_loss: 2.0934 - val_accuracy: 0.3574\n",
      "Epoch 99/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0129 - accuracy: 0.3787 - val_loss: 2.0939 - val_accuracy: 0.3555\n",
      "Epoch 100/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0160 - accuracy: 0.3772 - val_loss: 2.0954 - val_accuracy: 0.3579\n",
      "Epoch 101/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0136 - accuracy: 0.3788 - val_loss: 2.0919 - val_accuracy: 0.3569\n",
      "Epoch 102/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0125 - accuracy: 0.3789 - val_loss: 2.0914 - val_accuracy: 0.3602\n",
      "Epoch 103/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0141 - accuracy: 0.3789 - val_loss: 2.0932 - val_accuracy: 0.3608\n",
      "Epoch 104/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0114 - accuracy: 0.3803 - val_loss: 2.0910 - val_accuracy: 0.3595\n",
      "Epoch 105/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0087 - accuracy: 0.3815 - val_loss: 2.0916 - val_accuracy: 0.3608\n",
      "Epoch 106/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0061 - accuracy: 0.3820 - val_loss: 2.0918 - val_accuracy: 0.3608\n",
      "Epoch 107/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0074 - accuracy: 0.3801 - val_loss: 2.0932 - val_accuracy: 0.3603\n",
      "Epoch 108/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0071 - accuracy: 0.3800 - val_loss: 2.0901 - val_accuracy: 0.3586\n",
      "Epoch 109/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0062 - accuracy: 0.3812 - val_loss: 2.0903 - val_accuracy: 0.3607\n",
      "Epoch 110/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0060 - accuracy: 0.3804 - val_loss: 2.0899 - val_accuracy: 0.3585\n",
      "Epoch 111/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0042 - accuracy: 0.3828 - val_loss: 2.0923 - val_accuracy: 0.3610\n",
      "Epoch 112/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0052 - accuracy: 0.3804 - val_loss: 2.0918 - val_accuracy: 0.3600\n",
      "Epoch 113/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0066 - accuracy: 0.3814 - val_loss: 2.0932 - val_accuracy: 0.3620\n",
      "Epoch 114/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0024 - accuracy: 0.3828 - val_loss: 2.0923 - val_accuracy: 0.3608\n",
      "Epoch 115/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0046 - accuracy: 0.3802 - val_loss: 2.0912 - val_accuracy: 0.3618\n",
      "Epoch 116/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0020 - accuracy: 0.3800 - val_loss: 2.0905 - val_accuracy: 0.3597\n",
      "Epoch 117/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0014 - accuracy: 0.3820 - val_loss: 2.0921 - val_accuracy: 0.3620\n",
      "Epoch 118/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0021 - accuracy: 0.3814 - val_loss: 2.0917 - val_accuracy: 0.3592\n",
      "Epoch 119/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 2.0001 - accuracy: 0.3833 - val_loss: 2.0922 - val_accuracy: 0.3608\n",
      "Epoch 120/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9979 - accuracy: 0.3836 - val_loss: 2.0907 - val_accuracy: 0.3604\n",
      "Epoch 121/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9973 - accuracy: 0.3817 - val_loss: 2.0918 - val_accuracy: 0.3606\n",
      "Epoch 122/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9984 - accuracy: 0.3829 - val_loss: 2.0937 - val_accuracy: 0.3608\n",
      "Epoch 123/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9974 - accuracy: 0.3821 - val_loss: 2.0904 - val_accuracy: 0.3593\n",
      "Epoch 124/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9958 - accuracy: 0.3827 - val_loss: 2.0900 - val_accuracy: 0.3596\n",
      "Epoch 125/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9947 - accuracy: 0.3837 - val_loss: 2.0919 - val_accuracy: 0.3599\n",
      "Epoch 126/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9941 - accuracy: 0.3842 - val_loss: 2.0930 - val_accuracy: 0.3590\n",
      "Epoch 127/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9941 - accuracy: 0.3836 - val_loss: 2.0919 - val_accuracy: 0.3597\n",
      "Epoch 128/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9941 - accuracy: 0.3854 - val_loss: 2.0913 - val_accuracy: 0.3624\n",
      "Epoch 129/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9939 - accuracy: 0.3863 - val_loss: 2.0919 - val_accuracy: 0.3599\n",
      "Epoch 130/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9932 - accuracy: 0.3862 - val_loss: 2.0923 - val_accuracy: 0.3592\n",
      "Epoch 131/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9935 - accuracy: 0.3828 - val_loss: 2.0917 - val_accuracy: 0.3639\n",
      "Epoch 132/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9899 - accuracy: 0.3878 - val_loss: 2.0909 - val_accuracy: 0.3610\n",
      "Epoch 133/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9891 - accuracy: 0.3848 - val_loss: 2.0919 - val_accuracy: 0.3606\n",
      "Epoch 134/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9909 - accuracy: 0.3830 - val_loss: 2.0947 - val_accuracy: 0.3586\n",
      "Epoch 135/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9898 - accuracy: 0.3851 - val_loss: 2.0934 - val_accuracy: 0.3595\n",
      "Epoch 136/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9885 - accuracy: 0.3865 - val_loss: 2.0932 - val_accuracy: 0.3613\n",
      "Epoch 137/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9889 - accuracy: 0.3855 - val_loss: 2.0915 - val_accuracy: 0.3592\n",
      "Epoch 138/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9884 - accuracy: 0.3839 - val_loss: 2.0957 - val_accuracy: 0.3583\n",
      "Epoch 139/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9886 - accuracy: 0.3839 - val_loss: 2.0952 - val_accuracy: 0.3567\n",
      "Epoch 140/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9857 - accuracy: 0.3860 - val_loss: 2.0942 - val_accuracy: 0.3631\n",
      "Epoch 141/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9852 - accuracy: 0.3849 - val_loss: 2.0918 - val_accuracy: 0.3592\n",
      "Epoch 142/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9851 - accuracy: 0.3866 - val_loss: 2.0925 - val_accuracy: 0.3628\n",
      "Epoch 143/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9844 - accuracy: 0.3853 - val_loss: 2.0918 - val_accuracy: 0.3590\n",
      "Epoch 144/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9836 - accuracy: 0.3855 - val_loss: 2.0956 - val_accuracy: 0.3596\n",
      "Epoch 145/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9853 - accuracy: 0.3848 - val_loss: 2.0955 - val_accuracy: 0.3581\n",
      "Epoch 146/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9843 - accuracy: 0.3862 - val_loss: 2.0921 - val_accuracy: 0.3620\n",
      "Epoch 147/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9836 - accuracy: 0.3861 - val_loss: 2.0926 - val_accuracy: 0.3596\n",
      "Epoch 148/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9789 - accuracy: 0.3867 - val_loss: 2.0931 - val_accuracy: 0.3604\n",
      "Epoch 149/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9804 - accuracy: 0.3880 - val_loss: 2.0938 - val_accuracy: 0.3586\n",
      "Epoch 150/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9818 - accuracy: 0.3862 - val_loss: 2.0922 - val_accuracy: 0.3593\n",
      "Epoch 151/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9796 - accuracy: 0.3869 - val_loss: 2.0923 - val_accuracy: 0.3581\n",
      "Epoch 152/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9772 - accuracy: 0.3856 - val_loss: 2.0937 - val_accuracy: 0.3574\n",
      "Epoch 153/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9788 - accuracy: 0.3875 - val_loss: 2.0937 - val_accuracy: 0.3589\n",
      "Epoch 154/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9760 - accuracy: 0.3875 - val_loss: 2.0912 - val_accuracy: 0.3606\n",
      "Epoch 155/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9737 - accuracy: 0.3872 - val_loss: 2.0934 - val_accuracy: 0.3627\n",
      "Epoch 156/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9754 - accuracy: 0.3883 - val_loss: 2.0942 - val_accuracy: 0.3561\n",
      "Epoch 157/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9740 - accuracy: 0.3881 - val_loss: 2.0983 - val_accuracy: 0.3641\n",
      "Epoch 158/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9775 - accuracy: 0.3869 - val_loss: 2.0962 - val_accuracy: 0.3621\n",
      "Epoch 159/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9735 - accuracy: 0.3870 - val_loss: 2.0942 - val_accuracy: 0.3600\n",
      "Epoch 160/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9740 - accuracy: 0.3892 - val_loss: 2.0936 - val_accuracy: 0.3600\n",
      "Epoch 161/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9714 - accuracy: 0.3894 - val_loss: 2.0932 - val_accuracy: 0.3590\n",
      "Epoch 162/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9716 - accuracy: 0.3886 - val_loss: 2.0936 - val_accuracy: 0.3590\n",
      "Epoch 163/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9711 - accuracy: 0.3887 - val_loss: 2.0937 - val_accuracy: 0.3608\n",
      "Epoch 164/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9710 - accuracy: 0.3866 - val_loss: 2.0944 - val_accuracy: 0.3588\n",
      "Epoch 165/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9715 - accuracy: 0.3870 - val_loss: 2.0938 - val_accuracy: 0.3620\n",
      "Epoch 166/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9672 - accuracy: 0.3904 - val_loss: 2.0949 - val_accuracy: 0.3613\n",
      "Epoch 167/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9695 - accuracy: 0.3891 - val_loss: 2.0949 - val_accuracy: 0.3588\n",
      "Epoch 168/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9705 - accuracy: 0.3902 - val_loss: 2.0953 - val_accuracy: 0.3588\n",
      "Epoch 169/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9690 - accuracy: 0.3911 - val_loss: 2.0965 - val_accuracy: 0.3581\n",
      "Epoch 170/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9665 - accuracy: 0.3883 - val_loss: 2.0956 - val_accuracy: 0.3575\n",
      "Epoch 171/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9646 - accuracy: 0.3892 - val_loss: 2.0944 - val_accuracy: 0.3608\n",
      "Epoch 172/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9652 - accuracy: 0.3909 - val_loss: 2.0961 - val_accuracy: 0.3622\n",
      "Epoch 173/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9632 - accuracy: 0.3926 - val_loss: 2.0946 - val_accuracy: 0.3593\n",
      "Epoch 174/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9644 - accuracy: 0.3910 - val_loss: 2.0958 - val_accuracy: 0.3613\n",
      "Epoch 175/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9622 - accuracy: 0.3928 - val_loss: 2.0968 - val_accuracy: 0.3607\n",
      "Epoch 176/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9591 - accuracy: 0.3938 - val_loss: 2.0940 - val_accuracy: 0.3613\n",
      "Epoch 177/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9596 - accuracy: 0.3918 - val_loss: 2.0972 - val_accuracy: 0.3575\n",
      "Epoch 178/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9601 - accuracy: 0.3930 - val_loss: 2.1001 - val_accuracy: 0.3621\n",
      "Epoch 179/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9599 - accuracy: 0.3915 - val_loss: 2.0956 - val_accuracy: 0.3618\n",
      "Epoch 180/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9605 - accuracy: 0.3913 - val_loss: 2.0957 - val_accuracy: 0.3621\n",
      "Epoch 181/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9575 - accuracy: 0.3934 - val_loss: 2.0964 - val_accuracy: 0.3599\n",
      "Epoch 182/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9600 - accuracy: 0.3929 - val_loss: 2.0986 - val_accuracy: 0.3572\n",
      "Epoch 183/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9597 - accuracy: 0.3933 - val_loss: 2.0964 - val_accuracy: 0.3585\n",
      "Epoch 184/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9562 - accuracy: 0.3926 - val_loss: 2.0974 - val_accuracy: 0.3581\n",
      "Epoch 185/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9564 - accuracy: 0.3926 - val_loss: 2.0988 - val_accuracy: 0.3575\n",
      "Epoch 186/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9551 - accuracy: 0.3919 - val_loss: 2.1029 - val_accuracy: 0.3588\n",
      "Epoch 187/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9595 - accuracy: 0.3925 - val_loss: 2.0999 - val_accuracy: 0.3586\n",
      "Epoch 188/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9547 - accuracy: 0.3948 - val_loss: 2.0982 - val_accuracy: 0.3581\n",
      "Epoch 189/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9523 - accuracy: 0.3943 - val_loss: 2.0999 - val_accuracy: 0.3586\n",
      "Epoch 190/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9533 - accuracy: 0.3936 - val_loss: 2.0995 - val_accuracy: 0.3634\n",
      "Epoch 191/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9522 - accuracy: 0.3940 - val_loss: 2.0989 - val_accuracy: 0.3589\n",
      "Epoch 192/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9525 - accuracy: 0.3935 - val_loss: 2.1026 - val_accuracy: 0.3565\n",
      "Epoch 193/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9511 - accuracy: 0.3966 - val_loss: 2.0999 - val_accuracy: 0.3582\n",
      "Epoch 194/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9519 - accuracy: 0.3955 - val_loss: 2.1004 - val_accuracy: 0.3592\n",
      "Epoch 195/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9488 - accuracy: 0.3968 - val_loss: 2.1016 - val_accuracy: 0.3555\n",
      "Epoch 196/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9480 - accuracy: 0.3945 - val_loss: 2.0981 - val_accuracy: 0.3632\n",
      "Epoch 197/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9517 - accuracy: 0.3944 - val_loss: 2.1008 - val_accuracy: 0.3590\n",
      "Epoch 198/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9496 - accuracy: 0.3929 - val_loss: 2.0992 - val_accuracy: 0.3583\n",
      "Epoch 199/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9466 - accuracy: 0.3955 - val_loss: 2.0999 - val_accuracy: 0.3600\n",
      "Epoch 200/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9436 - accuracy: 0.3972 - val_loss: 2.1011 - val_accuracy: 0.3583\n",
      "Epoch 201/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9486 - accuracy: 0.3928 - val_loss: 2.0985 - val_accuracy: 0.3600\n",
      "Epoch 202/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9467 - accuracy: 0.3959 - val_loss: 2.1006 - val_accuracy: 0.3583\n",
      "Epoch 203/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9477 - accuracy: 0.3931 - val_loss: 2.1009 - val_accuracy: 0.3621\n",
      "Epoch 204/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9454 - accuracy: 0.3974 - val_loss: 2.1015 - val_accuracy: 0.3593\n",
      "Epoch 205/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9408 - accuracy: 0.3982 - val_loss: 2.0996 - val_accuracy: 0.3578\n",
      "Epoch 206/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9449 - accuracy: 0.3946 - val_loss: 2.1012 - val_accuracy: 0.3575\n",
      "Epoch 207/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9405 - accuracy: 0.3978 - val_loss: 2.0992 - val_accuracy: 0.3588\n",
      "Epoch 208/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9402 - accuracy: 0.3946 - val_loss: 2.1019 - val_accuracy: 0.3627\n",
      "Epoch 209/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9386 - accuracy: 0.3988 - val_loss: 2.0998 - val_accuracy: 0.3611\n",
      "Epoch 210/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9406 - accuracy: 0.3975 - val_loss: 2.1014 - val_accuracy: 0.3599\n",
      "Epoch 211/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9395 - accuracy: 0.3997 - val_loss: 2.1035 - val_accuracy: 0.3575\n",
      "Epoch 212/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9381 - accuracy: 0.3981 - val_loss: 2.1039 - val_accuracy: 0.3554\n",
      "Epoch 213/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9370 - accuracy: 0.3968 - val_loss: 2.1017 - val_accuracy: 0.3603\n",
      "Epoch 214/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9357 - accuracy: 0.3968 - val_loss: 2.1049 - val_accuracy: 0.3590\n",
      "Epoch 215/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9366 - accuracy: 0.3978 - val_loss: 2.1029 - val_accuracy: 0.3572\n",
      "Epoch 216/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9375 - accuracy: 0.3994 - val_loss: 2.1027 - val_accuracy: 0.3555\n",
      "Epoch 217/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9352 - accuracy: 0.4007 - val_loss: 2.1037 - val_accuracy: 0.3579\n",
      "Epoch 218/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9370 - accuracy: 0.3993 - val_loss: 2.1064 - val_accuracy: 0.3569\n",
      "Epoch 219/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9338 - accuracy: 0.3994 - val_loss: 2.1049 - val_accuracy: 0.3597\n",
      "Epoch 220/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9364 - accuracy: 0.3996 - val_loss: 2.1028 - val_accuracy: 0.3550\n",
      "Epoch 221/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9329 - accuracy: 0.3973 - val_loss: 2.1052 - val_accuracy: 0.3589\n",
      "Epoch 222/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9331 - accuracy: 0.3995 - val_loss: 2.1051 - val_accuracy: 0.3554\n",
      "Epoch 223/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9322 - accuracy: 0.3989 - val_loss: 2.1062 - val_accuracy: 0.3557\n",
      "Epoch 224/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9305 - accuracy: 0.3979 - val_loss: 2.1045 - val_accuracy: 0.3572\n",
      "Epoch 225/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9318 - accuracy: 0.4005 - val_loss: 2.1053 - val_accuracy: 0.3582\n",
      "Epoch 226/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9308 - accuracy: 0.3993 - val_loss: 2.1035 - val_accuracy: 0.3590\n",
      "Epoch 227/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9297 - accuracy: 0.3980 - val_loss: 2.1052 - val_accuracy: 0.3581\n",
      "Epoch 228/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9312 - accuracy: 0.3998 - val_loss: 2.1051 - val_accuracy: 0.3551\n",
      "Epoch 229/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9292 - accuracy: 0.4010 - val_loss: 2.1055 - val_accuracy: 0.3567\n",
      "Epoch 230/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9291 - accuracy: 0.3970 - val_loss: 2.1027 - val_accuracy: 0.3581\n",
      "Epoch 231/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9263 - accuracy: 0.4011 - val_loss: 2.1067 - val_accuracy: 0.3582\n",
      "Epoch 232/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9260 - accuracy: 0.4005 - val_loss: 2.1081 - val_accuracy: 0.3571\n",
      "Epoch 233/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9261 - accuracy: 0.4016 - val_loss: 2.1077 - val_accuracy: 0.3539\n",
      "Epoch 234/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9264 - accuracy: 0.4000 - val_loss: 2.1055 - val_accuracy: 0.3596\n",
      "Epoch 235/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9249 - accuracy: 0.4031 - val_loss: 2.1082 - val_accuracy: 0.3554\n",
      "Epoch 236/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9232 - accuracy: 0.4002 - val_loss: 2.1052 - val_accuracy: 0.3553\n",
      "Epoch 237/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9247 - accuracy: 0.4014 - val_loss: 2.1057 - val_accuracy: 0.3547\n",
      "Epoch 238/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9204 - accuracy: 0.4026 - val_loss: 2.1090 - val_accuracy: 0.3550\n",
      "Epoch 239/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9224 - accuracy: 0.4034 - val_loss: 2.1081 - val_accuracy: 0.3585\n",
      "Epoch 240/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9157 - accuracy: 0.4037 - val_loss: 2.1107 - val_accuracy: 0.3589\n",
      "Epoch 241/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9201 - accuracy: 0.4028 - val_loss: 2.1090 - val_accuracy: 0.3571\n",
      "Epoch 242/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9200 - accuracy: 0.4024 - val_loss: 2.1096 - val_accuracy: 0.3595\n",
      "Epoch 243/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9192 - accuracy: 0.4043 - val_loss: 2.1090 - val_accuracy: 0.3579\n",
      "Epoch 244/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9146 - accuracy: 0.4050 - val_loss: 2.1083 - val_accuracy: 0.3602\n",
      "Epoch 245/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9183 - accuracy: 0.4031 - val_loss: 2.1097 - val_accuracy: 0.3574\n",
      "Epoch 246/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9169 - accuracy: 0.4031 - val_loss: 2.1089 - val_accuracy: 0.3575\n",
      "Epoch 247/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9159 - accuracy: 0.4041 - val_loss: 2.1088 - val_accuracy: 0.3583\n",
      "Epoch 248/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9166 - accuracy: 0.4020 - val_loss: 2.1101 - val_accuracy: 0.3565\n",
      "Epoch 249/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9158 - accuracy: 0.4042 - val_loss: 2.1099 - val_accuracy: 0.3585\n",
      "Epoch 250/250\n",
      "28739/28739 [==============================] - 0s 8us/sample - loss: 1.9123 - accuracy: 0.4060 - val_loss: 2.1093 - val_accuracy: 0.3592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_micro</th>\n",
       "      <td>0.360558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_macro</th>\n",
       "      <td>0.360648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_accuracy</th>\n",
       "      <td>0.360558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_batch_val_accuracy</th>\n",
       "      <td>0.364986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_accuracy</th>\n",
       "      <td>0.377837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_loss</th>\n",
       "      <td>2.084618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loss</th>\n",
       "      <td>2.014422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>2743.034329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "avg_val_f1_micro           0.360558\n",
       "avg_val_f1_macro           0.360648\n",
       "avg_val_accuracy           0.360558\n",
       "avg_batch_val_accuracy     0.364986\n",
       "avg_accuracy               0.377837\n",
       "avg_val_loss               2.084618\n",
       "avg_loss                   2.014422\n",
       "train_time              2743.034329"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_fold(x_train, y_train, x_val, y_val, run_name, base_models, sklearn_models, sets_len, aux_models_outputs_size, fold=None):\n",
    "    \n",
    "    ensemble_model = create_ensemble_model(base_models, aux_models_outputs_size)\n",
    "    \n",
    "    if fold is not None:\n",
    "        run_name += '_fold' + str(fold)\n",
    "        print('Training fold ' + str(fold))\n",
    "    \n",
    "    # Unglue feature sets\n",
    "    sets_stop_index = list(itertools.accumulate(sets_len))\n",
    "    x_train_sets = unglue_feature_sets(x_train, sets_stop_index)\n",
    "    x_val_sets = unglue_feature_sets(x_val, sets_stop_index)\n",
    "    \n",
    "    nb_base_models = len(base_models)\n",
    "    \n",
    "    # Make sklearn models predictions\n",
    "    for i, sk_model in enumerate(sklearn_models):\n",
    "        \n",
    "        print('Making predictions with sklearn model no ' + str(i+1))\n",
    "        \n",
    "        set_i = nb_base_models + i\n",
    "        \n",
    "        x_train_set = x_train_sets[set_i]\n",
    "        x_val_set = x_val_sets[set_i]\n",
    "        \n",
    "        x_train_sets[set_i] = sk_model.predict_proba(x_train_set)\n",
    "        x_val_sets[set_i] = sk_model.predict_proba(x_val_set)\n",
    "    \n",
    "    # Callbacks\n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    #weight_restorer = BestWeightsRestorer(monitor='val_loss', mode='min', verbose=1)\n",
    "    callbacks = [\n",
    "        tk_board,\n",
    "        #weight_restorer\n",
    "    ]\n",
    "    \n",
    "    history = ensemble_model.fit(\n",
    "        x=x_train_sets,\n",
    "        y=y_train,\n",
    "        validation_data=[x_val_sets, y_val],\n",
    "        epochs=250,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    prob_predictions = ensemble_model.predict(x_val_sets)\n",
    "    predictions = prob_predictions.argmax(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "    \n",
    "experiment_number += 1\n",
    "run_name = 'ensemble_five_cv_' + str(experiment_number)\n",
    "\n",
    "results = resultsUtil.cross_validate(\n",
    "    x=np.hstack(x_split),\n",
    "    y=lbls_oh,\n",
    "    y_label_encoded=lbls_lb,\n",
    "    n_splits=5,\n",
    "    train_func=train_fold,\n",
    "    run_name=run_name,\n",
    "    base_models=base_models,\n",
    "    sklearn_models=sklearn_models,\n",
    "    sets_len=sets_len,\n",
    "    aux_models_outputs_size=aux_models_outputs_size\n",
    ")\n",
    "\n",
    "runUtil.save_run_results(run_name, results)\n",
    "\n",
    "resultsdf = pd.DataFrame([results]).transpose()\n",
    "\n",
    "display(resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with sklearn model no 1\n",
      "Making predictions with sklearn model no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  80 out of  80 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35911/35911 [==============================] - 2s 46us/sample - loss: 3.1302 - accuracy: 0.1585\n",
      "Epoch 2/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.8457 - accuracy: 0.2300\n",
      "Epoch 3/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.4954 - accuracy: 0.2813\n",
      "Epoch 4/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.3035 - accuracy: 0.3170\n",
      "Epoch 5/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.2278 - accuracy: 0.3282\n",
      "Epoch 6/100\n",
      "35911/35911 [==============================] - 0s 11us/sample - loss: 2.1901 - accuracy: 0.3331\n",
      "Epoch 7/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1692 - accuracy: 0.3387\n",
      "Epoch 8/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1563 - accuracy: 0.3420\n",
      "Epoch 9/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1463 - accuracy: 0.3437\n",
      "Epoch 10/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1368 - accuracy: 0.3485\n",
      "Epoch 11/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1294 - accuracy: 0.3498\n",
      "Epoch 12/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1259 - accuracy: 0.3487\n",
      "Epoch 13/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1199 - accuracy: 0.3513\n",
      "Epoch 14/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1181 - accuracy: 0.3520\n",
      "Epoch 15/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1117 - accuracy: 0.3541\n",
      "Epoch 16/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1070 - accuracy: 0.3543\n",
      "Epoch 17/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1054 - accuracy: 0.3551\n",
      "Epoch 18/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1017 - accuracy: 0.3566\n",
      "Epoch 19/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.1003 - accuracy: 0.3571\n",
      "Epoch 20/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0972 - accuracy: 0.3573\n",
      "Epoch 21/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0940 - accuracy: 0.3597\n",
      "Epoch 22/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0927 - accuracy: 0.3589\n",
      "Epoch 23/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0917 - accuracy: 0.3584\n",
      "Epoch 24/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0879 - accuracy: 0.3587\n",
      "Epoch 25/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0871 - accuracy: 0.3605\n",
      "Epoch 26/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0842 - accuracy: 0.3630\n",
      "Epoch 27/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0816 - accuracy: 0.3608\n",
      "Epoch 28/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0797 - accuracy: 0.3641\n",
      "Epoch 29/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0780 - accuracy: 0.3610\n",
      "Epoch 30/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0756 - accuracy: 0.3614\n",
      "Epoch 31/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0753 - accuracy: 0.3628\n",
      "Epoch 32/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0740 - accuracy: 0.3652\n",
      "Epoch 33/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0719 - accuracy: 0.3660\n",
      "Epoch 34/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0743 - accuracy: 0.3628\n",
      "Epoch 35/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0707 - accuracy: 0.3650\n",
      "Epoch 36/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0700 - accuracy: 0.3656\n",
      "Epoch 37/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0664 - accuracy: 0.3658\n",
      "Epoch 38/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0667 - accuracy: 0.3677\n",
      "Epoch 39/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0645 - accuracy: 0.3650\n",
      "Epoch 40/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0628 - accuracy: 0.3673\n",
      "Epoch 41/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0622 - accuracy: 0.3669\n",
      "Epoch 42/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0585 - accuracy: 0.3671\n",
      "Epoch 43/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0595 - accuracy: 0.3686\n",
      "Epoch 44/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0583 - accuracy: 0.3662\n",
      "Epoch 45/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0592 - accuracy: 0.3684\n",
      "Epoch 46/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0575 - accuracy: 0.3688\n",
      "Epoch 47/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0572 - accuracy: 0.3682\n",
      "Epoch 48/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0536 - accuracy: 0.3692\n",
      "Epoch 49/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0536 - accuracy: 0.3687\n",
      "Epoch 50/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0518 - accuracy: 0.3692\n",
      "Epoch 51/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0507 - accuracy: 0.3696\n",
      "Epoch 52/100\n",
      "35911/35911 [==============================] - 0s 11us/sample - loss: 2.0492 - accuracy: 0.3709\n",
      "Epoch 53/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0496 - accuracy: 0.3696\n",
      "Epoch 54/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0485 - accuracy: 0.3702\n",
      "Epoch 55/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0469 - accuracy: 0.3698\n",
      "Epoch 56/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0451 - accuracy: 0.3697\n",
      "Epoch 57/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0461 - accuracy: 0.3721\n",
      "Epoch 58/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0440 - accuracy: 0.3718\n",
      "Epoch 59/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0449 - accuracy: 0.3725\n",
      "Epoch 60/100\n",
      "35911/35911 [==============================] - 0s 11us/sample - loss: 2.0421 - accuracy: 0.3725\n",
      "Epoch 61/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0414 - accuracy: 0.3717\n",
      "Epoch 62/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0402 - accuracy: 0.3730\n",
      "Epoch 63/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0392 - accuracy: 0.3738\n",
      "Epoch 64/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0393 - accuracy: 0.3733\n",
      "Epoch 65/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0388 - accuracy: 0.3730\n",
      "Epoch 66/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0363 - accuracy: 0.3730\n",
      "Epoch 67/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0362 - accuracy: 0.3721\n",
      "Epoch 68/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0351 - accuracy: 0.3737\n",
      "Epoch 69/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0344 - accuracy: 0.3738\n",
      "Epoch 70/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0351 - accuracy: 0.3744\n",
      "Epoch 71/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0346 - accuracy: 0.3749\n",
      "Epoch 72/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0320 - accuracy: 0.3730\n",
      "Epoch 73/100\n",
      "35911/35911 [==============================] - 0s 11us/sample - loss: 2.0303 - accuracy: 0.3743\n",
      "Epoch 74/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0331 - accuracy: 0.3734\n",
      "Epoch 75/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0279 - accuracy: 0.3765\n",
      "Epoch 76/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0294 - accuracy: 0.3751\n",
      "Epoch 77/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0267 - accuracy: 0.3730\n",
      "Epoch 78/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0264 - accuracy: 0.3767\n",
      "Epoch 79/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0267 - accuracy: 0.3771\n",
      "Epoch 80/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0243 - accuracy: 0.3775\n",
      "Epoch 81/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0271 - accuracy: 0.3772\n",
      "Epoch 82/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0247 - accuracy: 0.3774\n",
      "Epoch 83/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0225 - accuracy: 0.3768\n",
      "Epoch 84/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0245 - accuracy: 0.3760\n",
      "Epoch 85/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0223 - accuracy: 0.3762\n",
      "Epoch 86/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0214 - accuracy: 0.3779\n",
      "Epoch 87/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0210 - accuracy: 0.3777\n",
      "Epoch 88/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0215 - accuracy: 0.3770\n",
      "Epoch 89/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0179 - accuracy: 0.3771\n",
      "Epoch 90/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0199 - accuracy: 0.3774\n",
      "Epoch 91/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0176 - accuracy: 0.3777\n",
      "Epoch 92/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0175 - accuracy: 0.3785\n",
      "Epoch 93/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0178 - accuracy: 0.3795\n",
      "Epoch 94/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0155 - accuracy: 0.3780\n",
      "Epoch 95/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0151 - accuracy: 0.3784\n",
      "Epoch 96/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0142 - accuracy: 0.3780\n",
      "Epoch 97/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0149 - accuracy: 0.3786\n",
      "Epoch 98/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0119 - accuracy: 0.3797\n",
      "Epoch 99/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0139 - accuracy: 0.3802\n",
      "Epoch 100/100\n",
      "35911/35911 [==============================] - 0s 10us/sample - loss: 2.0114 - accuracy: 0.3789\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(x, y, run_name, base_models, sklearn_models, aux_models_outputs_size):\n",
    "    \n",
    "    save_path = constants.MODELS_PATH + run_name + '.h5' \n",
    "    \n",
    "    x_sets = x\n",
    "    nb_base_models = len(base_models)\n",
    "\n",
    "    for i, sk_model in enumerate(sklearn_models):\n",
    "    \n",
    "        print('Making predictions with sklearn model no ' + str(i+1))\n",
    "        \n",
    "        set_i = nb_base_models + i\n",
    "        \n",
    "        x_sets[set_i] = sk_model.predict_proba(x_sets[set_i])\n",
    "    \n",
    "        ensemble_model = create_ensemble_model(base_models, aux_models_outputs_size)\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    \n",
    "    ensemble_model.fit(\n",
    "        x=x_sets,\n",
    "        y=y,\n",
    "        epochs=100,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    ensemble_model.save(save_path)\n",
    "\n",
    "    \n",
    "train_final_model(x_split, lbls_oh, 'ensemble_five_final_4', base_models, sklearn_models, aux_models_outputs_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
