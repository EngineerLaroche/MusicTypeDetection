{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload chaque module spécifié par %aimport\n",
    "%autoreload 1\n",
    "\n",
    "%aimport src.kerasCallbacks\n",
    "%aimport src.results\n",
    "\n",
    "from IPython.display import display\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from src import constants\n",
    "from src.kerasCallbacks import BestWeightsRestorer\n",
    "import src.results as resultsUtil\n",
    "import src.runUtil as runUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_feature_set():\n",
    "\n",
    "    file_path = path.join(constants.DATA_PATH, 'jmirderivatives_base_split.csv')\n",
    "    \n",
    "    ftrs = np.array(pd.read_csv(file_path, header=None).values[:,2:-1])\n",
    "    lbls = np.array(pd.read_csv(file_path, header=None).values[:,-1])\n",
    "    \n",
    "    return ftrs, lbls\n",
    "\n",
    "def scale_features(ftrs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    ftrs_scld = scaler.fit_transform(ftrs)\n",
    "    \n",
    "    return ftrs_scld\n",
    "\n",
    "def one_hot_labels(lbls):\n",
    "    \n",
    "    lbls_1d = lbls.reshape(len(lbls), 1)\n",
    "        \n",
    "    oh_encoder = OneHotEncoder(sparse=False)\n",
    "    lbls_oh = oh_encoder.fit_transform(lbls_1d)\n",
    "    \n",
    "    return lbls_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143644, 96)\n"
     ]
    }
   ],
   "source": [
    "# Load the features and the labels\n",
    "raw_ftrs, raw_lbls = load_feature_set()\n",
    "\n",
    "lbls_oh = one_hot_labels(raw_lbls)\n",
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoded_lbls = lbl_encoder.fit_transform(raw_lbls)\n",
    "\n",
    "ftrs = scale_features(raw_ftrs)\n",
    "\n",
    "print(ftrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='mlp_derivs_input')\n",
    "    \n",
    "    layer = Dense(90, activation='relu', name='mlp_derivs_dense_1')(inputs)\n",
    "    layer = Dropout(0.025, name='mlp_derivs_dropout_1')(layer)\n",
    "    layer = Dense(70, activation='relu', name='mlp_derivs_dense_2')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_derivs_dropout_2')(layer)\n",
    "    layer = Dense(50, activation='relu', name='mlp_derivs_dense_3')(layer)\n",
    "    layer = Dropout(0.025, name='mlp_derivs_dropout_3')(layer)\n",
    "    layer = Dense(30, activation='relu', name='mlp_derivs_dense_4')(layer)\n",
    "    \n",
    "    outputs = Dense(25, activation='softmax', name='mlp_derivs_output')(layer)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=[\n",
    "            CategoricalAccuracy(name='accuracy')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training fold 1\n",
      "Train on 114904 samples, validate on 28740 samples\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "114904/114904 [==============================] - 1s 6us/sample - loss: 2.9987 - accuracy: 0.1263 - val_loss: 2.7840 - val_accuracy: 0.1639\n",
      "Epoch 2/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.7227 - accuracy: 0.1773 - val_loss: 2.6410 - val_accuracy: 0.1938\n",
      "Epoch 3/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.6228 - accuracy: 0.1999 - val_loss: 2.5727 - val_accuracy: 0.2099\n",
      "Epoch 4/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.5719 - accuracy: 0.2131 - val_loss: 2.5377 - val_accuracy: 0.2214\n",
      "Epoch 5/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.5425 - accuracy: 0.2207 - val_loss: 2.5151 - val_accuracy: 0.2262\n",
      "Epoch 6/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.5221 - accuracy: 0.2264 - val_loss: 2.4983 - val_accuracy: 0.2308\n",
      "Epoch 7/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.5033 - accuracy: 0.2334 - val_loss: 2.4842 - val_accuracy: 0.2353\n",
      "Epoch 8/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4903 - accuracy: 0.2363 - val_loss: 2.4765 - val_accuracy: 0.2375\n",
      "Epoch 9/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4800 - accuracy: 0.2392 - val_loss: 2.4672 - val_accuracy: 0.2406\n",
      "Epoch 10/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4684 - accuracy: 0.2425 - val_loss: 2.4585 - val_accuracy: 0.2435\n",
      "Epoch 11/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4585 - accuracy: 0.2446 - val_loss: 2.4510 - val_accuracy: 0.2469\n",
      "Epoch 12/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4519 - accuracy: 0.2464 - val_loss: 2.4460 - val_accuracy: 0.2465\n",
      "Epoch 13/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4444 - accuracy: 0.2482 - val_loss: 2.4347 - val_accuracy: 0.2493\n",
      "Epoch 14/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4360 - accuracy: 0.2504 - val_loss: 2.4298 - val_accuracy: 0.2518\n",
      "Epoch 15/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4315 - accuracy: 0.2519 - val_loss: 2.4267 - val_accuracy: 0.2520\n",
      "Epoch 16/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4230 - accuracy: 0.2547 - val_loss: 2.4212 - val_accuracy: 0.2527\n",
      "Epoch 17/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4184 - accuracy: 0.2550 - val_loss: 2.4177 - val_accuracy: 0.2536\n",
      "Epoch 18/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4143 - accuracy: 0.2568 - val_loss: 2.4138 - val_accuracy: 0.2556\n",
      "Epoch 19/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4084 - accuracy: 0.2580 - val_loss: 2.4128 - val_accuracy: 0.2565\n",
      "Epoch 20/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4036 - accuracy: 0.2601 - val_loss: 2.4083 - val_accuracy: 0.2564\n",
      "Epoch 21/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.4011 - accuracy: 0.2597 - val_loss: 2.4060 - val_accuracy: 0.2555\n",
      "Epoch 22/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3945 - accuracy: 0.2629 - val_loss: 2.4008 - val_accuracy: 0.2586\n",
      "Epoch 23/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3921 - accuracy: 0.2625 - val_loss: 2.3998 - val_accuracy: 0.2597\n",
      "Epoch 24/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3858 - accuracy: 0.2634 - val_loss: 2.3975 - val_accuracy: 0.2599\n",
      "Epoch 25/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3857 - accuracy: 0.2649 - val_loss: 2.3965 - val_accuracy: 0.2596\n",
      "Epoch 26/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3826 - accuracy: 0.2656 - val_loss: 2.3942 - val_accuracy: 0.2610\n",
      "Epoch 27/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3784 - accuracy: 0.2669 - val_loss: 2.3933 - val_accuracy: 0.2595\n",
      "Epoch 28/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3757 - accuracy: 0.2661 - val_loss: 2.3881 - val_accuracy: 0.2634\n",
      "Epoch 29/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3712 - accuracy: 0.2674 - val_loss: 2.3874 - val_accuracy: 0.2635\n",
      "Epoch 30/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3690 - accuracy: 0.2694 - val_loss: 2.3874 - val_accuracy: 0.2640\n",
      "Epoch 31/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3671 - accuracy: 0.2708 - val_loss: 2.3849 - val_accuracy: 0.2621\n",
      "Epoch 32/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3638 - accuracy: 0.2702 - val_loss: 2.3844 - val_accuracy: 0.2665\n",
      "Epoch 33/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3620 - accuracy: 0.2705 - val_loss: 2.3824 - val_accuracy: 0.2666\n",
      "Epoch 34/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3588 - accuracy: 0.2722 - val_loss: 2.3811 - val_accuracy: 0.2642\n",
      "Epoch 35/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3565 - accuracy: 0.2728 - val_loss: 2.3788 - val_accuracy: 0.2651\n",
      "Epoch 36/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3534 - accuracy: 0.2739 - val_loss: 2.3790 - val_accuracy: 0.2654\n",
      "Epoch 37/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3527 - accuracy: 0.2721 - val_loss: 2.3786 - val_accuracy: 0.2678\n",
      "Epoch 38/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3484 - accuracy: 0.2741 - val_loss: 2.3755 - val_accuracy: 0.2691\n",
      "Epoch 39/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3473 - accuracy: 0.2745 - val_loss: 2.3742 - val_accuracy: 0.2684\n",
      "Epoch 40/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3468 - accuracy: 0.2748 - val_loss: 2.3758 - val_accuracy: 0.2683\n",
      "Epoch 41/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3453 - accuracy: 0.2752 - val_loss: 2.3742 - val_accuracy: 0.2689\n",
      "Epoch 42/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3417 - accuracy: 0.2773 - val_loss: 2.3713 - val_accuracy: 0.2689\n",
      "Epoch 43/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3399 - accuracy: 0.2771 - val_loss: 2.3716 - val_accuracy: 0.2671\n",
      "Epoch 44/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3387 - accuracy: 0.2780 - val_loss: 2.3709 - val_accuracy: 0.2684\n",
      "Epoch 45/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3349 - accuracy: 0.2781 - val_loss: 2.3701 - val_accuracy: 0.2696\n",
      "Epoch 46/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3354 - accuracy: 0.2786 - val_loss: 2.3693 - val_accuracy: 0.2683\n",
      "Epoch 47/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3328 - accuracy: 0.2797 - val_loss: 2.3675 - val_accuracy: 0.2685\n",
      "Epoch 48/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3322 - accuracy: 0.2798 - val_loss: 2.3680 - val_accuracy: 0.2706\n",
      "Epoch 49/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3313 - accuracy: 0.2787 - val_loss: 2.3653 - val_accuracy: 0.2703\n",
      "Epoch 50/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3289 - accuracy: 0.2805 - val_loss: 2.3647 - val_accuracy: 0.2690\n",
      "Epoch 51/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3295 - accuracy: 0.2812 - val_loss: 2.3652 - val_accuracy: 0.2689\n",
      "Epoch 52/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3255 - accuracy: 0.2810 - val_loss: 2.3651 - val_accuracy: 0.2705\n",
      "Epoch 53/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3228 - accuracy: 0.2813 - val_loss: 2.3662 - val_accuracy: 0.2686\n",
      "Epoch 54/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3224 - accuracy: 0.2817 - val_loss: 2.3612 - val_accuracy: 0.2708\n",
      "Epoch 55/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3217 - accuracy: 0.2833 - val_loss: 2.3628 - val_accuracy: 0.2709\n",
      "Epoch 56/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3198 - accuracy: 0.2835 - val_loss: 2.3615 - val_accuracy: 0.2703\n",
      "Epoch 57/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3173 - accuracy: 0.2842 - val_loss: 2.3616 - val_accuracy: 0.2712\n",
      "Epoch 58/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3166 - accuracy: 0.2832 - val_loss: 2.3604 - val_accuracy: 0.2703\n",
      "Epoch 59/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3160 - accuracy: 0.2838 - val_loss: 2.3615 - val_accuracy: 0.2713\n",
      "Epoch 60/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3138 - accuracy: 0.2848 - val_loss: 2.3623 - val_accuracy: 0.2719\n",
      "Epoch 61/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3117 - accuracy: 0.2852 - val_loss: 2.3628 - val_accuracy: 0.2725\n",
      "Epoch 62/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3122 - accuracy: 0.2861 - val_loss: 2.3582 - val_accuracy: 0.2725\n",
      "Epoch 63/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3103 - accuracy: 0.2850 - val_loss: 2.3595 - val_accuracy: 0.2732\n",
      "Epoch 64/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3100 - accuracy: 0.2854 - val_loss: 2.3574 - val_accuracy: 0.2739\n",
      "Epoch 65/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3093 - accuracy: 0.2870 - val_loss: 2.3589 - val_accuracy: 0.2710\n",
      "Epoch 66/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3080 - accuracy: 0.2857 - val_loss: 2.3586 - val_accuracy: 0.2735\n",
      "Epoch 67/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3086 - accuracy: 0.2870 - val_loss: 2.3582 - val_accuracy: 0.2711\n",
      "Epoch 68/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3062 - accuracy: 0.2866 - val_loss: 2.3582 - val_accuracy: 0.2725\n",
      "Epoch 69/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3056 - accuracy: 0.2876 - val_loss: 2.3584 - val_accuracy: 0.2740\n",
      "Epoch 70/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3040 - accuracy: 0.2854 - val_loss: 2.3560 - val_accuracy: 0.2733\n",
      "Epoch 71/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3032 - accuracy: 0.2875 - val_loss: 2.3567 - val_accuracy: 0.2725\n",
      "Epoch 72/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3009 - accuracy: 0.2877 - val_loss: 2.3556 - val_accuracy: 0.2745\n",
      "Epoch 73/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3008 - accuracy: 0.2876 - val_loss: 2.3578 - val_accuracy: 0.2723\n",
      "Epoch 74/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.3005 - accuracy: 0.2876 - val_loss: 2.3543 - val_accuracy: 0.2744\n",
      "Epoch 75/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.3012 - accuracy: 0.2890 - val_loss: 2.3568 - val_accuracy: 0.2735\n",
      "Epoch 76/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2981 - accuracy: 0.2893 - val_loss: 2.3529 - val_accuracy: 0.2728\n",
      "Epoch 77/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2982 - accuracy: 0.2894 - val_loss: 2.3578 - val_accuracy: 0.2735\n",
      "Epoch 78/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2970 - accuracy: 0.2903 - val_loss: 2.3541 - val_accuracy: 0.2736\n",
      "Epoch 79/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2955 - accuracy: 0.2890 - val_loss: 2.3547 - val_accuracy: 0.2744\n",
      "Epoch 80/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2935 - accuracy: 0.2901 - val_loss: 2.3532 - val_accuracy: 0.2754\n",
      "Epoch 81/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2936 - accuracy: 0.2908 - val_loss: 2.3556 - val_accuracy: 0.2739\n",
      "Epoch 82/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2931 - accuracy: 0.2901 - val_loss: 2.3537 - val_accuracy: 0.2730\n",
      "Epoch 83/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2927 - accuracy: 0.2904 - val_loss: 2.3510 - val_accuracy: 0.2757\n",
      "Epoch 84/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2895 - accuracy: 0.2901 - val_loss: 2.3519 - val_accuracy: 0.2755\n",
      "Epoch 85/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2907 - accuracy: 0.2908 - val_loss: 2.3518 - val_accuracy: 0.2741\n",
      "Epoch 86/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2886 - accuracy: 0.2910 - val_loss: 2.3528 - val_accuracy: 0.2741\n",
      "Epoch 87/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2893 - accuracy: 0.2911 - val_loss: 2.3532 - val_accuracy: 0.2738\n",
      "Epoch 88/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2879 - accuracy: 0.2918 - val_loss: 2.3545 - val_accuracy: 0.2729\n",
      "Epoch 89/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2879 - accuracy: 0.2926 - val_loss: 2.3542 - val_accuracy: 0.2738\n",
      "Epoch 90/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2869 - accuracy: 0.2919 - val_loss: 2.3559 - val_accuracy: 0.2729\n",
      "Epoch 91/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2834 - accuracy: 0.2924 - val_loss: 2.3516 - val_accuracy: 0.2743\n",
      "Epoch 92/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2850 - accuracy: 0.2928 - val_loss: 2.3521 - val_accuracy: 0.2758\n",
      "Epoch 93/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2836 - accuracy: 0.2930 - val_loss: 2.3533 - val_accuracy: 0.2762\n",
      "Epoch 94/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2833 - accuracy: 0.2937 - val_loss: 2.3510 - val_accuracy: 0.2746\n",
      "Epoch 95/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2827 - accuracy: 0.2930 - val_loss: 2.3543 - val_accuracy: 0.2744\n",
      "Epoch 96/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2815 - accuracy: 0.2930 - val_loss: 2.3538 - val_accuracy: 0.2739\n",
      "Epoch 97/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2826 - accuracy: 0.2925 - val_loss: 2.3509 - val_accuracy: 0.2748\n",
      "Epoch 98/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2800 - accuracy: 0.2938 - val_loss: 2.3496 - val_accuracy: 0.2770\n",
      "Epoch 99/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2788 - accuracy: 0.2942 - val_loss: 2.3515 - val_accuracy: 0.2761\n",
      "Epoch 100/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2781 - accuracy: 0.2940 - val_loss: 2.3509 - val_accuracy: 0.2761\n",
      "Epoch 101/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2784 - accuracy: 0.2950 - val_loss: 2.3509 - val_accuracy: 0.2751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2776 - accuracy: 0.2959 - val_loss: 2.3504 - val_accuracy: 0.2769\n",
      "Epoch 103/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2764 - accuracy: 0.2949 - val_loss: 2.3497 - val_accuracy: 0.2760\n",
      "Epoch 104/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2772 - accuracy: 0.2950 - val_loss: 2.3514 - val_accuracy: 0.2751\n",
      "Epoch 105/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2756 - accuracy: 0.2949 - val_loss: 2.3503 - val_accuracy: 0.2768\n",
      "Epoch 106/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2744 - accuracy: 0.2952 - val_loss: 2.3532 - val_accuracy: 0.2746\n",
      "Epoch 107/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2742 - accuracy: 0.2944 - val_loss: 2.3484 - val_accuracy: 0.2773\n",
      "Epoch 108/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2740 - accuracy: 0.2964 - val_loss: 2.3488 - val_accuracy: 0.2767\n",
      "Epoch 109/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2734 - accuracy: 0.2957 - val_loss: 2.3529 - val_accuracy: 0.2746\n",
      "Epoch 110/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2719 - accuracy: 0.2967 - val_loss: 2.3488 - val_accuracy: 0.2767\n",
      "Epoch 111/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2728 - accuracy: 0.2961 - val_loss: 2.3512 - val_accuracy: 0.2763\n",
      "Epoch 112/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2713 - accuracy: 0.2965 - val_loss: 2.3510 - val_accuracy: 0.2771\n",
      "Epoch 113/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2695 - accuracy: 0.2978 - val_loss: 2.3489 - val_accuracy: 0.2764\n",
      "Epoch 114/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2704 - accuracy: 0.2966 - val_loss: 2.3519 - val_accuracy: 0.2752\n",
      "Epoch 115/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2709 - accuracy: 0.2972 - val_loss: 2.3512 - val_accuracy: 0.2771\n",
      "Epoch 116/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2707 - accuracy: 0.2976 - val_loss: 2.3508 - val_accuracy: 0.2766\n",
      "Epoch 117/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2691 - accuracy: 0.2972 - val_loss: 2.3481 - val_accuracy: 0.2754\n",
      "Epoch 118/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2667 - accuracy: 0.2987 - val_loss: 2.3496 - val_accuracy: 0.2774\n",
      "Epoch 119/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2670 - accuracy: 0.2983 - val_loss: 2.3488 - val_accuracy: 0.2761\n",
      "Epoch 120/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2674 - accuracy: 0.2979 - val_loss: 2.3515 - val_accuracy: 0.2775\n",
      "Epoch 121/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2675 - accuracy: 0.2964 - val_loss: 2.3506 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2655 - accuracy: 0.2971 - val_loss: 2.3508 - val_accuracy: 0.2760\n",
      "Epoch 123/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2655 - accuracy: 0.2986 - val_loss: 2.3493 - val_accuracy: 0.2759\n",
      "Epoch 124/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2652 - accuracy: 0.2990 - val_loss: 2.3490 - val_accuracy: 0.2759\n",
      "Epoch 125/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2650 - accuracy: 0.2986 - val_loss: 2.3476 - val_accuracy: 0.2774\n",
      "Epoch 126/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2649 - accuracy: 0.2988 - val_loss: 2.3487 - val_accuracy: 0.2772\n",
      "Epoch 127/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2650 - accuracy: 0.2988 - val_loss: 2.3486 - val_accuracy: 0.2777\n",
      "Epoch 128/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2615 - accuracy: 0.2999 - val_loss: 2.3490 - val_accuracy: 0.2782\n",
      "Epoch 129/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2619 - accuracy: 0.2996 - val_loss: 2.3523 - val_accuracy: 0.2764\n",
      "Epoch 130/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2608 - accuracy: 0.3001 - val_loss: 2.3497 - val_accuracy: 0.2775\n",
      "Epoch 131/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2618 - accuracy: 0.2988 - val_loss: 2.3489 - val_accuracy: 0.2759\n",
      "Epoch 132/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2601 - accuracy: 0.2988 - val_loss: 2.3478 - val_accuracy: 0.2772\n",
      "Epoch 133/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2602 - accuracy: 0.3000 - val_loss: 2.3485 - val_accuracy: 0.2775\n",
      "Epoch 134/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2598 - accuracy: 0.2995 - val_loss: 2.3519 - val_accuracy: 0.2753\n",
      "Epoch 135/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2591 - accuracy: 0.3002 - val_loss: 2.3494 - val_accuracy: 0.2762\n",
      "Epoch 136/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2594 - accuracy: 0.2994 - val_loss: 2.3489 - val_accuracy: 0.2780\n",
      "Epoch 137/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2601 - accuracy: 0.3000 - val_loss: 2.3509 - val_accuracy: 0.2775\n",
      "Epoch 138/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2588 - accuracy: 0.3000 - val_loss: 2.3514 - val_accuracy: 0.2761\n",
      "Epoch 139/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2579 - accuracy: 0.3000 - val_loss: 2.3471 - val_accuracy: 0.2764\n",
      "Epoch 140/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2560 - accuracy: 0.2999 - val_loss: 2.3464 - val_accuracy: 0.2785\n",
      "Epoch 141/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2559 - accuracy: 0.3002 - val_loss: 2.3465 - val_accuracy: 0.2781\n",
      "Epoch 142/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2565 - accuracy: 0.3011 - val_loss: 2.3505 - val_accuracy: 0.2759\n",
      "Epoch 143/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2544 - accuracy: 0.3017 - val_loss: 2.3476 - val_accuracy: 0.2768\n",
      "Epoch 144/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2567 - accuracy: 0.3001 - val_loss: 2.3510 - val_accuracy: 0.2772\n",
      "Epoch 145/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2531 - accuracy: 0.3018 - val_loss: 2.3500 - val_accuracy: 0.2772\n",
      "Epoch 146/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2545 - accuracy: 0.3007 - val_loss: 2.3489 - val_accuracy: 0.2765\n",
      "Epoch 147/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2541 - accuracy: 0.3007 - val_loss: 2.3497 - val_accuracy: 0.2769\n",
      "Epoch 148/150\n",
      "114904/114904 [==============================] - 0s 2us/sample - loss: 2.2538 - accuracy: 0.3005 - val_loss: 2.3493 - val_accuracy: 0.2786\n",
      "Epoch 149/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2540 - accuracy: 0.3000 - val_loss: 2.3489 - val_accuracy: 0.2782\n",
      "Epoch 150/150\n",
      "114904/114904 [==============================] - 0s 3us/sample - loss: 2.2528 - accuracy: 0.3004 - val_loss: 2.3503 - val_accuracy: 0.2769\n",
      "Restoring the best weights from epoch 150\n",
      "Training fold 2\n",
      "Train on 114911 samples, validate on 28733 samples\n",
      "Epoch 1/150\n",
      "114911/114911 [==============================] - 1s 5us/sample - loss: 3.0206 - accuracy: 0.1168 - val_loss: 2.8082 - val_accuracy: 0.1633\n",
      "Epoch 2/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.7437 - accuracy: 0.1726 - val_loss: 2.6539 - val_accuracy: 0.1973\n",
      "Epoch 3/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.6395 - accuracy: 0.1964 - val_loss: 2.5799 - val_accuracy: 0.2158\n",
      "Epoch 4/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.5848 - accuracy: 0.2102 - val_loss: 2.5430 - val_accuracy: 0.2242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.5505 - accuracy: 0.2191 - val_loss: 2.5145 - val_accuracy: 0.2307\n",
      "Epoch 6/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.5263 - accuracy: 0.2258 - val_loss: 2.4989 - val_accuracy: 0.2344\n",
      "Epoch 7/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.5059 - accuracy: 0.2316 - val_loss: 2.4796 - val_accuracy: 0.2409\n",
      "Epoch 8/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.4923 - accuracy: 0.2354 - val_loss: 2.4702 - val_accuracy: 0.2438\n",
      "Epoch 9/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.4814 - accuracy: 0.2386 - val_loss: 2.4633 - val_accuracy: 0.2467\n",
      "Epoch 10/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4690 - accuracy: 0.2422 - val_loss: 2.4520 - val_accuracy: 0.2491\n",
      "Epoch 11/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4615 - accuracy: 0.2436 - val_loss: 2.4444 - val_accuracy: 0.2521\n",
      "Epoch 12/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4544 - accuracy: 0.2446 - val_loss: 2.4387 - val_accuracy: 0.2529\n",
      "Epoch 13/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4447 - accuracy: 0.2480 - val_loss: 2.4318 - val_accuracy: 0.2550\n",
      "Epoch 14/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4389 - accuracy: 0.2501 - val_loss: 2.4236 - val_accuracy: 0.2555\n",
      "Epoch 15/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4316 - accuracy: 0.2510 - val_loss: 2.4199 - val_accuracy: 0.2568\n",
      "Epoch 16/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4284 - accuracy: 0.2523 - val_loss: 2.4165 - val_accuracy: 0.2582\n",
      "Epoch 17/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4229 - accuracy: 0.2533 - val_loss: 2.4101 - val_accuracy: 0.2605\n",
      "Epoch 18/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4174 - accuracy: 0.2551 - val_loss: 2.4122 - val_accuracy: 0.2586\n",
      "Epoch 19/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4144 - accuracy: 0.2555 - val_loss: 2.4039 - val_accuracy: 0.2610\n",
      "Epoch 20/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4077 - accuracy: 0.2572 - val_loss: 2.4001 - val_accuracy: 0.2623\n",
      "Epoch 21/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.4046 - accuracy: 0.2582 - val_loss: 2.3966 - val_accuracy: 0.2644\n",
      "Epoch 22/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3999 - accuracy: 0.2591 - val_loss: 2.3952 - val_accuracy: 0.2641\n",
      "Epoch 23/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3968 - accuracy: 0.2611 - val_loss: 2.3954 - val_accuracy: 0.2637\n",
      "Epoch 24/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3933 - accuracy: 0.2618 - val_loss: 2.3904 - val_accuracy: 0.2658\n",
      "Epoch 25/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3903 - accuracy: 0.2625 - val_loss: 2.3869 - val_accuracy: 0.2666\n",
      "Epoch 26/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3863 - accuracy: 0.2636 - val_loss: 2.3843 - val_accuracy: 0.2684\n",
      "Epoch 27/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3833 - accuracy: 0.2646 - val_loss: 2.3813 - val_accuracy: 0.2673\n",
      "Epoch 28/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3806 - accuracy: 0.2648 - val_loss: 2.3817 - val_accuracy: 0.2678\n",
      "Epoch 29/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3780 - accuracy: 0.2668 - val_loss: 2.3797 - val_accuracy: 0.2670\n",
      "Epoch 30/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3747 - accuracy: 0.2660 - val_loss: 2.3752 - val_accuracy: 0.2688\n",
      "Epoch 31/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3707 - accuracy: 0.2681 - val_loss: 2.3767 - val_accuracy: 0.2699\n",
      "Epoch 32/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3693 - accuracy: 0.2685 - val_loss: 2.3734 - val_accuracy: 0.2705\n",
      "Epoch 33/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3676 - accuracy: 0.2695 - val_loss: 2.3739 - val_accuracy: 0.2717\n",
      "Epoch 34/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3645 - accuracy: 0.2702 - val_loss: 2.3738 - val_accuracy: 0.2711\n",
      "Epoch 35/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3617 - accuracy: 0.2708 - val_loss: 2.3691 - val_accuracy: 0.2708\n",
      "Epoch 36/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3581 - accuracy: 0.2703 - val_loss: 2.3680 - val_accuracy: 0.2693\n",
      "Epoch 37/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3582 - accuracy: 0.2719 - val_loss: 2.3693 - val_accuracy: 0.2728\n",
      "Epoch 38/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3556 - accuracy: 0.2713 - val_loss: 2.3683 - val_accuracy: 0.2719\n",
      "Epoch 39/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3550 - accuracy: 0.2727 - val_loss: 2.3669 - val_accuracy: 0.2709\n",
      "Epoch 40/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3529 - accuracy: 0.2734 - val_loss: 2.3658 - val_accuracy: 0.2709\n",
      "Epoch 41/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3507 - accuracy: 0.2723 - val_loss: 2.3653 - val_accuracy: 0.2727\n",
      "Epoch 42/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3479 - accuracy: 0.2748 - val_loss: 2.3662 - val_accuracy: 0.2717\n",
      "Epoch 43/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3461 - accuracy: 0.2747 - val_loss: 2.3649 - val_accuracy: 0.2720\n",
      "Epoch 44/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3436 - accuracy: 0.2764 - val_loss: 2.3611 - val_accuracy: 0.2725\n",
      "Epoch 45/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3411 - accuracy: 0.2754 - val_loss: 2.3613 - val_accuracy: 0.2715\n",
      "Epoch 46/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3399 - accuracy: 0.2759 - val_loss: 2.3610 - val_accuracy: 0.2724\n",
      "Epoch 47/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3381 - accuracy: 0.2763 - val_loss: 2.3614 - val_accuracy: 0.2724\n",
      "Epoch 48/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3371 - accuracy: 0.2774 - val_loss: 2.3617 - val_accuracy: 0.2734\n",
      "Epoch 49/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3350 - accuracy: 0.2771 - val_loss: 2.3581 - val_accuracy: 0.2737\n",
      "Epoch 50/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3338 - accuracy: 0.2791 - val_loss: 2.3592 - val_accuracy: 0.2729\n",
      "Epoch 51/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3318 - accuracy: 0.2780 - val_loss: 2.3553 - val_accuracy: 0.2742\n",
      "Epoch 52/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3307 - accuracy: 0.2781 - val_loss: 2.3566 - val_accuracy: 0.2732\n",
      "Epoch 53/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3277 - accuracy: 0.2795 - val_loss: 2.3583 - val_accuracy: 0.2722\n",
      "Epoch 54/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3300 - accuracy: 0.2796 - val_loss: 2.3550 - val_accuracy: 0.2754\n",
      "Epoch 55/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3246 - accuracy: 0.2805 - val_loss: 2.3601 - val_accuracy: 0.2747\n",
      "Epoch 56/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3273 - accuracy: 0.2796 - val_loss: 2.3572 - val_accuracy: 0.2736\n",
      "Epoch 57/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3252 - accuracy: 0.2799 - val_loss: 2.3533 - val_accuracy: 0.2755\n",
      "Epoch 58/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3228 - accuracy: 0.2808 - val_loss: 2.3556 - val_accuracy: 0.2739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3211 - accuracy: 0.2809 - val_loss: 2.3528 - val_accuracy: 0.2751\n",
      "Epoch 60/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3200 - accuracy: 0.2816 - val_loss: 2.3537 - val_accuracy: 0.2766\n",
      "Epoch 61/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3190 - accuracy: 0.2829 - val_loss: 2.3532 - val_accuracy: 0.2743\n",
      "Epoch 62/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3180 - accuracy: 0.2828 - val_loss: 2.3520 - val_accuracy: 0.2759\n",
      "Epoch 63/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3173 - accuracy: 0.2825 - val_loss: 2.3531 - val_accuracy: 0.2737\n",
      "Epoch 64/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3148 - accuracy: 0.2850 - val_loss: 2.3509 - val_accuracy: 0.2757\n",
      "Epoch 65/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3144 - accuracy: 0.2839 - val_loss: 2.3499 - val_accuracy: 0.2759\n",
      "Epoch 66/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3122 - accuracy: 0.2840 - val_loss: 2.3513 - val_accuracy: 0.2751\n",
      "Epoch 67/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3100 - accuracy: 0.2846 - val_loss: 2.3509 - val_accuracy: 0.2760\n",
      "Epoch 68/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3107 - accuracy: 0.2846 - val_loss: 2.3515 - val_accuracy: 0.2776\n",
      "Epoch 69/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3095 - accuracy: 0.2853 - val_loss: 2.3482 - val_accuracy: 0.2767\n",
      "Epoch 70/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3098 - accuracy: 0.2843 - val_loss: 2.3480 - val_accuracy: 0.2744\n",
      "Epoch 71/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3079 - accuracy: 0.2858 - val_loss: 2.3497 - val_accuracy: 0.2767\n",
      "Epoch 72/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3063 - accuracy: 0.2868 - val_loss: 2.3479 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.3048 - accuracy: 0.2860 - val_loss: 2.3498 - val_accuracy: 0.2758\n",
      "Epoch 74/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3042 - accuracy: 0.2869 - val_loss: 2.3469 - val_accuracy: 0.2780\n",
      "Epoch 75/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3024 - accuracy: 0.2864 - val_loss: 2.3451 - val_accuracy: 0.2769\n",
      "Epoch 76/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3010 - accuracy: 0.2865 - val_loss: 2.3441 - val_accuracy: 0.2771\n",
      "Epoch 77/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3010 - accuracy: 0.2877 - val_loss: 2.3448 - val_accuracy: 0.2772\n",
      "Epoch 78/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3010 - accuracy: 0.2866 - val_loss: 2.3462 - val_accuracy: 0.2776\n",
      "Epoch 79/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.3014 - accuracy: 0.2871 - val_loss: 2.3432 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2981 - accuracy: 0.2873 - val_loss: 2.3446 - val_accuracy: 0.2801\n",
      "Epoch 81/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2971 - accuracy: 0.2885 - val_loss: 2.3431 - val_accuracy: 0.2783\n",
      "Epoch 82/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2973 - accuracy: 0.2881 - val_loss: 2.3436 - val_accuracy: 0.2790\n",
      "Epoch 83/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2960 - accuracy: 0.2883 - val_loss: 2.3466 - val_accuracy: 0.2775\n",
      "Epoch 84/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2950 - accuracy: 0.2891 - val_loss: 2.3441 - val_accuracy: 0.2792\n",
      "Epoch 85/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2939 - accuracy: 0.2892 - val_loss: 2.3431 - val_accuracy: 0.2799\n",
      "Epoch 86/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2928 - accuracy: 0.2891 - val_loss: 2.3447 - val_accuracy: 0.2768\n",
      "Epoch 87/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2904 - accuracy: 0.2888 - val_loss: 2.3426 - val_accuracy: 0.2792\n",
      "Epoch 88/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2918 - accuracy: 0.2890 - val_loss: 2.3427 - val_accuracy: 0.2804\n",
      "Epoch 89/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2895 - accuracy: 0.2903 - val_loss: 2.3413 - val_accuracy: 0.2785\n",
      "Epoch 90/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2897 - accuracy: 0.2899 - val_loss: 2.3402 - val_accuracy: 0.2800\n",
      "Epoch 91/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2895 - accuracy: 0.2893 - val_loss: 2.3448 - val_accuracy: 0.2795\n",
      "Epoch 92/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2900 - accuracy: 0.2901 - val_loss: 2.3421 - val_accuracy: 0.2789\n",
      "Epoch 93/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2876 - accuracy: 0.2901 - val_loss: 2.3401 - val_accuracy: 0.2793\n",
      "Epoch 94/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2868 - accuracy: 0.2912 - val_loss: 2.3406 - val_accuracy: 0.2782\n",
      "Epoch 95/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2852 - accuracy: 0.2907 - val_loss: 2.3401 - val_accuracy: 0.2790\n",
      "Epoch 96/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2878 - accuracy: 0.2911 - val_loss: 2.3409 - val_accuracy: 0.2784\n",
      "Epoch 97/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2859 - accuracy: 0.2906 - val_loss: 2.3407 - val_accuracy: 0.2803\n",
      "Epoch 98/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2854 - accuracy: 0.2908 - val_loss: 2.3414 - val_accuracy: 0.2785\n",
      "Epoch 99/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2843 - accuracy: 0.2917 - val_loss: 2.3411 - val_accuracy: 0.2791\n",
      "Epoch 100/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2835 - accuracy: 0.2919 - val_loss: 2.3413 - val_accuracy: 0.2786\n",
      "Epoch 101/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2834 - accuracy: 0.2921 - val_loss: 2.3389 - val_accuracy: 0.2818\n",
      "Epoch 102/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2820 - accuracy: 0.2916 - val_loss: 2.3380 - val_accuracy: 0.2803\n",
      "Epoch 103/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2806 - accuracy: 0.2917 - val_loss: 2.3391 - val_accuracy: 0.2799\n",
      "Epoch 104/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2806 - accuracy: 0.2927 - val_loss: 2.3424 - val_accuracy: 0.2787\n",
      "Epoch 105/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2805 - accuracy: 0.2916 - val_loss: 2.3391 - val_accuracy: 0.2800\n",
      "Epoch 106/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2779 - accuracy: 0.2925 - val_loss: 2.3391 - val_accuracy: 0.2797\n",
      "Epoch 107/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2770 - accuracy: 0.2949 - val_loss: 2.3378 - val_accuracy: 0.2813\n",
      "Epoch 108/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2774 - accuracy: 0.2945 - val_loss: 2.3385 - val_accuracy: 0.2820\n",
      "Epoch 109/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2782 - accuracy: 0.2935 - val_loss: 2.3366 - val_accuracy: 0.2819\n",
      "Epoch 110/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2782 - accuracy: 0.2933 - val_loss: 2.3374 - val_accuracy: 0.2825\n",
      "Epoch 111/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2748 - accuracy: 0.2941 - val_loss: 2.3380 - val_accuracy: 0.2805\n",
      "Epoch 112/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2755 - accuracy: 0.2938 - val_loss: 2.3376 - val_accuracy: 0.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2761 - accuracy: 0.2936 - val_loss: 2.3351 - val_accuracy: 0.2831\n",
      "Epoch 114/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2745 - accuracy: 0.2955 - val_loss: 2.3378 - val_accuracy: 0.2812\n",
      "Epoch 115/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2730 - accuracy: 0.2939 - val_loss: 2.3380 - val_accuracy: 0.2810\n",
      "Epoch 116/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2729 - accuracy: 0.2942 - val_loss: 2.3362 - val_accuracy: 0.2808\n",
      "Epoch 117/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2705 - accuracy: 0.2961 - val_loss: 2.3384 - val_accuracy: 0.2801\n",
      "Epoch 118/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2726 - accuracy: 0.2949 - val_loss: 2.3366 - val_accuracy: 0.2798\n",
      "Epoch 119/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2721 - accuracy: 0.2959 - val_loss: 2.3379 - val_accuracy: 0.2797\n",
      "Epoch 120/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2707 - accuracy: 0.2962 - val_loss: 2.3384 - val_accuracy: 0.2824\n",
      "Epoch 121/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2689 - accuracy: 0.2954 - val_loss: 2.3411 - val_accuracy: 0.2793\n",
      "Epoch 122/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2710 - accuracy: 0.2963 - val_loss: 2.3385 - val_accuracy: 0.2806\n",
      "Epoch 123/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2692 - accuracy: 0.2952 - val_loss: 2.3370 - val_accuracy: 0.2810\n",
      "Epoch 124/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2681 - accuracy: 0.2965 - val_loss: 2.3391 - val_accuracy: 0.2805\n",
      "Epoch 125/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2668 - accuracy: 0.2962 - val_loss: 2.3391 - val_accuracy: 0.2814\n",
      "Epoch 126/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2685 - accuracy: 0.2958 - val_loss: 2.3381 - val_accuracy: 0.2812\n",
      "Epoch 127/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2660 - accuracy: 0.2970 - val_loss: 2.3370 - val_accuracy: 0.2838\n",
      "Epoch 128/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2659 - accuracy: 0.2968 - val_loss: 2.3368 - val_accuracy: 0.2833\n",
      "Epoch 129/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2659 - accuracy: 0.2975 - val_loss: 2.3389 - val_accuracy: 0.2810\n",
      "Epoch 130/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2661 - accuracy: 0.2970 - val_loss: 2.3359 - val_accuracy: 0.2822\n",
      "Epoch 131/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2647 - accuracy: 0.2972 - val_loss: 2.3357 - val_accuracy: 0.2813\n",
      "Epoch 132/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2647 - accuracy: 0.2993 - val_loss: 2.3376 - val_accuracy: 0.2824\n",
      "Epoch 133/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2644 - accuracy: 0.2967 - val_loss: 2.3346 - val_accuracy: 0.2817\n",
      "Epoch 134/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2634 - accuracy: 0.2976 - val_loss: 2.3362 - val_accuracy: 0.2836\n",
      "Epoch 135/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2659 - accuracy: 0.2965 - val_loss: 2.3374 - val_accuracy: 0.2823\n",
      "Epoch 136/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2628 - accuracy: 0.2984 - val_loss: 2.3355 - val_accuracy: 0.2818\n",
      "Epoch 137/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2608 - accuracy: 0.2977 - val_loss: 2.3378 - val_accuracy: 0.2809\n",
      "Epoch 138/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2637 - accuracy: 0.2972 - val_loss: 2.3371 - val_accuracy: 0.2835\n",
      "Epoch 139/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2612 - accuracy: 0.2993 - val_loss: 2.3356 - val_accuracy: 0.2819\n",
      "Epoch 140/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2605 - accuracy: 0.2977 - val_loss: 2.3377 - val_accuracy: 0.2813\n",
      "Epoch 141/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2595 - accuracy: 0.2989 - val_loss: 2.3367 - val_accuracy: 0.2831\n",
      "Epoch 142/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2611 - accuracy: 0.2968 - val_loss: 2.3388 - val_accuracy: 0.2818\n",
      "Epoch 143/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2587 - accuracy: 0.2988 - val_loss: 2.3380 - val_accuracy: 0.2816\n",
      "Epoch 144/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2604 - accuracy: 0.2986 - val_loss: 2.3355 - val_accuracy: 0.2838\n",
      "Epoch 145/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2582 - accuracy: 0.2998 - val_loss: 2.3394 - val_accuracy: 0.2831\n",
      "Epoch 146/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2576 - accuracy: 0.3005 - val_loss: 2.3347 - val_accuracy: 0.2824\n",
      "Epoch 147/150\n",
      "114911/114911 [==============================] - 0s 2us/sample - loss: 2.2577 - accuracy: 0.2993 - val_loss: 2.3385 - val_accuracy: 0.2809\n",
      "Epoch 148/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2573 - accuracy: 0.2999 - val_loss: 2.3377 - val_accuracy: 0.2823\n",
      "Epoch 149/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2593 - accuracy: 0.2991 - val_loss: 2.3396 - val_accuracy: 0.2839\n",
      "Epoch 150/150\n",
      "114911/114911 [==============================] - 0s 3us/sample - loss: 2.2582 - accuracy: 0.3001 - val_loss: 2.3378 - val_accuracy: 0.2827\n",
      "Restoring the best weights from epoch 150\n",
      "Training fold 3\n",
      "Train on 114914 samples, validate on 28730 samples\n",
      "Epoch 1/150\n",
      "114914/114914 [==============================] - 1s 5us/sample - loss: 3.0338 - accuracy: 0.1080 - val_loss: 2.8184 - val_accuracy: 0.1624\n",
      "Epoch 2/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.7379 - accuracy: 0.1733 - val_loss: 2.6648 - val_accuracy: 0.1927\n",
      "Epoch 3/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.6311 - accuracy: 0.1995 - val_loss: 2.5875 - val_accuracy: 0.2179\n",
      "Epoch 4/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.5695 - accuracy: 0.2151 - val_loss: 2.5488 - val_accuracy: 0.2248\n",
      "Epoch 5/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.5349 - accuracy: 0.2236 - val_loss: 2.5186 - val_accuracy: 0.2336\n",
      "Epoch 6/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.5134 - accuracy: 0.2298 - val_loss: 2.5031 - val_accuracy: 0.2326\n",
      "Epoch 7/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4950 - accuracy: 0.2339 - val_loss: 2.4871 - val_accuracy: 0.2379\n",
      "Epoch 8/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4788 - accuracy: 0.2392 - val_loss: 2.4764 - val_accuracy: 0.2414\n",
      "Epoch 9/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4676 - accuracy: 0.2416 - val_loss: 2.4662 - val_accuracy: 0.2428\n",
      "Epoch 10/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4570 - accuracy: 0.2443 - val_loss: 2.4585 - val_accuracy: 0.2462\n",
      "Epoch 11/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4505 - accuracy: 0.2455 - val_loss: 2.4526 - val_accuracy: 0.2488\n",
      "Epoch 12/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4422 - accuracy: 0.2480 - val_loss: 2.4489 - val_accuracy: 0.2487\n",
      "Epoch 13/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4339 - accuracy: 0.2505 - val_loss: 2.4402 - val_accuracy: 0.2509\n",
      "Epoch 14/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4300 - accuracy: 0.2508 - val_loss: 2.4350 - val_accuracy: 0.2525\n",
      "Epoch 15/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4219 - accuracy: 0.2544 - val_loss: 2.4308 - val_accuracy: 0.2552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4169 - accuracy: 0.2554 - val_loss: 2.4299 - val_accuracy: 0.2559\n",
      "Epoch 17/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4136 - accuracy: 0.2564 - val_loss: 2.4252 - val_accuracy: 0.2551\n",
      "Epoch 18/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4075 - accuracy: 0.2587 - val_loss: 2.4221 - val_accuracy: 0.2562\n",
      "Epoch 19/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.4043 - accuracy: 0.2596 - val_loss: 2.4186 - val_accuracy: 0.2578\n",
      "Epoch 20/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3996 - accuracy: 0.2608 - val_loss: 2.4167 - val_accuracy: 0.2580\n",
      "Epoch 21/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3959 - accuracy: 0.2613 - val_loss: 2.4134 - val_accuracy: 0.2598\n",
      "Epoch 22/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3934 - accuracy: 0.2635 - val_loss: 2.4096 - val_accuracy: 0.2608\n",
      "Epoch 23/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3877 - accuracy: 0.2636 - val_loss: 2.4088 - val_accuracy: 0.2602\n",
      "Epoch 24/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3851 - accuracy: 0.2641 - val_loss: 2.4088 - val_accuracy: 0.2600\n",
      "Epoch 25/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3818 - accuracy: 0.2660 - val_loss: 2.4049 - val_accuracy: 0.2620\n",
      "Epoch 26/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3800 - accuracy: 0.2660 - val_loss: 2.4060 - val_accuracy: 0.2621\n",
      "Epoch 27/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3773 - accuracy: 0.2665 - val_loss: 2.4006 - val_accuracy: 0.2640\n",
      "Epoch 28/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3729 - accuracy: 0.2678 - val_loss: 2.3981 - val_accuracy: 0.2638\n",
      "Epoch 29/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3722 - accuracy: 0.2689 - val_loss: 2.3977 - val_accuracy: 0.2668\n",
      "Epoch 30/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3680 - accuracy: 0.2694 - val_loss: 2.3949 - val_accuracy: 0.2658\n",
      "Epoch 31/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3654 - accuracy: 0.2713 - val_loss: 2.3956 - val_accuracy: 0.2643\n",
      "Epoch 32/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3627 - accuracy: 0.2704 - val_loss: 2.3928 - val_accuracy: 0.2653\n",
      "Epoch 33/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3591 - accuracy: 0.2710 - val_loss: 2.3907 - val_accuracy: 0.2647\n",
      "Epoch 34/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3585 - accuracy: 0.2723 - val_loss: 2.3923 - val_accuracy: 0.2678\n",
      "Epoch 35/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3560 - accuracy: 0.2726 - val_loss: 2.3884 - val_accuracy: 0.2684\n",
      "Epoch 36/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3542 - accuracy: 0.2742 - val_loss: 2.3862 - val_accuracy: 0.2684\n",
      "Epoch 37/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3516 - accuracy: 0.2749 - val_loss: 2.3864 - val_accuracy: 0.2686\n",
      "Epoch 38/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3497 - accuracy: 0.2745 - val_loss: 2.3834 - val_accuracy: 0.2680\n",
      "Epoch 39/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3485 - accuracy: 0.2754 - val_loss: 2.3807 - val_accuracy: 0.2691\n",
      "Epoch 40/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3477 - accuracy: 0.2762 - val_loss: 2.3801 - val_accuracy: 0.2704\n",
      "Epoch 41/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3440 - accuracy: 0.2771 - val_loss: 2.3815 - val_accuracy: 0.2699\n",
      "Epoch 42/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3425 - accuracy: 0.2777 - val_loss: 2.3820 - val_accuracy: 0.2692\n",
      "Epoch 43/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3398 - accuracy: 0.2775 - val_loss: 2.3782 - val_accuracy: 0.2712\n",
      "Epoch 44/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3391 - accuracy: 0.2789 - val_loss: 2.3792 - val_accuracy: 0.2699\n",
      "Epoch 45/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3363 - accuracy: 0.2793 - val_loss: 2.3759 - val_accuracy: 0.2714\n",
      "Epoch 46/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3358 - accuracy: 0.2780 - val_loss: 2.3750 - val_accuracy: 0.2717\n",
      "Epoch 47/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3351 - accuracy: 0.2802 - val_loss: 2.3738 - val_accuracy: 0.2715\n",
      "Epoch 48/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3310 - accuracy: 0.2807 - val_loss: 2.3740 - val_accuracy: 0.2700\n",
      "Epoch 49/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3304 - accuracy: 0.2801 - val_loss: 2.3728 - val_accuracy: 0.2728\n",
      "Epoch 50/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3260 - accuracy: 0.2820 - val_loss: 2.3719 - val_accuracy: 0.2712\n",
      "Epoch 51/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3265 - accuracy: 0.2822 - val_loss: 2.3699 - val_accuracy: 0.2731\n",
      "Epoch 52/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3251 - accuracy: 0.2821 - val_loss: 2.3702 - val_accuracy: 0.2730\n",
      "Epoch 53/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3231 - accuracy: 0.2829 - val_loss: 2.3661 - val_accuracy: 0.2751\n",
      "Epoch 54/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3230 - accuracy: 0.2843 - val_loss: 2.3711 - val_accuracy: 0.2735\n",
      "Epoch 55/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3209 - accuracy: 0.2819 - val_loss: 2.3687 - val_accuracy: 0.2746\n",
      "Epoch 56/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3210 - accuracy: 0.2834 - val_loss: 2.3678 - val_accuracy: 0.2739\n",
      "Epoch 57/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3187 - accuracy: 0.2842 - val_loss: 2.3658 - val_accuracy: 0.2739\n",
      "Epoch 58/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3178 - accuracy: 0.2842 - val_loss: 2.3651 - val_accuracy: 0.2743\n",
      "Epoch 59/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3167 - accuracy: 0.2834 - val_loss: 2.3670 - val_accuracy: 0.2745\n",
      "Epoch 60/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3159 - accuracy: 0.2846 - val_loss: 2.3666 - val_accuracy: 0.2762\n",
      "Epoch 61/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3141 - accuracy: 0.2863 - val_loss: 2.3636 - val_accuracy: 0.2771\n",
      "Epoch 62/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3129 - accuracy: 0.2852 - val_loss: 2.3642 - val_accuracy: 0.2749\n",
      "Epoch 63/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3121 - accuracy: 0.2849 - val_loss: 2.3667 - val_accuracy: 0.2750\n",
      "Epoch 64/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3110 - accuracy: 0.2863 - val_loss: 2.3632 - val_accuracy: 0.2757\n",
      "Epoch 65/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3093 - accuracy: 0.2875 - val_loss: 2.3645 - val_accuracy: 0.2767\n",
      "Epoch 66/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3084 - accuracy: 0.2870 - val_loss: 2.3623 - val_accuracy: 0.2761\n",
      "Epoch 67/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3076 - accuracy: 0.2885 - val_loss: 2.3605 - val_accuracy: 0.2766\n",
      "Epoch 68/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3072 - accuracy: 0.2875 - val_loss: 2.3624 - val_accuracy: 0.2754\n",
      "Epoch 69/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3041 - accuracy: 0.2871 - val_loss: 2.3624 - val_accuracy: 0.2748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3065 - accuracy: 0.2868 - val_loss: 2.3604 - val_accuracy: 0.2777\n",
      "Epoch 71/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3027 - accuracy: 0.2895 - val_loss: 2.3581 - val_accuracy: 0.2775\n",
      "Epoch 72/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3024 - accuracy: 0.2881 - val_loss: 2.3612 - val_accuracy: 0.2784\n",
      "Epoch 73/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3031 - accuracy: 0.2896 - val_loss: 2.3577 - val_accuracy: 0.2756\n",
      "Epoch 74/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.3002 - accuracy: 0.2891 - val_loss: 2.3581 - val_accuracy: 0.2771\n",
      "Epoch 75/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.3013 - accuracy: 0.2893 - val_loss: 2.3591 - val_accuracy: 0.2781\n",
      "Epoch 76/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2994 - accuracy: 0.2898 - val_loss: 2.3576 - val_accuracy: 0.2781\n",
      "Epoch 77/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2970 - accuracy: 0.2892 - val_loss: 2.3557 - val_accuracy: 0.2785\n",
      "Epoch 78/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2976 - accuracy: 0.2900 - val_loss: 2.3589 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2976 - accuracy: 0.2896 - val_loss: 2.3588 - val_accuracy: 0.2762\n",
      "Epoch 80/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2942 - accuracy: 0.2910 - val_loss: 2.3552 - val_accuracy: 0.2795\n",
      "Epoch 81/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2940 - accuracy: 0.2914 - val_loss: 2.3569 - val_accuracy: 0.2762\n",
      "Epoch 82/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2952 - accuracy: 0.2906 - val_loss: 2.3553 - val_accuracy: 0.2772\n",
      "Epoch 83/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2926 - accuracy: 0.2923 - val_loss: 2.3557 - val_accuracy: 0.2758\n",
      "Epoch 84/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2917 - accuracy: 0.2910 - val_loss: 2.3553 - val_accuracy: 0.2771\n",
      "Epoch 85/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2915 - accuracy: 0.2917 - val_loss: 2.3596 - val_accuracy: 0.2763\n",
      "Epoch 86/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2909 - accuracy: 0.2921 - val_loss: 2.3551 - val_accuracy: 0.2771\n",
      "Epoch 87/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2911 - accuracy: 0.2910 - val_loss: 2.3543 - val_accuracy: 0.2780\n",
      "Epoch 88/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2888 - accuracy: 0.2921 - val_loss: 2.3547 - val_accuracy: 0.2773\n",
      "Epoch 89/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2877 - accuracy: 0.2931 - val_loss: 2.3564 - val_accuracy: 0.2769\n",
      "Epoch 90/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2870 - accuracy: 0.2922 - val_loss: 2.3517 - val_accuracy: 0.2790\n",
      "Epoch 91/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2869 - accuracy: 0.2922 - val_loss: 2.3535 - val_accuracy: 0.2781\n",
      "Epoch 92/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2873 - accuracy: 0.2933 - val_loss: 2.3542 - val_accuracy: 0.2794\n",
      "Epoch 93/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2856 - accuracy: 0.2915 - val_loss: 2.3536 - val_accuracy: 0.2786\n",
      "Epoch 94/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2870 - accuracy: 0.2935 - val_loss: 2.3511 - val_accuracy: 0.2788\n",
      "Epoch 95/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2830 - accuracy: 0.2938 - val_loss: 2.3528 - val_accuracy: 0.2798\n",
      "Epoch 96/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2846 - accuracy: 0.2924 - val_loss: 2.3531 - val_accuracy: 0.2807\n",
      "Epoch 97/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2826 - accuracy: 0.2945 - val_loss: 2.3551 - val_accuracy: 0.2777\n",
      "Epoch 98/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2839 - accuracy: 0.2930 - val_loss: 2.3549 - val_accuracy: 0.2782\n",
      "Epoch 99/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2814 - accuracy: 0.2933 - val_loss: 2.3513 - val_accuracy: 0.2799\n",
      "Epoch 100/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2804 - accuracy: 0.2947 - val_loss: 2.3523 - val_accuracy: 0.2794\n",
      "Epoch 101/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2790 - accuracy: 0.2965 - val_loss: 2.3549 - val_accuracy: 0.2787\n",
      "Epoch 102/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2799 - accuracy: 0.2943 - val_loss: 2.3512 - val_accuracy: 0.2803\n",
      "Epoch 103/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2802 - accuracy: 0.2933 - val_loss: 2.3530 - val_accuracy: 0.2809\n",
      "Epoch 104/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2808 - accuracy: 0.2940 - val_loss: 2.3501 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2770 - accuracy: 0.2960 - val_loss: 2.3497 - val_accuracy: 0.2792\n",
      "Epoch 106/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2778 - accuracy: 0.2944 - val_loss: 2.3509 - val_accuracy: 0.2791\n",
      "Epoch 107/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2770 - accuracy: 0.2950 - val_loss: 2.3531 - val_accuracy: 0.2790\n",
      "Epoch 108/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2756 - accuracy: 0.2943 - val_loss: 2.3545 - val_accuracy: 0.2779\n",
      "Epoch 109/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2758 - accuracy: 0.2961 - val_loss: 2.3510 - val_accuracy: 0.2804\n",
      "Epoch 110/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2751 - accuracy: 0.2959 - val_loss: 2.3502 - val_accuracy: 0.2796\n",
      "Epoch 111/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2742 - accuracy: 0.2957 - val_loss: 2.3492 - val_accuracy: 0.2803\n",
      "Epoch 112/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2741 - accuracy: 0.2947 - val_loss: 2.3509 - val_accuracy: 0.2810\n",
      "Epoch 113/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2744 - accuracy: 0.2968 - val_loss: 2.3496 - val_accuracy: 0.2803\n",
      "Epoch 114/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2711 - accuracy: 0.2972 - val_loss: 2.3516 - val_accuracy: 0.2808\n",
      "Epoch 115/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2720 - accuracy: 0.2991 - val_loss: 2.3523 - val_accuracy: 0.2786\n",
      "Epoch 116/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2707 - accuracy: 0.2973 - val_loss: 2.3482 - val_accuracy: 0.2818\n",
      "Epoch 117/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2710 - accuracy: 0.2976 - val_loss: 2.3485 - val_accuracy: 0.2825\n",
      "Epoch 118/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2701 - accuracy: 0.2961 - val_loss: 2.3512 - val_accuracy: 0.2796\n",
      "Epoch 119/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2689 - accuracy: 0.2971 - val_loss: 2.3497 - val_accuracy: 0.2807\n",
      "Epoch 120/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2697 - accuracy: 0.2965 - val_loss: 2.3491 - val_accuracy: 0.2824\n",
      "Epoch 121/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2686 - accuracy: 0.2976 - val_loss: 2.3497 - val_accuracy: 0.2798\n",
      "Epoch 122/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2697 - accuracy: 0.2969 - val_loss: 2.3494 - val_accuracy: 0.2799\n",
      "Epoch 123/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2693 - accuracy: 0.2974 - val_loss: 2.3507 - val_accuracy: 0.2805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2680 - accuracy: 0.2974 - val_loss: 2.3491 - val_accuracy: 0.2786\n",
      "Epoch 125/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2672 - accuracy: 0.2984 - val_loss: 2.3526 - val_accuracy: 0.2802\n",
      "Epoch 126/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2655 - accuracy: 0.2978 - val_loss: 2.3485 - val_accuracy: 0.2804\n",
      "Epoch 127/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2658 - accuracy: 0.2987 - val_loss: 2.3497 - val_accuracy: 0.2794\n",
      "Epoch 128/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2672 - accuracy: 0.2997 - val_loss: 2.3479 - val_accuracy: 0.2813\n",
      "Epoch 129/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2643 - accuracy: 0.2985 - val_loss: 2.3544 - val_accuracy: 0.2796\n",
      "Epoch 130/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2667 - accuracy: 0.2976 - val_loss: 2.3483 - val_accuracy: 0.2792\n",
      "Epoch 131/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2639 - accuracy: 0.2995 - val_loss: 2.3525 - val_accuracy: 0.2816\n",
      "Epoch 132/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2653 - accuracy: 0.2981 - val_loss: 2.3513 - val_accuracy: 0.2801\n",
      "Epoch 133/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2615 - accuracy: 0.3004 - val_loss: 2.3516 - val_accuracy: 0.2809\n",
      "Epoch 134/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2629 - accuracy: 0.2994 - val_loss: 2.3489 - val_accuracy: 0.2816\n",
      "Epoch 135/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2629 - accuracy: 0.3000 - val_loss: 2.3490 - val_accuracy: 0.2786\n",
      "Epoch 136/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2601 - accuracy: 0.3002 - val_loss: 2.3492 - val_accuracy: 0.2805\n",
      "Epoch 137/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2619 - accuracy: 0.2995 - val_loss: 2.3498 - val_accuracy: 0.2823\n",
      "Epoch 138/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2614 - accuracy: 0.3005 - val_loss: 2.3484 - val_accuracy: 0.2814\n",
      "Epoch 139/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2599 - accuracy: 0.3006 - val_loss: 2.3491 - val_accuracy: 0.2803\n",
      "Epoch 140/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2590 - accuracy: 0.2997 - val_loss: 2.3487 - val_accuracy: 0.2806\n",
      "Epoch 141/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2593 - accuracy: 0.2993 - val_loss: 2.3482 - val_accuracy: 0.2795\n",
      "Epoch 142/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2607 - accuracy: 0.2989 - val_loss: 2.3503 - val_accuracy: 0.2779\n",
      "Epoch 143/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2575 - accuracy: 0.3002 - val_loss: 2.3476 - val_accuracy: 0.2814\n",
      "Epoch 144/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2550 - accuracy: 0.3021 - val_loss: 2.3498 - val_accuracy: 0.2808\n",
      "Epoch 145/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2576 - accuracy: 0.3009 - val_loss: 2.3502 - val_accuracy: 0.2805\n",
      "Epoch 146/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2565 - accuracy: 0.3023 - val_loss: 2.3508 - val_accuracy: 0.2802\n",
      "Epoch 147/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2561 - accuracy: 0.3006 - val_loss: 2.3482 - val_accuracy: 0.2804\n",
      "Epoch 148/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2552 - accuracy: 0.3008 - val_loss: 2.3469 - val_accuracy: 0.2802\n",
      "Epoch 149/150\n",
      "114914/114914 [==============================] - 0s 3us/sample - loss: 2.2553 - accuracy: 0.3010 - val_loss: 2.3504 - val_accuracy: 0.2798\n",
      "Epoch 150/150\n",
      "114914/114914 [==============================] - 0s 2us/sample - loss: 2.2555 - accuracy: 0.2996 - val_loss: 2.3503 - val_accuracy: 0.2801\n",
      "Restoring the best weights from epoch 150\n",
      "Training fold 4\n",
      "Train on 114922 samples, validate on 28722 samples\n",
      "Epoch 1/150\n",
      "114922/114922 [==============================] - 1s 5us/sample - loss: 3.0495 - accuracy: 0.1062 - val_loss: 2.8454 - val_accuracy: 0.1603\n",
      "Epoch 2/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.7393 - accuracy: 0.1764 - val_loss: 2.6363 - val_accuracy: 0.1979\n",
      "Epoch 3/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.6205 - accuracy: 0.2011 - val_loss: 2.5674 - val_accuracy: 0.2160\n",
      "Epoch 4/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.5683 - accuracy: 0.2154 - val_loss: 2.5321 - val_accuracy: 0.2228\n",
      "Epoch 5/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.5383 - accuracy: 0.2243 - val_loss: 2.5099 - val_accuracy: 0.2311\n",
      "Epoch 6/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.5149 - accuracy: 0.2303 - val_loss: 2.4929 - val_accuracy: 0.2346\n",
      "Epoch 7/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.5006 - accuracy: 0.2346 - val_loss: 2.4827 - val_accuracy: 0.2385\n",
      "Epoch 8/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4881 - accuracy: 0.2370 - val_loss: 2.4709 - val_accuracy: 0.2404\n",
      "Epoch 9/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4759 - accuracy: 0.2422 - val_loss: 2.4643 - val_accuracy: 0.2428\n",
      "Epoch 10/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4677 - accuracy: 0.2424 - val_loss: 2.4562 - val_accuracy: 0.2460\n",
      "Epoch 11/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4576 - accuracy: 0.2457 - val_loss: 2.4476 - val_accuracy: 0.2476\n",
      "Epoch 12/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4496 - accuracy: 0.2475 - val_loss: 2.4406 - val_accuracy: 0.2490\n",
      "Epoch 13/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4442 - accuracy: 0.2487 - val_loss: 2.4393 - val_accuracy: 0.2496\n",
      "Epoch 14/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4368 - accuracy: 0.2506 - val_loss: 2.4310 - val_accuracy: 0.2514\n",
      "Epoch 15/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.4293 - accuracy: 0.2528 - val_loss: 2.4275 - val_accuracy: 0.2541\n",
      "Epoch 16/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.4245 - accuracy: 0.2544 - val_loss: 2.4251 - val_accuracy: 0.2538\n",
      "Epoch 17/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4191 - accuracy: 0.2545 - val_loss: 2.4215 - val_accuracy: 0.2537\n",
      "Epoch 18/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4150 - accuracy: 0.2569 - val_loss: 2.4163 - val_accuracy: 0.2543\n",
      "Epoch 19/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4097 - accuracy: 0.2573 - val_loss: 2.4143 - val_accuracy: 0.2544\n",
      "Epoch 20/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.4063 - accuracy: 0.2582 - val_loss: 2.4114 - val_accuracy: 0.2575\n",
      "Epoch 21/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3998 - accuracy: 0.2608 - val_loss: 2.4071 - val_accuracy: 0.2600\n",
      "Epoch 22/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3969 - accuracy: 0.2608 - val_loss: 2.4047 - val_accuracy: 0.2583\n",
      "Epoch 23/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3920 - accuracy: 0.2625 - val_loss: 2.4019 - val_accuracy: 0.2607\n",
      "Epoch 24/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3893 - accuracy: 0.2641 - val_loss: 2.4017 - val_accuracy: 0.2593\n",
      "Epoch 25/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3855 - accuracy: 0.2636 - val_loss: 2.3980 - val_accuracy: 0.2620\n",
      "Epoch 26/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3828 - accuracy: 0.2652 - val_loss: 2.3981 - val_accuracy: 0.2612\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3805 - accuracy: 0.2657 - val_loss: 2.3984 - val_accuracy: 0.2626\n",
      "Epoch 28/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3778 - accuracy: 0.2663 - val_loss: 2.3934 - val_accuracy: 0.2630\n",
      "Epoch 29/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3749 - accuracy: 0.2665 - val_loss: 2.3936 - val_accuracy: 0.2625\n",
      "Epoch 30/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3715 - accuracy: 0.2679 - val_loss: 2.3874 - val_accuracy: 0.2642\n",
      "Epoch 31/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3692 - accuracy: 0.2691 - val_loss: 2.3893 - val_accuracy: 0.2665\n",
      "Epoch 32/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3658 - accuracy: 0.2689 - val_loss: 2.3875 - val_accuracy: 0.2654\n",
      "Epoch 33/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3653 - accuracy: 0.2700 - val_loss: 2.3838 - val_accuracy: 0.2662\n",
      "Epoch 34/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3620 - accuracy: 0.2701 - val_loss: 2.3850 - val_accuracy: 0.2676\n",
      "Epoch 35/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3601 - accuracy: 0.2726 - val_loss: 2.3817 - val_accuracy: 0.2667\n",
      "Epoch 36/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3578 - accuracy: 0.2714 - val_loss: 2.3830 - val_accuracy: 0.2676\n",
      "Epoch 37/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3551 - accuracy: 0.2742 - val_loss: 2.3810 - val_accuracy: 0.2687\n",
      "Epoch 38/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3540 - accuracy: 0.2742 - val_loss: 2.3801 - val_accuracy: 0.2678\n",
      "Epoch 39/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3502 - accuracy: 0.2741 - val_loss: 2.3784 - val_accuracy: 0.2669\n",
      "Epoch 40/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3488 - accuracy: 0.2757 - val_loss: 2.3769 - val_accuracy: 0.2686\n",
      "Epoch 41/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3486 - accuracy: 0.2754 - val_loss: 2.3749 - val_accuracy: 0.2702\n",
      "Epoch 42/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3446 - accuracy: 0.2751 - val_loss: 2.3753 - val_accuracy: 0.2686\n",
      "Epoch 43/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3453 - accuracy: 0.2766 - val_loss: 2.3749 - val_accuracy: 0.2693\n",
      "Epoch 44/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3430 - accuracy: 0.2761 - val_loss: 2.3736 - val_accuracy: 0.2689\n",
      "Epoch 45/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3404 - accuracy: 0.2767 - val_loss: 2.3722 - val_accuracy: 0.2695\n",
      "Epoch 46/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3390 - accuracy: 0.2778 - val_loss: 2.3738 - val_accuracy: 0.2685\n",
      "Epoch 47/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3370 - accuracy: 0.2774 - val_loss: 2.3699 - val_accuracy: 0.2714\n",
      "Epoch 48/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3353 - accuracy: 0.2778 - val_loss: 2.3709 - val_accuracy: 0.2694\n",
      "Epoch 49/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3331 - accuracy: 0.2779 - val_loss: 2.3702 - val_accuracy: 0.2714\n",
      "Epoch 50/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3313 - accuracy: 0.2799 - val_loss: 2.3710 - val_accuracy: 0.2701\n",
      "Epoch 51/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3322 - accuracy: 0.2789 - val_loss: 2.3719 - val_accuracy: 0.2692\n",
      "Epoch 52/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3287 - accuracy: 0.2794 - val_loss: 2.3708 - val_accuracy: 0.2705\n",
      "Epoch 53/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3270 - accuracy: 0.2803 - val_loss: 2.3694 - val_accuracy: 0.2694\n",
      "Epoch 54/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3261 - accuracy: 0.2820 - val_loss: 2.3677 - val_accuracy: 0.2702\n",
      "Epoch 55/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3242 - accuracy: 0.2812 - val_loss: 2.3672 - val_accuracy: 0.2697\n",
      "Epoch 56/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3235 - accuracy: 0.2821 - val_loss: 2.3668 - val_accuracy: 0.2724\n",
      "Epoch 57/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3211 - accuracy: 0.2829 - val_loss: 2.3647 - val_accuracy: 0.2714\n",
      "Epoch 58/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3208 - accuracy: 0.2829 - val_loss: 2.3678 - val_accuracy: 0.2709\n",
      "Epoch 59/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3200 - accuracy: 0.2828 - val_loss: 2.3659 - val_accuracy: 0.2718\n",
      "Epoch 60/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3180 - accuracy: 0.2834 - val_loss: 2.3647 - val_accuracy: 0.2715\n",
      "Epoch 61/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3191 - accuracy: 0.2826 - val_loss: 2.3654 - val_accuracy: 0.2701\n",
      "Epoch 62/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3163 - accuracy: 0.2837 - val_loss: 2.3640 - val_accuracy: 0.2734\n",
      "Epoch 63/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3129 - accuracy: 0.2850 - val_loss: 2.3638 - val_accuracy: 0.2736\n",
      "Epoch 64/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3138 - accuracy: 0.2845 - val_loss: 2.3620 - val_accuracy: 0.2719\n",
      "Epoch 65/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3122 - accuracy: 0.2847 - val_loss: 2.3655 - val_accuracy: 0.2721\n",
      "Epoch 66/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3112 - accuracy: 0.2847 - val_loss: 2.3607 - val_accuracy: 0.2714\n",
      "Epoch 67/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3104 - accuracy: 0.2856 - val_loss: 2.3647 - val_accuracy: 0.2722\n",
      "Epoch 68/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.3082 - accuracy: 0.2866 - val_loss: 2.3643 - val_accuracy: 0.2719\n",
      "Epoch 69/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3072 - accuracy: 0.2856 - val_loss: 2.3621 - val_accuracy: 0.2717\n",
      "Epoch 70/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3079 - accuracy: 0.2855 - val_loss: 2.3640 - val_accuracy: 0.2706\n",
      "Epoch 71/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3044 - accuracy: 0.2872 - val_loss: 2.3632 - val_accuracy: 0.2718\n",
      "Epoch 72/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3043 - accuracy: 0.2860 - val_loss: 2.3621 - val_accuracy: 0.2739\n",
      "Epoch 73/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3036 - accuracy: 0.2874 - val_loss: 2.3619 - val_accuracy: 0.2718\n",
      "Epoch 74/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3026 - accuracy: 0.2876 - val_loss: 2.3607 - val_accuracy: 0.2720\n",
      "Epoch 75/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3012 - accuracy: 0.2876 - val_loss: 2.3590 - val_accuracy: 0.2725\n",
      "Epoch 76/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.3010 - accuracy: 0.2884 - val_loss: 2.3610 - val_accuracy: 0.2720\n",
      "Epoch 77/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2998 - accuracy: 0.2883 - val_loss: 2.3618 - val_accuracy: 0.2724\n",
      "Epoch 78/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2991 - accuracy: 0.2882 - val_loss: 2.3586 - val_accuracy: 0.2742\n",
      "Epoch 79/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2978 - accuracy: 0.2891 - val_loss: 2.3596 - val_accuracy: 0.2739\n",
      "Epoch 80/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2976 - accuracy: 0.2891 - val_loss: 2.3584 - val_accuracy: 0.2738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2977 - accuracy: 0.2884 - val_loss: 2.3584 - val_accuracy: 0.2745\n",
      "Epoch 82/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2944 - accuracy: 0.2891 - val_loss: 2.3568 - val_accuracy: 0.2754\n",
      "Epoch 83/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2955 - accuracy: 0.2900 - val_loss: 2.3592 - val_accuracy: 0.2756\n",
      "Epoch 84/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2925 - accuracy: 0.2903 - val_loss: 2.3572 - val_accuracy: 0.2728\n",
      "Epoch 85/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2926 - accuracy: 0.2916 - val_loss: 2.3570 - val_accuracy: 0.2767\n",
      "Epoch 86/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2922 - accuracy: 0.2906 - val_loss: 2.3590 - val_accuracy: 0.2728\n",
      "Epoch 87/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2896 - accuracy: 0.2913 - val_loss: 2.3584 - val_accuracy: 0.2737\n",
      "Epoch 88/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2901 - accuracy: 0.2903 - val_loss: 2.3569 - val_accuracy: 0.2746\n",
      "Epoch 89/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2908 - accuracy: 0.2927 - val_loss: 2.3571 - val_accuracy: 0.2741\n",
      "Epoch 90/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2901 - accuracy: 0.2900 - val_loss: 2.3582 - val_accuracy: 0.2746\n",
      "Epoch 91/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2898 - accuracy: 0.2914 - val_loss: 2.3564 - val_accuracy: 0.2747\n",
      "Epoch 92/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2904 - accuracy: 0.2909 - val_loss: 2.3564 - val_accuracy: 0.2736\n",
      "Epoch 93/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2870 - accuracy: 0.2914 - val_loss: 2.3548 - val_accuracy: 0.2757\n",
      "Epoch 94/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2883 - accuracy: 0.2918 - val_loss: 2.3549 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2857 - accuracy: 0.2921 - val_loss: 2.3565 - val_accuracy: 0.2736\n",
      "Epoch 96/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2846 - accuracy: 0.2933 - val_loss: 2.3542 - val_accuracy: 0.2760\n",
      "Epoch 97/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2851 - accuracy: 0.2927 - val_loss: 2.3553 - val_accuracy: 0.2764\n",
      "Epoch 98/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2834 - accuracy: 0.2928 - val_loss: 2.3558 - val_accuracy: 0.2752\n",
      "Epoch 99/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2813 - accuracy: 0.2923 - val_loss: 2.3528 - val_accuracy: 0.2766\n",
      "Epoch 100/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2826 - accuracy: 0.2935 - val_loss: 2.3535 - val_accuracy: 0.2755\n",
      "Epoch 101/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2823 - accuracy: 0.2929 - val_loss: 2.3567 - val_accuracy: 0.2736\n",
      "Epoch 102/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2794 - accuracy: 0.2936 - val_loss: 2.3558 - val_accuracy: 0.2754\n",
      "Epoch 103/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2801 - accuracy: 0.2940 - val_loss: 2.3542 - val_accuracy: 0.2744\n",
      "Epoch 104/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2779 - accuracy: 0.2948 - val_loss: 2.3539 - val_accuracy: 0.2751\n",
      "Epoch 105/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2791 - accuracy: 0.2950 - val_loss: 2.3520 - val_accuracy: 0.2764\n",
      "Epoch 106/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2768 - accuracy: 0.2950 - val_loss: 2.3540 - val_accuracy: 0.2771\n",
      "Epoch 107/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2793 - accuracy: 0.2949 - val_loss: 2.3537 - val_accuracy: 0.2763\n",
      "Epoch 108/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2783 - accuracy: 0.2937 - val_loss: 2.3532 - val_accuracy: 0.2770\n",
      "Epoch 109/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2778 - accuracy: 0.2951 - val_loss: 2.3510 - val_accuracy: 0.2755\n",
      "Epoch 110/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2747 - accuracy: 0.2950 - val_loss: 2.3541 - val_accuracy: 0.2748\n",
      "Epoch 111/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2751 - accuracy: 0.2952 - val_loss: 2.3517 - val_accuracy: 0.2760\n",
      "Epoch 112/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2735 - accuracy: 0.2960 - val_loss: 2.3529 - val_accuracy: 0.2769\n",
      "Epoch 113/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2735 - accuracy: 0.2956 - val_loss: 2.3522 - val_accuracy: 0.2769\n",
      "Epoch 114/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2735 - accuracy: 0.2954 - val_loss: 2.3530 - val_accuracy: 0.2772\n",
      "Epoch 115/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2729 - accuracy: 0.2955 - val_loss: 2.3528 - val_accuracy: 0.2768\n",
      "Epoch 116/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2734 - accuracy: 0.2942 - val_loss: 2.3511 - val_accuracy: 0.2776\n",
      "Epoch 117/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2707 - accuracy: 0.2957 - val_loss: 2.3521 - val_accuracy: 0.2766\n",
      "Epoch 118/150\n",
      "114922/114922 [==============================] - 0s 2us/sample - loss: 2.2697 - accuracy: 0.2969 - val_loss: 2.3499 - val_accuracy: 0.2767\n",
      "Epoch 119/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2710 - accuracy: 0.2969 - val_loss: 2.3535 - val_accuracy: 0.2775\n",
      "Epoch 120/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2719 - accuracy: 0.2964 - val_loss: 2.3519 - val_accuracy: 0.2759\n",
      "Epoch 121/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2700 - accuracy: 0.2971 - val_loss: 2.3515 - val_accuracy: 0.2781\n",
      "Epoch 122/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2700 - accuracy: 0.2958 - val_loss: 2.3517 - val_accuracy: 0.2765\n",
      "Epoch 123/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2687 - accuracy: 0.2966 - val_loss: 2.3496 - val_accuracy: 0.2783\n",
      "Epoch 124/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2699 - accuracy: 0.2965 - val_loss: 2.3535 - val_accuracy: 0.2787\n",
      "Epoch 125/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2661 - accuracy: 0.2973 - val_loss: 2.3496 - val_accuracy: 0.2770\n",
      "Epoch 126/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2672 - accuracy: 0.2965 - val_loss: 2.3503 - val_accuracy: 0.2794\n",
      "Epoch 127/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2675 - accuracy: 0.2979 - val_loss: 2.3512 - val_accuracy: 0.2768\n",
      "Epoch 128/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2656 - accuracy: 0.2977 - val_loss: 2.3530 - val_accuracy: 0.2758\n",
      "Epoch 129/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2662 - accuracy: 0.2979 - val_loss: 2.3493 - val_accuracy: 0.2796\n",
      "Epoch 130/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2658 - accuracy: 0.2965 - val_loss: 2.3502 - val_accuracy: 0.2782\n",
      "Epoch 131/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2644 - accuracy: 0.2985 - val_loss: 2.3496 - val_accuracy: 0.2788\n",
      "Epoch 132/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2637 - accuracy: 0.2984 - val_loss: 2.3499 - val_accuracy: 0.2777\n",
      "Epoch 133/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2654 - accuracy: 0.2974 - val_loss: 2.3509 - val_accuracy: 0.2781\n",
      "Epoch 134/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2645 - accuracy: 0.2980 - val_loss: 2.3492 - val_accuracy: 0.2780\n",
      "Epoch 135/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2628 - accuracy: 0.2975 - val_loss: 2.3486 - val_accuracy: 0.2795\n",
      "Epoch 136/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2635 - accuracy: 0.2991 - val_loss: 2.3495 - val_accuracy: 0.2791\n",
      "Epoch 137/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2617 - accuracy: 0.3003 - val_loss: 2.3496 - val_accuracy: 0.2795\n",
      "Epoch 138/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2640 - accuracy: 0.2990 - val_loss: 2.3492 - val_accuracy: 0.2799\n",
      "Epoch 139/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2622 - accuracy: 0.2973 - val_loss: 2.3506 - val_accuracy: 0.2776\n",
      "Epoch 140/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2601 - accuracy: 0.2981 - val_loss: 2.3476 - val_accuracy: 0.2804\n",
      "Epoch 141/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2622 - accuracy: 0.2985 - val_loss: 2.3517 - val_accuracy: 0.2783\n",
      "Epoch 142/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2616 - accuracy: 0.2982 - val_loss: 2.3492 - val_accuracy: 0.2771\n",
      "Epoch 143/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2588 - accuracy: 0.2983 - val_loss: 2.3506 - val_accuracy: 0.2781\n",
      "Epoch 144/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2585 - accuracy: 0.2989 - val_loss: 2.3490 - val_accuracy: 0.2777\n",
      "Epoch 145/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2583 - accuracy: 0.2989 - val_loss: 2.3493 - val_accuracy: 0.2784\n",
      "Epoch 146/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2592 - accuracy: 0.2987 - val_loss: 2.3482 - val_accuracy: 0.2777\n",
      "Epoch 147/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2580 - accuracy: 0.2997 - val_loss: 2.3507 - val_accuracy: 0.2773\n",
      "Epoch 148/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2592 - accuracy: 0.2994 - val_loss: 2.3474 - val_accuracy: 0.2772\n",
      "Epoch 149/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2595 - accuracy: 0.3009 - val_loss: 2.3456 - val_accuracy: 0.2800\n",
      "Epoch 150/150\n",
      "114922/114922 [==============================] - 0s 3us/sample - loss: 2.2553 - accuracy: 0.2996 - val_loss: 2.3494 - val_accuracy: 0.2778\n",
      "Restoring the best weights from epoch 150\n",
      "Training fold 5\n",
      "Train on 114925 samples, validate on 28719 samples\n",
      "Epoch 1/150\n",
      "114925/114925 [==============================] - 1s 5us/sample - loss: 2.9967 - accuracy: 0.1264 - val_loss: 2.7832 - val_accuracy: 0.1684\n",
      "Epoch 2/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.7207 - accuracy: 0.1808 - val_loss: 2.6470 - val_accuracy: 0.2012\n",
      "Epoch 3/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.6264 - accuracy: 0.2011 - val_loss: 2.5842 - val_accuracy: 0.2141\n",
      "Epoch 4/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.5738 - accuracy: 0.2163 - val_loss: 2.5396 - val_accuracy: 0.2267\n",
      "Epoch 5/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.5389 - accuracy: 0.2243 - val_loss: 2.5195 - val_accuracy: 0.2295\n",
      "Epoch 6/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.5162 - accuracy: 0.2297 - val_loss: 2.4978 - val_accuracy: 0.2353\n",
      "Epoch 7/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4980 - accuracy: 0.2350 - val_loss: 2.4833 - val_accuracy: 0.2383\n",
      "Epoch 8/150\n",
      "114925/114925 [==============================] - 0s 2us/sample - loss: 2.4832 - accuracy: 0.2377 - val_loss: 2.4750 - val_accuracy: 0.2429\n",
      "Epoch 9/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4722 - accuracy: 0.2420 - val_loss: 2.4636 - val_accuracy: 0.2445\n",
      "Epoch 10/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4614 - accuracy: 0.2440 - val_loss: 2.4596 - val_accuracy: 0.2458\n",
      "Epoch 11/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4534 - accuracy: 0.2472 - val_loss: 2.4503 - val_accuracy: 0.2483\n",
      "Epoch 12/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4448 - accuracy: 0.2489 - val_loss: 2.4463 - val_accuracy: 0.2499\n",
      "Epoch 13/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4383 - accuracy: 0.2501 - val_loss: 2.4408 - val_accuracy: 0.2501\n",
      "Epoch 14/150\n",
      "114925/114925 [==============================] - 0s 4us/sample - loss: 2.4318 - accuracy: 0.2518 - val_loss: 2.4325 - val_accuracy: 0.2550\n",
      "Epoch 15/150\n",
      "114925/114925 [==============================] - 0s 2us/sample - loss: 2.4259 - accuracy: 0.2535 - val_loss: 2.4311 - val_accuracy: 0.2542\n",
      "Epoch 16/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4196 - accuracy: 0.2557 - val_loss: 2.4244 - val_accuracy: 0.2555\n",
      "Epoch 17/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4147 - accuracy: 0.2575 - val_loss: 2.4234 - val_accuracy: 0.2563\n",
      "Epoch 18/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4098 - accuracy: 0.2581 - val_loss: 2.4213 - val_accuracy: 0.2575\n",
      "Epoch 19/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4058 - accuracy: 0.2591 - val_loss: 2.4179 - val_accuracy: 0.2570\n",
      "Epoch 20/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.4013 - accuracy: 0.2613 - val_loss: 2.4117 - val_accuracy: 0.2582\n",
      "Epoch 21/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3955 - accuracy: 0.2631 - val_loss: 2.4124 - val_accuracy: 0.2582\n",
      "Epoch 22/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3947 - accuracy: 0.2627 - val_loss: 2.4095 - val_accuracy: 0.2606\n",
      "Epoch 23/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3897 - accuracy: 0.2633 - val_loss: 2.4061 - val_accuracy: 0.2618\n",
      "Epoch 24/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3869 - accuracy: 0.2644 - val_loss: 2.4031 - val_accuracy: 0.2607\n",
      "Epoch 25/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3826 - accuracy: 0.2650 - val_loss: 2.4026 - val_accuracy: 0.2626\n",
      "Epoch 26/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3803 - accuracy: 0.2654 - val_loss: 2.4019 - val_accuracy: 0.2631\n",
      "Epoch 27/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3768 - accuracy: 0.2672 - val_loss: 2.3980 - val_accuracy: 0.2630\n",
      "Epoch 28/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3761 - accuracy: 0.2676 - val_loss: 2.3978 - val_accuracy: 0.2630\n",
      "Epoch 29/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3716 - accuracy: 0.2691 - val_loss: 2.3951 - val_accuracy: 0.2654\n",
      "Epoch 30/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3694 - accuracy: 0.2684 - val_loss: 2.3962 - val_accuracy: 0.2632\n",
      "Epoch 31/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3680 - accuracy: 0.2697 - val_loss: 2.3901 - val_accuracy: 0.2656\n",
      "Epoch 32/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3639 - accuracy: 0.2706 - val_loss: 2.3888 - val_accuracy: 0.2642\n",
      "Epoch 33/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3603 - accuracy: 0.2713 - val_loss: 2.3867 - val_accuracy: 0.2658\n",
      "Epoch 34/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3602 - accuracy: 0.2707 - val_loss: 2.3879 - val_accuracy: 0.2650\n",
      "Epoch 35/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3577 - accuracy: 0.2731 - val_loss: 2.3842 - val_accuracy: 0.2686\n",
      "Epoch 36/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3555 - accuracy: 0.2733 - val_loss: 2.3827 - val_accuracy: 0.2668\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3537 - accuracy: 0.2730 - val_loss: 2.3851 - val_accuracy: 0.2670\n",
      "Epoch 38/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3522 - accuracy: 0.2732 - val_loss: 2.3816 - val_accuracy: 0.2673\n",
      "Epoch 39/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3493 - accuracy: 0.2749 - val_loss: 2.3817 - val_accuracy: 0.2669\n",
      "Epoch 40/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3481 - accuracy: 0.2759 - val_loss: 2.3815 - val_accuracy: 0.2685\n",
      "Epoch 41/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3444 - accuracy: 0.2757 - val_loss: 2.3801 - val_accuracy: 0.2675\n",
      "Epoch 42/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3420 - accuracy: 0.2775 - val_loss: 2.3785 - val_accuracy: 0.2686\n",
      "Epoch 43/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3430 - accuracy: 0.2767 - val_loss: 2.3759 - val_accuracy: 0.2692\n",
      "Epoch 44/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3391 - accuracy: 0.2774 - val_loss: 2.3747 - val_accuracy: 0.2700\n",
      "Epoch 45/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3401 - accuracy: 0.2764 - val_loss: 2.3753 - val_accuracy: 0.2690\n",
      "Epoch 46/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3367 - accuracy: 0.2787 - val_loss: 2.3749 - val_accuracy: 0.2700\n",
      "Epoch 47/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3348 - accuracy: 0.2798 - val_loss: 2.3744 - val_accuracy: 0.2719\n",
      "Epoch 48/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3348 - accuracy: 0.2785 - val_loss: 2.3732 - val_accuracy: 0.2709\n",
      "Epoch 49/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3325 - accuracy: 0.2790 - val_loss: 2.3708 - val_accuracy: 0.2714\n",
      "Epoch 50/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3298 - accuracy: 0.2797 - val_loss: 2.3736 - val_accuracy: 0.2715\n",
      "Epoch 51/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3283 - accuracy: 0.2796 - val_loss: 2.3720 - val_accuracy: 0.2703\n",
      "Epoch 52/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3267 - accuracy: 0.2802 - val_loss: 2.3726 - val_accuracy: 0.2711\n",
      "Epoch 53/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3260 - accuracy: 0.2812 - val_loss: 2.3728 - val_accuracy: 0.2703\n",
      "Epoch 54/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3232 - accuracy: 0.2811 - val_loss: 2.3686 - val_accuracy: 0.2718\n",
      "Epoch 55/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3229 - accuracy: 0.2808 - val_loss: 2.3686 - val_accuracy: 0.2721\n",
      "Epoch 56/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3227 - accuracy: 0.2806 - val_loss: 2.3707 - val_accuracy: 0.2701\n",
      "Epoch 57/150\n",
      "114925/114925 [==============================] - 0s 2us/sample - loss: 2.3201 - accuracy: 0.2818 - val_loss: 2.3701 - val_accuracy: 0.2715\n",
      "Epoch 58/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3192 - accuracy: 0.2831 - val_loss: 2.3658 - val_accuracy: 0.2716\n",
      "Epoch 59/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3162 - accuracy: 0.2833 - val_loss: 2.3671 - val_accuracy: 0.2714\n",
      "Epoch 60/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3147 - accuracy: 0.2836 - val_loss: 2.3666 - val_accuracy: 0.2718\n",
      "Epoch 61/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3148 - accuracy: 0.2849 - val_loss: 2.3656 - val_accuracy: 0.2714\n",
      "Epoch 62/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3130 - accuracy: 0.2837 - val_loss: 2.3633 - val_accuracy: 0.2723\n",
      "Epoch 63/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3111 - accuracy: 0.2862 - val_loss: 2.3657 - val_accuracy: 0.2717\n",
      "Epoch 64/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3103 - accuracy: 0.2852 - val_loss: 2.3659 - val_accuracy: 0.2712\n",
      "Epoch 65/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3109 - accuracy: 0.2847 - val_loss: 2.3646 - val_accuracy: 0.2743\n",
      "Epoch 66/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3111 - accuracy: 0.2850 - val_loss: 2.3649 - val_accuracy: 0.2715\n",
      "Epoch 67/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3081 - accuracy: 0.2868 - val_loss: 2.3641 - val_accuracy: 0.2718\n",
      "Epoch 68/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3083 - accuracy: 0.2869 - val_loss: 2.3657 - val_accuracy: 0.2745\n",
      "Epoch 69/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3056 - accuracy: 0.2869 - val_loss: 2.3619 - val_accuracy: 0.2750\n",
      "Epoch 70/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3050 - accuracy: 0.2870 - val_loss: 2.3637 - val_accuracy: 0.2734\n",
      "Epoch 71/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3046 - accuracy: 0.2869 - val_loss: 2.3618 - val_accuracy: 0.2741\n",
      "Epoch 72/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3031 - accuracy: 0.2876 - val_loss: 2.3609 - val_accuracy: 0.2732\n",
      "Epoch 73/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3021 - accuracy: 0.2883 - val_loss: 2.3608 - val_accuracy: 0.2758\n",
      "Epoch 74/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3001 - accuracy: 0.2878 - val_loss: 2.3625 - val_accuracy: 0.2742\n",
      "Epoch 75/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2996 - accuracy: 0.2901 - val_loss: 2.3610 - val_accuracy: 0.2755\n",
      "Epoch 76/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.3009 - accuracy: 0.2869 - val_loss: 2.3609 - val_accuracy: 0.2746\n",
      "Epoch 77/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2973 - accuracy: 0.2896 - val_loss: 2.3607 - val_accuracy: 0.2769\n",
      "Epoch 78/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2988 - accuracy: 0.2904 - val_loss: 2.3632 - val_accuracy: 0.2749\n",
      "Epoch 79/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2969 - accuracy: 0.2883 - val_loss: 2.3606 - val_accuracy: 0.2729\n",
      "Epoch 80/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2954 - accuracy: 0.2892 - val_loss: 2.3604 - val_accuracy: 0.2739\n",
      "Epoch 81/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2941 - accuracy: 0.2899 - val_loss: 2.3618 - val_accuracy: 0.2738\n",
      "Epoch 82/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2933 - accuracy: 0.2904 - val_loss: 2.3584 - val_accuracy: 0.2746\n",
      "Epoch 83/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2934 - accuracy: 0.2888 - val_loss: 2.3590 - val_accuracy: 0.2739\n",
      "Epoch 84/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2911 - accuracy: 0.2903 - val_loss: 2.3596 - val_accuracy: 0.2748\n",
      "Epoch 85/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2920 - accuracy: 0.2915 - val_loss: 2.3605 - val_accuracy: 0.2764\n",
      "Epoch 86/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2915 - accuracy: 0.2911 - val_loss: 2.3585 - val_accuracy: 0.2747\n",
      "Epoch 87/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2903 - accuracy: 0.2906 - val_loss: 2.3601 - val_accuracy: 0.2753\n",
      "Epoch 88/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2893 - accuracy: 0.2930 - val_loss: 2.3582 - val_accuracy: 0.2758\n",
      "Epoch 89/150\n",
      "114925/114925 [==============================] - 0s 2us/sample - loss: 2.2889 - accuracy: 0.2917 - val_loss: 2.3586 - val_accuracy: 0.2760\n",
      "Epoch 90/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2862 - accuracy: 0.2922 - val_loss: 2.3611 - val_accuracy: 0.2761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2874 - accuracy: 0.2917 - val_loss: 2.3581 - val_accuracy: 0.2763\n",
      "Epoch 92/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2865 - accuracy: 0.2928 - val_loss: 2.3584 - val_accuracy: 0.2758\n",
      "Epoch 93/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2847 - accuracy: 0.2937 - val_loss: 2.3555 - val_accuracy: 0.2760\n",
      "Epoch 94/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2844 - accuracy: 0.2921 - val_loss: 2.3601 - val_accuracy: 0.2746\n",
      "Epoch 95/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2848 - accuracy: 0.2925 - val_loss: 2.3576 - val_accuracy: 0.2756\n",
      "Epoch 96/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2835 - accuracy: 0.2936 - val_loss: 2.3592 - val_accuracy: 0.2740\n",
      "Epoch 97/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2819 - accuracy: 0.2928 - val_loss: 2.3559 - val_accuracy: 0.2763\n",
      "Epoch 98/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2793 - accuracy: 0.2947 - val_loss: 2.3566 - val_accuracy: 0.2754\n",
      "Epoch 99/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2809 - accuracy: 0.2942 - val_loss: 2.3589 - val_accuracy: 0.2747\n",
      "Epoch 100/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2791 - accuracy: 0.2934 - val_loss: 2.3564 - val_accuracy: 0.2767\n",
      "Epoch 101/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2778 - accuracy: 0.2937 - val_loss: 2.3575 - val_accuracy: 0.2751\n",
      "Epoch 102/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2781 - accuracy: 0.2945 - val_loss: 2.3565 - val_accuracy: 0.2756\n",
      "Epoch 103/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2777 - accuracy: 0.2949 - val_loss: 2.3548 - val_accuracy: 0.2769\n",
      "Epoch 104/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2771 - accuracy: 0.2962 - val_loss: 2.3573 - val_accuracy: 0.2767\n",
      "Epoch 105/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2769 - accuracy: 0.2949 - val_loss: 2.3568 - val_accuracy: 0.2754\n",
      "Epoch 106/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2766 - accuracy: 0.2943 - val_loss: 2.3566 - val_accuracy: 0.2751\n",
      "Epoch 107/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2748 - accuracy: 0.2953 - val_loss: 2.3568 - val_accuracy: 0.2756\n",
      "Epoch 108/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2749 - accuracy: 0.2956 - val_loss: 2.3587 - val_accuracy: 0.2771\n",
      "Epoch 109/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2739 - accuracy: 0.2956 - val_loss: 2.3577 - val_accuracy: 0.2772\n",
      "Epoch 110/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2747 - accuracy: 0.2962 - val_loss: 2.3553 - val_accuracy: 0.2773\n",
      "Epoch 111/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2729 - accuracy: 0.2958 - val_loss: 2.3556 - val_accuracy: 0.2775\n",
      "Epoch 112/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2730 - accuracy: 0.2962 - val_loss: 2.3551 - val_accuracy: 0.2765\n",
      "Epoch 113/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2709 - accuracy: 0.2974 - val_loss: 2.3559 - val_accuracy: 0.2760\n",
      "Epoch 114/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2714 - accuracy: 0.2959 - val_loss: 2.3569 - val_accuracy: 0.2770\n",
      "Epoch 115/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2703 - accuracy: 0.2964 - val_loss: 2.3541 - val_accuracy: 0.2767\n",
      "Epoch 116/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2686 - accuracy: 0.2972 - val_loss: 2.3555 - val_accuracy: 0.2763\n",
      "Epoch 117/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2699 - accuracy: 0.2982 - val_loss: 2.3551 - val_accuracy: 0.2779\n",
      "Epoch 118/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2687 - accuracy: 0.2983 - val_loss: 2.3529 - val_accuracy: 0.2771\n",
      "Epoch 119/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2692 - accuracy: 0.2975 - val_loss: 2.3540 - val_accuracy: 0.2789\n",
      "Epoch 120/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2680 - accuracy: 0.2967 - val_loss: 2.3538 - val_accuracy: 0.2798\n",
      "Epoch 121/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2664 - accuracy: 0.2981 - val_loss: 2.3567 - val_accuracy: 0.2769\n",
      "Epoch 122/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2682 - accuracy: 0.2983 - val_loss: 2.3583 - val_accuracy: 0.2750\n",
      "Epoch 123/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2667 - accuracy: 0.2972 - val_loss: 2.3525 - val_accuracy: 0.2771\n",
      "Epoch 124/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2657 - accuracy: 0.2982 - val_loss: 2.3539 - val_accuracy: 0.2774\n",
      "Epoch 125/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2655 - accuracy: 0.2974 - val_loss: 2.3551 - val_accuracy: 0.2770\n",
      "Epoch 126/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2649 - accuracy: 0.2980 - val_loss: 2.3551 - val_accuracy: 0.2774\n",
      "Epoch 127/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2648 - accuracy: 0.3006 - val_loss: 2.3577 - val_accuracy: 0.2768\n",
      "Epoch 128/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2650 - accuracy: 0.2997 - val_loss: 2.3545 - val_accuracy: 0.2782\n",
      "Epoch 129/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2646 - accuracy: 0.2984 - val_loss: 2.3551 - val_accuracy: 0.2771\n",
      "Epoch 130/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2625 - accuracy: 0.3001 - val_loss: 2.3543 - val_accuracy: 0.2776\n",
      "Epoch 131/150\n",
      "114925/114925 [==============================] - 0s 2us/sample - loss: 2.2636 - accuracy: 0.2983 - val_loss: 2.3562 - val_accuracy: 0.2764\n",
      "Epoch 132/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2607 - accuracy: 0.2984 - val_loss: 2.3531 - val_accuracy: 0.2784\n",
      "Epoch 133/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2606 - accuracy: 0.3004 - val_loss: 2.3536 - val_accuracy: 0.2786\n",
      "Epoch 134/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2616 - accuracy: 0.2990 - val_loss: 2.3550 - val_accuracy: 0.2777\n",
      "Epoch 135/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2606 - accuracy: 0.3010 - val_loss: 2.3560 - val_accuracy: 0.2781\n",
      "Epoch 136/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2610 - accuracy: 0.2998 - val_loss: 2.3547 - val_accuracy: 0.2791\n",
      "Epoch 137/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2585 - accuracy: 0.2998 - val_loss: 2.3547 - val_accuracy: 0.2770\n",
      "Epoch 138/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2601 - accuracy: 0.3000 - val_loss: 2.3578 - val_accuracy: 0.2763\n",
      "Epoch 139/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2583 - accuracy: 0.2990 - val_loss: 2.3569 - val_accuracy: 0.2768\n",
      "Epoch 140/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2592 - accuracy: 0.2997 - val_loss: 2.3541 - val_accuracy: 0.2774\n",
      "Epoch 141/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2578 - accuracy: 0.3008 - val_loss: 2.3543 - val_accuracy: 0.2777\n",
      "Epoch 142/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2570 - accuracy: 0.2994 - val_loss: 2.3537 - val_accuracy: 0.2775\n",
      "Epoch 143/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2573 - accuracy: 0.3008 - val_loss: 2.3553 - val_accuracy: 0.2784\n",
      "Epoch 144/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2550 - accuracy: 0.3010 - val_loss: 2.3561 - val_accuracy: 0.2788\n",
      "Epoch 145/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2557 - accuracy: 0.3010 - val_loss: 2.3563 - val_accuracy: 0.2769\n",
      "Epoch 146/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2550 - accuracy: 0.3031 - val_loss: 2.3528 - val_accuracy: 0.2792\n",
      "Epoch 147/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2564 - accuracy: 0.3003 - val_loss: 2.3520 - val_accuracy: 0.2786\n",
      "Epoch 148/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2552 - accuracy: 0.3013 - val_loss: 2.3539 - val_accuracy: 0.2784\n",
      "Epoch 149/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2529 - accuracy: 0.3021 - val_loss: 2.3548 - val_accuracy: 0.2770\n",
      "Epoch 150/150\n",
      "114925/114925 [==============================] - 0s 3us/sample - loss: 2.2532 - accuracy: 0.3024 - val_loss: 2.3554 - val_accuracy: 0.2785\n",
      "Restoring the best weights from epoch 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_micro</th>\n",
       "      <td>0.279803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_f1_macro</th>\n",
       "      <td>0.262677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_accuracy</th>\n",
       "      <td>0.279803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_batch_val_accuracy</th>\n",
       "      <td>0.279803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_accuracy</th>\n",
       "      <td>0.299715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_val_loss</th>\n",
       "      <td>2.345093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loss</th>\n",
       "      <td>2.258318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>237.282015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "avg_val_f1_micro          0.279803\n",
       "avg_val_f1_macro          0.262677\n",
       "avg_val_accuracy          0.279803\n",
       "avg_batch_val_accuracy    0.279803\n",
       "avg_accuracy              0.299715\n",
       "avg_val_loss              2.345093\n",
       "avg_loss                  2.258318\n",
       "train_time              237.282015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_fold(x_train, y_train, x_val, y_val, run_name, fold=None):\n",
    "\n",
    "    input_shape = x_train[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    if fold is not None:\n",
    "        run_name += '_fold' + str(fold)\n",
    "        print('Training fold ' + str(fold))\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    weight_restorer = BestWeightsRestorer(monitor='val_loss', mode='min', verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=[x_val, y_val],\n",
    "        epochs=150,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board, weight_restorer],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    prob_predictions = model.predict(x_val)\n",
    "    predictions = prob_predictions.argmax(axis=1)\n",
    "    \n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "experiment_number += 1\n",
    "run_name = 'new_base_mlp_deriv_cv_' + str(experiment_number)\n",
    "\n",
    "results = resultsUtil.cross_validate(\n",
    "    x=ftrs,\n",
    "    y=lbls_oh,\n",
    "    y_label_encoded=lbl_encoded_lbls,\n",
    "    n_splits=5,\n",
    "    train_func=train_fold,\n",
    "    run_name=run_name\n",
    ")\n",
    "\n",
    "runUtil.save_run_results(run_name, results)\n",
    "\n",
    "resultsdf = pd.DataFrame([results]).transpose()\n",
    "\n",
    "display(resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/marc/anaconda3/envs/ml_main/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "143644/143644 [==============================] - 1s 7us/sample - loss: 3.0152 - accuracy: 0.1189\n",
      "Epoch 2/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.6988 - accuracy: 0.1831\n",
      "Epoch 3/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.6008 - accuracy: 0.2070\n",
      "Epoch 4/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.5539 - accuracy: 0.2193\n",
      "Epoch 5/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.5242 - accuracy: 0.2272\n",
      "Epoch 6/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.5043 - accuracy: 0.2329\n",
      "Epoch 7/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4892 - accuracy: 0.2369\n",
      "Epoch 8/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4746 - accuracy: 0.2409\n",
      "Epoch 9/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4628 - accuracy: 0.2427\n",
      "Epoch 10/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.4539 - accuracy: 0.2474\n",
      "Epoch 11/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4467 - accuracy: 0.2475\n",
      "Epoch 12/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.4378 - accuracy: 0.2501\n",
      "Epoch 13/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.4302 - accuracy: 0.2525\n",
      "Epoch 14/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.4235 - accuracy: 0.2553\n",
      "Epoch 15/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4194 - accuracy: 0.2550\n",
      "Epoch 16/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4135 - accuracy: 0.2565\n",
      "Epoch 17/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4093 - accuracy: 0.2579\n",
      "Epoch 18/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.4062 - accuracy: 0.2585\n",
      "Epoch 19/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3993 - accuracy: 0.2604\n",
      "Epoch 20/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3954 - accuracy: 0.2624\n",
      "Epoch 21/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.3925 - accuracy: 0.2615\n",
      "Epoch 22/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3879 - accuracy: 0.2649\n",
      "Epoch 23/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.3833 - accuracy: 0.2651\n",
      "Epoch 24/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3798 - accuracy: 0.2667\n",
      "Epoch 25/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3765 - accuracy: 0.2679\n",
      "Epoch 26/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3741 - accuracy: 0.2672\n",
      "Epoch 27/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3747 - accuracy: 0.2690\n",
      "Epoch 28/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3687 - accuracy: 0.2687\n",
      "Epoch 29/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3659 - accuracy: 0.2720\n",
      "Epoch 30/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3632 - accuracy: 0.2709\n",
      "Epoch 31/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3608 - accuracy: 0.2723\n",
      "Epoch 32/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3575 - accuracy: 0.2733\n",
      "Epoch 33/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3556 - accuracy: 0.2736\n",
      "Epoch 34/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3536 - accuracy: 0.2733\n",
      "Epoch 35/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3524 - accuracy: 0.2747\n",
      "Epoch 36/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3492 - accuracy: 0.2756\n",
      "Epoch 37/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3473 - accuracy: 0.2767\n",
      "Epoch 38/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3449 - accuracy: 0.2765\n",
      "Epoch 39/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3440 - accuracy: 0.2771\n",
      "Epoch 40/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3410 - accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3391 - accuracy: 0.2790\n",
      "Epoch 42/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3386 - accuracy: 0.2782\n",
      "Epoch 43/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3343 - accuracy: 0.2799\n",
      "Epoch 44/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3338 - accuracy: 0.2799\n",
      "Epoch 45/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3332 - accuracy: 0.2791\n",
      "Epoch 46/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.3315 - accuracy: 0.2800\n",
      "Epoch 47/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3277 - accuracy: 0.2806\n",
      "Epoch 48/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3279 - accuracy: 0.2807\n",
      "Epoch 49/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3265 - accuracy: 0.2809\n",
      "Epoch 50/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3248 - accuracy: 0.2831\n",
      "Epoch 51/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3245 - accuracy: 0.2825\n",
      "Epoch 52/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3229 - accuracy: 0.2823\n",
      "Epoch 53/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3224 - accuracy: 0.2827\n",
      "Epoch 54/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3218 - accuracy: 0.2828\n",
      "Epoch 55/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3189 - accuracy: 0.2826\n",
      "Epoch 56/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3158 - accuracy: 0.2844\n",
      "Epoch 57/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3162 - accuracy: 0.2851\n",
      "Epoch 58/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3153 - accuracy: 0.2851\n",
      "Epoch 59/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3144 - accuracy: 0.2846\n",
      "Epoch 60/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3121 - accuracy: 0.2856\n",
      "Epoch 61/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3126 - accuracy: 0.2857\n",
      "Epoch 62/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3092 - accuracy: 0.2858\n",
      "Epoch 63/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3104 - accuracy: 0.2868\n",
      "Epoch 64/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3079 - accuracy: 0.2876\n",
      "Epoch 65/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3066 - accuracy: 0.2871\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3046 - accuracy: 0.2884\n",
      "Epoch 67/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3061 - accuracy: 0.2889\n",
      "Epoch 68/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.3063 - accuracy: 0.2872\n",
      "Epoch 69/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3054 - accuracy: 0.2877\n",
      "Epoch 70/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.3032 - accuracy: 0.2884\n",
      "Epoch 71/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.3028 - accuracy: 0.2876\n",
      "Epoch 72/150\n",
      "143644/143644 [==============================] - 1s 3us/sample - loss: 2.2994 - accuracy: 0.2885\n",
      "Epoch 73/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.3001 - accuracy: 0.2883\n",
      "Epoch 74/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2975 - accuracy: 0.2910\n",
      "Epoch 75/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2985 - accuracy: 0.2891\n",
      "Epoch 76/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2965 - accuracy: 0.2909\n",
      "Epoch 77/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2974 - accuracy: 0.2901\n",
      "Epoch 78/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2952 - accuracy: 0.2910\n",
      "Epoch 79/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2938 - accuracy: 0.2905\n",
      "Epoch 80/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2939 - accuracy: 0.2900\n",
      "Epoch 81/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2927 - accuracy: 0.2916\n",
      "Epoch 82/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2914 - accuracy: 0.2909\n",
      "Epoch 83/150\n",
      "143644/143644 [==============================] - 1s 4us/sample - loss: 2.2907 - accuracy: 0.2916\n",
      "Epoch 84/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2911 - accuracy: 0.2920\n",
      "Epoch 85/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2906 - accuracy: 0.2915\n",
      "Epoch 86/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2886 - accuracy: 0.2927\n",
      "Epoch 87/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2886 - accuracy: 0.2924\n",
      "Epoch 88/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2885 - accuracy: 0.2936\n",
      "Epoch 89/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2865 - accuracy: 0.2931\n",
      "Epoch 90/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2852 - accuracy: 0.2934\n",
      "Epoch 91/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2856 - accuracy: 0.2931\n",
      "Epoch 92/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2847 - accuracy: 0.2926\n",
      "Epoch 93/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2839 - accuracy: 0.2933\n",
      "Epoch 94/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2831 - accuracy: 0.2945\n",
      "Epoch 95/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2829 - accuracy: 0.2945\n",
      "Epoch 96/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2833 - accuracy: 0.2938\n",
      "Epoch 97/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2826 - accuracy: 0.2944\n",
      "Epoch 98/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2803 - accuracy: 0.2952\n",
      "Epoch 99/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2811 - accuracy: 0.2949\n",
      "Epoch 100/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2798 - accuracy: 0.2952\n",
      "Epoch 101/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2803 - accuracy: 0.2949\n",
      "Epoch 102/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2789 - accuracy: 0.2951\n",
      "Epoch 103/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2760 - accuracy: 0.2955\n",
      "Epoch 104/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2779 - accuracy: 0.2955\n",
      "Epoch 105/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2756 - accuracy: 0.2965\n",
      "Epoch 106/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2777 - accuracy: 0.2953\n",
      "Epoch 107/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2752 - accuracy: 0.2971\n",
      "Epoch 108/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2759 - accuracy: 0.2963\n",
      "Epoch 109/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2763 - accuracy: 0.2959\n",
      "Epoch 110/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2746 - accuracy: 0.2949\n",
      "Epoch 111/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2726 - accuracy: 0.2966\n",
      "Epoch 112/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2717 - accuracy: 0.2980\n",
      "Epoch 113/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2714 - accuracy: 0.2973\n",
      "Epoch 114/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2720 - accuracy: 0.2966\n",
      "Epoch 115/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2723 - accuracy: 0.2956\n",
      "Epoch 116/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2717 - accuracy: 0.2969\n",
      "Epoch 117/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2703 - accuracy: 0.2982\n",
      "Epoch 118/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2712 - accuracy: 0.2970\n",
      "Epoch 119/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2686 - accuracy: 0.2979\n",
      "Epoch 120/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2688 - accuracy: 0.2975\n",
      "Epoch 121/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2680 - accuracy: 0.2980\n",
      "Epoch 122/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2692 - accuracy: 0.2974\n",
      "Epoch 123/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2669 - accuracy: 0.2983\n",
      "Epoch 124/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2675 - accuracy: 0.2990\n",
      "Epoch 125/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2661 - accuracy: 0.2997\n",
      "Epoch 126/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2656 - accuracy: 0.2995\n",
      "Epoch 127/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2652 - accuracy: 0.2984\n",
      "Epoch 128/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2650 - accuracy: 0.2981\n",
      "Epoch 129/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2655 - accuracy: 0.2997\n",
      "Epoch 130/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2671 - accuracy: 0.2990\n",
      "Epoch 131/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2647 - accuracy: 0.2985\n",
      "Epoch 132/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2633 - accuracy: 0.2997\n",
      "Epoch 133/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2627 - accuracy: 0.2995\n",
      "Epoch 134/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2635 - accuracy: 0.3000\n",
      "Epoch 135/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2640 - accuracy: 0.2988\n",
      "Epoch 136/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2626 - accuracy: 0.2990\n",
      "Epoch 137/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2619 - accuracy: 0.3002\n",
      "Epoch 138/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2619 - accuracy: 0.3002\n",
      "Epoch 139/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2618 - accuracy: 0.3009\n",
      "Epoch 140/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2611 - accuracy: 0.3011\n",
      "Epoch 141/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2618 - accuracy: 0.2996\n",
      "Epoch 142/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2614 - accuracy: 0.3007\n",
      "Epoch 143/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2594 - accuracy: 0.2999\n",
      "Epoch 144/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2574 - accuracy: 0.3004\n",
      "Epoch 145/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2582 - accuracy: 0.3006\n",
      "Epoch 146/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2586 - accuracy: 0.3002\n",
      "Epoch 147/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2567 - accuracy: 0.3008\n",
      "Epoch 148/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2560 - accuracy: 0.3016\n",
      "Epoch 149/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2561 - accuracy: 0.3023\n",
      "Epoch 150/150\n",
      "143644/143644 [==============================] - 0s 3us/sample - loss: 2.2569 - accuracy: 0.3009\n"
     ]
    }
   ],
   "source": [
    "def train_final_model(x, y, run_name):\n",
    "    \n",
    "    save_path = constants.MODELS_PATH + run_name + '.h5' \n",
    "    \n",
    "    input_shape = x[0].shape\n",
    "    model = create_model(input_shape)\n",
    "    \n",
    "    tk_board = TensorBoard(log_dir=constants.LOGS_PATH + run_name)\n",
    "    \n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        epochs=150,\n",
    "        batch_size=2000,\n",
    "        shuffle=True,\n",
    "        callbacks=[tk_board],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.save(save_path)\n",
    "\n",
    "\n",
    "train_final_model(ftrs, lbls_oh, 'base_mlp_deriv_final4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
